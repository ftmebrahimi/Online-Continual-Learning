{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1BIBJep39wY",
        "outputId": "07ac84a1-839f-4995-e21d-a15487f04aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet-ml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.44.1)\n",
            "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (6.0.0)\n",
            "Requirement already satisfied: python-box<7.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (6.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (2.32.3)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (2.10.0)\n",
            "Requirement already satisfied: simplejson in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (3.19.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (2.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (1.16.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (3.1.1)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (0.22.1)\n",
            "Requirement already satisfied: rich>=13.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from comet-ml) (13.7.1)\n",
            "Requirement already satisfied: configobj in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.8)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.18.4->comet-ml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.18.4->comet-ml) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.18.4->comet-ml) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich>=13.3.2->comet-ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich>=13.3.2->comet-ml) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
            "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet-ml) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install comet-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEkdjhYBhN1n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import pdb\n",
        "import itertools\n",
        "import random\n",
        "import string\n",
        "import math\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "import torch.nn.utils.weight_norm as weightNorm\n",
        "from torch.nn.functional import relu, avg_pool2d\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data.sampler import Sampler, RandomSampler\n",
        "import torchvision.transforms.functional as TorchVisionFunc\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, ConcatDataset, Subset\n",
        "\n",
        "from comet_ml import Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MxXNmOBKF4N"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "def save_model(model, path):\n",
        "    torch.save(model.cpu(), path)\n",
        "\n",
        "def load_model(path):\n",
        "    model = torch.load(path)\n",
        "    return model\n",
        "\n",
        "def setup_experiment(experiment, config):\n",
        "    Path(f\"./checkpoints/{config['dataset']}\").mkdir(parents=True, exist_ok=True)\n",
        "    init_model = ResNet18(config=config) if 'cifar' in config['dataset'] else MLP(config)\n",
        "    save_model(init_model, f\"./checkpoints/{config['dataset']}/init.pth\")\n",
        "    experiment.log_parameters(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj02gPIajcAN"
      },
      "source": [
        "# Compute grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JV_M877jamR"
      },
      "outputs": [],
      "source": [
        "def flatten_grads(m, numpy_output=False, bias=True, only_linear=False):\n",
        "    total_grads = []\n",
        "    for name, param in m.named_parameters():\n",
        "        if only_linear:\n",
        "            if (bias or not 'bias' in name) and 'linear' in name:\n",
        "                total_grads.append(param.grad.detach().view(-1))\n",
        "        else:\n",
        "            if (bias or not 'bias' in name) and not 'bn' in name and not 'IC' in name:\n",
        "                try:\n",
        "                    total_grads.append(param.grad.detach().view(-1))\n",
        "                except AttributeError:\n",
        "                    pass\n",
        "\n",
        "    total_grads = torch.cat(total_grads)\n",
        "    if numpy_output:\n",
        "        return total_grads.cpu().detach().numpy()\n",
        "    return total_grads\n",
        "\n",
        "\n",
        "def compute_and_flatten_example_grads(m, criterion, data, target, task_id):\n",
        "    _eg = []\n",
        "    criterion2 = nn.CrossEntropyLoss(reduction='none').to(DEVICE)\n",
        "    m.eval()\n",
        "    m.zero_grad()\n",
        "    pred = m(data, task_id)\n",
        "    loss = criterion2(pred, target)\n",
        "    for idx in range(len(data)):\n",
        "        loss[idx].backward(retain_graph=True)\n",
        "        _g = flatten_grads(m, numpy_output=True)\n",
        "        _eg.append(torch.Tensor(_g))\n",
        "        m.zero_grad()\n",
        "    return torch.stack(_eg)\n",
        "\n",
        "def flatten_example_grads(m, numpy_output=False):\n",
        "    total_grads = []\n",
        "    for param in m.parameters():\n",
        "            total_grads.append(param.grad1.view(param.grad1.size()[0], -1))\n",
        "    total_grads = torch.cat(total_grads, 1)\n",
        "    if numpy_output:\n",
        "        return total_grads.cpu().detach().numpy()\n",
        "    return total_grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_BJLU24jxZs"
      },
      "source": [
        "# Coreset Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGXNSnIZwC-L"
      },
      "outputs": [],
      "source": [
        "def sample_selection(g, eg, config, ref_grads=None, attn=None):\n",
        "    ng = torch.norm(g)\n",
        "    neg = torch.norm(eg, dim=1)\n",
        "    mean_sim = torch.matmul(g,eg.t()) / torch.maximum(ng*neg, torch.ones_like(neg)*1e-6)\n",
        "    negd = torch.unsqueeze(neg, 1)\n",
        "\n",
        "    cross_div = torch.matmul(eg,eg.t()) / torch.maximum(torch.matmul(negd, negd.t()), torch.ones_like(negd)*1e-6)\n",
        "    avg_div = torch.mean(cross_div, 0)\n",
        "\n",
        "    coreset_aff = 0.\n",
        "    if ref_grads is not None:\n",
        "        ref_ng = torch.norm(ref_grads)\n",
        "        coreset_aff = torch.matmul(ref_grads, eg.t()) / torch.maximum(ref_ng*neg, torch.ones_like(neg)*1e-6)\n",
        "\n",
        "    measure = mean_sim - avg_div + config['tau'] * coreset_aff\n",
        "    _, u_idx = torch.sort(measure, descending=True)\n",
        "    return u_idx.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YifnpGnkD5W6"
      },
      "outputs": [],
      "source": [
        "def classwise_fair_selection(task, cand_target, sorted_index, num_per_label, config, is_shuffle=True):\n",
        "    num_examples_per_task = config['memory_size'] // task\n",
        "    num_examples_per_class = num_examples_per_task // config['n_classes']\n",
        "    num_residuals = num_examples_per_task - num_examples_per_class * config['n_classes']\n",
        "    residuals =  np.sum([(num_examples_per_class - n_c)*(num_examples_per_class > n_c) for n_c in num_per_label])\n",
        "    num_residuals += residuals\n",
        "\n",
        "    # Get the number of coreset instances per class\n",
        "    while True:\n",
        "        n_less_sample_class =  np.sum([(num_examples_per_class > n_c) for n_c in num_per_label])\n",
        "        num_class = (config['n_classes']-n_less_sample_class)\n",
        "        if (num_residuals // num_class) > 0:\n",
        "            num_examples_per_class += (num_residuals // num_class)\n",
        "            num_residuals -= (num_residuals // num_class) * num_class\n",
        "        else:\n",
        "            break\n",
        "    # Get best coresets per class\n",
        "    selected = []\n",
        "    target_tid = np.floor(max(cand_target)/config['n_classes'])\n",
        "\n",
        "    for j in range(config['n_classes']):\n",
        "        position = np.squeeze((cand_target[sorted_index]==j+(target_tid*config['n_classes'])).nonzero())\n",
        "        if position.numel() > 1:\n",
        "            selected.append(position[:num_examples_per_class])\n",
        "        elif position.numel() == 0:\n",
        "            continue\n",
        "        else:\n",
        "            selected.append([position])\n",
        "    # Fill rest space as best residuals\n",
        "    selected = np.concatenate(selected)\n",
        "    unselected = np.array(list(set(np.arange(num_examples_per_task))^set(selected)))\n",
        "    final_num_residuals = num_examples_per_task - len(selected)\n",
        "    best_residuals = unselected[:final_num_residuals]\n",
        "    selected = np.concatenate([selected, best_residuals])\n",
        "\n",
        "    if is_shuffle:\n",
        "        random.shuffle(selected)\n",
        "\n",
        "    return sorted_index[selected.astype(int)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Snn4jL5dJSDP"
      },
      "outputs": [],
      "source": [
        "def select_coreset(loader, task, model, candidates, config, candidate_size=250, fair_selection=True):\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "    temp_optimizer = torch.optim.SGD(model.parameters(), lr=config['seq_lr'], momentum=config['momentum'])\n",
        "    temp_optimizer.zero_grad()\n",
        "\n",
        "    if fair_selection:\n",
        "        # collect candidates\n",
        "        cand_data, cand_target = [], []\n",
        "        cand_size = len(candidates)\n",
        "        for batch_idx, (data, target, task_id) in enumerate(loader['sequential'][task]['train']):\n",
        "            if batch_idx == cand_size:\n",
        "                break\n",
        "            try:\n",
        "                cand_data.append(data[candidates[batch_idx]])\n",
        "                cand_target.append(target[candidates[batch_idx]])\n",
        "            except IndexError:\n",
        "                pass\n",
        "        cand_data = torch.cat(cand_data, 0)\n",
        "        cand_target = torch.cat(cand_target, 0)\n",
        "\n",
        "        random_pick_up = torch.randperm(len(cand_target))[:candidate_size]\n",
        "        cand_data = cand_data[random_pick_up]\n",
        "        cand_target = cand_target[random_pick_up]\n",
        "\n",
        "        num_per_label = [len((cand_target==(jj+config['n_classes']*(task-1))).nonzero()) for jj in range(config['n_classes'])]\n",
        "\n",
        "        num_examples_per_task = config['memory_size'] // task\n",
        "        pred = model(cand_data.to(DEVICE), task)\n",
        "        loss = criterion(pred, cand_target.long().to(DEVICE))\n",
        "        loss.backward()\n",
        "\n",
        "        # Coreset update\n",
        "        _eg = compute_and_flatten_example_grads(model, criterion, cand_data.to(DEVICE), cand_target.long().to(DEVICE), task)\n",
        "        _g = torch.mean(_eg, 0)\n",
        "        sorted = sample_selection(_g, _eg, config)\n",
        "\n",
        "        pick = torch.randperm(len(sorted))\n",
        "        selected = classwise_fair_selection(task, cand_target, pick, num_per_label, config, is_shuffle=True)\n",
        "\n",
        "        loader['coreset'][task]['train'].data = copy.deepcopy(cand_data[selected])\n",
        "        loader['coreset'][task]['train'].targets = copy.deepcopy(cand_target[selected])\n",
        "        num_per_label = [len((cand_target[selected]==(jj+config['n_classes']*(task-1))).nonzero()) for jj in range(config['n_classes'])]\n",
        "    else:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBby5SigNLlX"
      },
      "outputs": [],
      "source": [
        "def reconstruct_coreset_loader(config, dataset, task):\n",
        "    trains = []\n",
        "    all_coreset = {}\n",
        "    for tid in range(1, task+1):\n",
        "        num_examples_per_task = config['memory_size'] // task\n",
        "        coreset = Coreset(num_examples_per_task, input_shape=[3, 32, 32])\n",
        "\n",
        "        pick_idx = torch.randperm(num_examples_per_task)\n",
        "        coreset.data = copy.deepcopy(dataset[tid]['train'].data[pick_idx])\n",
        "        coreset.targets = copy.deepcopy(dataset[tid]['train'].targets[pick_idx])\n",
        "        coreset_loader = torch.utils.data.DataLoader(coreset, batch_size=config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
        "        train_loader = fast_cifar_loader(coreset_loader, tid, eval=False)\n",
        "        if ('cifar' in config['dataset']):\n",
        "            train_loader = fast_cifar_loader(coreset_loader, tid, eval=False)\n",
        "        else:\n",
        "            train_loader = fast_mnist_loader(coreset_loader, eval=False)\n",
        "        trains += train_loader\n",
        "    all_coreset = random.sample(trains[:], len(trains))\n",
        "    return all_coreset\n",
        "\n",
        "\n",
        "def get_coreset_loss(model, iterloader, config):\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "    model.train()\n",
        "    coreset_loss = 0\n",
        "    count = 0\n",
        "    data, target, task_id = iterloader\n",
        "    count += len(target)\n",
        "    data = data.to(DEVICE)\n",
        "    target = target.to(DEVICE)\n",
        "    output = model(data, task_id)\n",
        "    coreset_loss += criterion(output, target.long())\n",
        "    coreset_loss /= count\n",
        "    return coreset_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeXU3AUxKZky"
      },
      "outputs": [],
      "source": [
        "def update_coreset(loader, task, model, task_id, config):\n",
        "    # Coreset update\n",
        "    num_examples_per_task = config['memory_size'] // task\n",
        "    prv_nept = config['memory_size'] // (task-1)\n",
        "\n",
        "    for tid in range(1, task):\n",
        "        criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "        temp_optimizer = torch.optim.SGD(model.parameters(), lr=config['seq_lr'], momentum=config['momentum'])\n",
        "\n",
        "        tid_coreset = loader['coreset'][tid]['train'].data\n",
        "        tid_targets = loader['coreset'][tid]['train'].targets\n",
        "\n",
        "        temp_optimizer.zero_grad()\n",
        "\n",
        "        pred = model(tid_coreset.to(DEVICE), task_id)\n",
        "        loss = criterion(pred, tid_targets.long().to(DEVICE))\n",
        "        loss.backward()\n",
        "        _tid_eg = compute_and_flatten_example_grads(model, criterion, tid_coreset.to(DEVICE), tid_targets.to(DEVICE), tid)\n",
        "        _tid_g = torch.mean(_tid_eg, 0)\n",
        "        pick = sample_selection(_tid_g, _tid_eg, config)\n",
        "\n",
        "        class_idx = [tid_targets.cpu().numpy() == i for i in range(config['n_classes'])]\n",
        "        num_per_label = [len((tid_targets.cpu()==(jj+config['n_classes']*(task-1))).nonzero()) for jj in range(config['n_classes'])]\n",
        "\n",
        "        selected = classwise_fair_selection(task, tid_targets, pick, num_per_label, config)\n",
        "        _nn = [len((tid_targets[selected]==(jj+config['n_classes']*(tid-1))).nonzero()) for jj in range(config['n_classes'])]\n",
        "\n",
        "        loader['coreset'][tid]['train'].data = copy.deepcopy(loader['coreset'][tid]['train'].data[selected])\n",
        "        loader['coreset'][tid]['train'].targets = copy.deepcopy(loader['coreset'][tid]['train'].targets[selected])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dmm8b3uN7IQ"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFjRBJehMozG"
      },
      "outputs": [],
      "source": [
        "def train_single_step(model, optimizer, loader, task, step, config):\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "    is_last_step = True if step == config['n_substeps'] else False\n",
        "    candidates_indices=[]\n",
        "    for batch_idx, (data, target, task_id) in enumerate(loader['sequential'][task]['train']):\n",
        "        model.train()\n",
        "        data = data.to(DEVICE)\n",
        "        target = target.to(DEVICE)\n",
        "        is_ocspick = True if (config['ocspick'] and len(data) > config['batch_size']) else False\n",
        "        optimizer.zero_grad()\n",
        "        if is_ocspick and step != 1:\n",
        "            _eg = compute_and_flatten_example_grads(model, criterion, data, target, task_id)\n",
        "            _g = torch.mean(_eg, 0)\n",
        "            sorted = sample_selection(_g, _eg, config)\n",
        "            pick = sorted[:config['batch_size']]\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(data[pick], task_id)\n",
        "            loss = criterion(pred, target[pick])\n",
        "            loss.backward()\n",
        "\n",
        "            # Select coresets at final step\n",
        "            if is_last_step:\n",
        "                candidates_indices.append(pick)\n",
        "        else:\n",
        "            size = min(len(data), config['batch_size'])\n",
        "            pick = torch.randperm(len(data))[:size]\n",
        "            pred = model(data[pick], task_id)\n",
        "            loss = criterion(pred, target[pick])\n",
        "            loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if is_last_step:\n",
        "        select_coreset(loader, task, model, candidates_indices, config)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAUg7N59Y_Rb"
      },
      "outputs": [],
      "source": [
        "def train_ocs_single_step(model, optimizer, loader, task, step, config):\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "    is_last_step = step == config['n_substeps']\n",
        "\n",
        "    # Concatenate previous task data and targets\n",
        "    prev_coreset = [loader['coreset'][tid]['train'].data for tid in range(1, task)]\n",
        "    prev_targets = [loader['coreset'][tid]['train'].targets for tid in range(1, task)]\n",
        "    c_x = torch.cat(prev_coreset, 0)\n",
        "    c_y = torch.cat(prev_targets, 0)\n",
        "\n",
        "    ref_loader = reconstruct_coreset_loader(config, loader['coreset'], task - 1)\n",
        "    ref_iterloader = itertools.cycle(ref_loader)  # Create an iterator that cycles through ref_loader\n",
        "\n",
        "    candidates_indices = []\n",
        "\n",
        "    for batch_idx, (data, target, task_id) in enumerate(loader['sequential'][task]['train']):\n",
        "        model.eval()\n",
        "        optimizer.zero_grad()\n",
        "        is_rand_start = step == 1\n",
        "\n",
        "        # Compute reference gradients\n",
        "        ref_pred = model(c_x.to(DEVICE), task)\n",
        "        ref_loss = criterion(ref_pred, c_y.long().to(DEVICE))\n",
        "        ref_loss.backward()\n",
        "        ref_grads = copy.deepcopy(flatten_grads(model))\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to(DEVICE)\n",
        "        target = target.to(DEVICE)\n",
        "\n",
        "        if is_rand_start:\n",
        "            size = min(len(data), config['batch_size'])\n",
        "            pick = torch.randperm(len(data))[:size]\n",
        "        else:\n",
        "            # Compute example gradients and select samples\n",
        "            _eg = compute_and_flatten_example_grads(model, criterion, data, target, task_id)\n",
        "            _g = torch.mean(_eg, 0)\n",
        "            sorted_indices = sample_selection(_g.cuda(), _eg.cuda(), config, ref_grads=ref_grads)\n",
        "            pick = sorted_indices[:config['batch_size']]\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(data[pick], task_id)\n",
        "        loss = criterion(pred, target[pick])\n",
        "\n",
        "        ref_data = next(ref_iterloader)\n",
        "        ref_loss = get_coreset_loss(model, ref_data, config)\n",
        "        loss += config['ref_hyp'] * ref_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if is_last_step:\n",
        "            candidates_indices.append(pick)\n",
        "\n",
        "    if is_last_step:\n",
        "        select_coreset(loader, task, model, candidates_indices, config)\n",
        "        update_coreset(loader, task, model, task_id, config)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x6_PYeiJBVr"
      },
      "outputs": [],
      "source": [
        "def eval_single_epoch(model, loader, config):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "    total_loss, correct, total_samples = 0.0, 0, 0\n",
        "\n",
        "    class_correct = np.zeros(config['n_classes'])\n",
        "    class_total = np.zeros(config['n_classes'])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target, task_id in loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data, task_id)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            total_loss += loss.item() * len(target)\n",
        "            total_samples += len(target)\n",
        "\n",
        "            preds = output.argmax(dim=1)\n",
        "            correct += (preds == target).sum().item()\n",
        "\n",
        "            for cid in range(config['n_classes']):\n",
        "                cid_index = (target == cid) if 'cifar' not in config['dataset'] else (target == cid + (task_id - 1) * config['n_classes'])\n",
        "                class_correct[cid] += (preds == target)[cid_index].sum().item()\n",
        "                class_total[cid] += cid_index.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    avg_acc = 100.0 * correct / total_samples\n",
        "    per_class_acc = [round(100.0 * a / b, 4) if b > 0 else 0.0 for a, b in zip(class_correct, class_total)]\n",
        "\n",
        "    return {'accuracy': avg_acc, 'per_class_accuracy': per_class_acc, 'loss': avg_loss}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-SoOeeAJBac"
      },
      "outputs": [],
      "source": [
        "def train_task_sequentially(task, train_loader, config, summary=None):\n",
        "    current_lr = config['seq_lr'] * (config['lr_decay'])**(task-1)\n",
        "    prev_model_path = f\"./checkpoints/{config['dataset']}/init.pth\"\n",
        "    model = load_model(prev_model_path).to(DEVICE)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=current_lr, momentum=config['momentum'])\n",
        "    config['n_substeps'] = int((config['stream_size'] / config['batch_size']))\n",
        "    for _step in range(1, config['n_substeps']+1):\n",
        "        if task == 1 or (config['ocspick'] == False):\n",
        "            model = train_single_step(model, optimizer, train_loader, task, _step, config)\n",
        "        else:\n",
        "            model = train_ocs_single_step(model, optimizer, train_loader, task, _step, config)\n",
        "        metrics = eval_single_epoch(model, train_loader['sequential'][task]['val'], config)\n",
        "        print('Epoch {} >> (per-task accuracy): {}'.format(_step/config['n_substeps'], np.mean(metrics['accuracy'])))\n",
        "        print('Epoch {} >> (class accuracy): {}'.format(_step/config['n_substeps'], metrics['per_class_accuracy']))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezF-AAyIODvU"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zRoLVvjZJa4"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Two layer MLP for MNIST benchmarks.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "        self.save_acts = False\n",
        "        self.acts = {}\n",
        "        self.config = config\n",
        "        self.W1 = nn.Linear(784, config['mlp_hiddens'])\n",
        "        self.dropout_1 =  nn.Dropout(p=config['dropout'])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.W2 = nn.Linear(config['mlp_hiddens'], config['mlp_hiddens'])\n",
        "        self.dropout_2 =  nn.Dropout(p=config['dropout'])\n",
        "\n",
        "        self.W3 = nn.Linear(config['mlp_hiddens'], 10)\n",
        "        # self.dropout_p = config['dropout']\n",
        "\n",
        "    def embed(self, x):\n",
        "        out = self.W1(x)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        if self.save_acts:\n",
        "            self.acts['layer 1'] = out.detach().clone()\n",
        "\n",
        "        if self.config['dropout'] > 0:\n",
        "            out = self.dropout_1(out)\n",
        "        out = self.W2(out)\n",
        "        self.feature = self.relu(out)\n",
        "        if self.save_acts:\n",
        "            self.acts['layer 2'] = self.feature.detach().clone()\n",
        "        if self.config['dropout'] > 0:\n",
        "            out = self.dropout_2(self.feature)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def forward(self, x, task_id=None):\n",
        "        # x = x.view(-1, 784 + self.num_condition_neurons)\n",
        "        out = self.embed(x)\n",
        "        out = self.W3(self.feature)\n",
        "        # out = nn.functional.dropout(out, p=self.dropout_p)\n",
        "        return out\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, config={}):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "            )\n",
        "        self.IC1 = nn.Sequential(\n",
        "            nn.BatchNorm2d(planes, track_running_stats=False),\n",
        "            nn.Dropout(p=config['dropout'])\n",
        "            )\n",
        "\n",
        "        self.IC2 = nn.Sequential(\n",
        "            nn.BatchNorm2d(planes, track_running_stats=False),\n",
        "            nn.Dropout(p=config['dropout'])\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = relu(out)\n",
        "        out = self.IC1(out)\n",
        "\n",
        "        out += self.shortcut(x)\n",
        "        out = relu(out)\n",
        "        out = self.IC2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes, nf, config={}):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = nf\n",
        "        self.conv1 = conv3x3(3, nf * 1)\n",
        "        self.bn1 = nn.BatchNorm2d(nf * 1, track_running_stats=False)\n",
        "        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1, config=config)\n",
        "        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2, config=config)\n",
        "        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2, config=config)\n",
        "        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2, config=config)\n",
        "        self.linear = nn.Linear(nf * 8 * block.expansion, num_classes)\n",
        "        self.config =config\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride, config):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, config=config))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def embed(self, x):\n",
        "        bsz = x.size(0)\n",
        "        out = relu(self.bn1(self.conv1(x.view(bsz, 3, 32, 32))))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out\n",
        "\n",
        "    def forward(self, x, task_id):\n",
        "        out = self.embed(x)\n",
        "        out = self.linear(out)\n",
        "        t = task_id\n",
        "        if isinstance(self.config['n_classes'], int):\n",
        "            offset1 = int((t-1) * 5)\n",
        "            offset2 = int(t * 5)\n",
        "            if offset1 > 0:\n",
        "                out[:, :offset1].data.fill_(-10e10)\n",
        "            if offset2 < 100:\n",
        "                out[:, offset2:100].data.fill_(-10e10)\n",
        "            return out\n",
        "        else:\n",
        "            offsets = [sum(self.config['n_classes'][:c]) for c in range(1,len(self.config['n_classes'])+1)]\n",
        "            offset1 = int(offsets[t-1])\n",
        "            offset2 = int(offsets[t])\n",
        "            if offset1 > 0:\n",
        "                out[:, :offset1].data.fill_(-10e10)\n",
        "            if offset2 < offsets[-1]:\n",
        "                out[:, offset2:offsets[-1]].data.fill_(-10e10)\n",
        "            return out\n",
        "\n",
        "def ResNet18(nclasses=100, nf=20, config={}):\n",
        "    net = ResNet(BasicBlock, [2, 2, 2, 2], nclasses, nf, config=config)\n",
        "    return net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH8_iqekvhB_"
      },
      "source": [
        "# ِDataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoSoZlax78ME"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAQ0JaJYy_qI"
      },
      "outputs": [],
      "source": [
        "class RotationTransform:\n",
        "    def __init__(self, angle):\n",
        "        self.angle = angle\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return TorchVisionFunc.rotate(x, self.angle, fill=(0,))\n",
        "\n",
        "def fast_mnist_loader(loaders, eval=True, device='cpu'):\n",
        "    trains, evals = [], []\n",
        "    if eval:\n",
        "        train_loader, eval_loader = loaders\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device).view(-1, 784)\n",
        "            target = target.to(device)\n",
        "            trains.append([data, target, None])\n",
        "\n",
        "        for data, target in eval_loader:\n",
        "            data = data.to(device).view(-1, 784)\n",
        "            target = target.to(device)\n",
        "            evals.append([data, target, None])\n",
        "        return trains, evals\n",
        "    else:\n",
        "        train_loader = loaders\n",
        "\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device).view(-1, 784)\n",
        "            target = target.to(device)\n",
        "            trains.append([data, target, None])\n",
        "        return trains\n",
        "\n",
        "def get_balanced_noisy_rotated_mnist(task_id, batch_size, per_task_rotation):\n",
        "    print('Noisy Rotated MNIST')\n",
        "    rotation_degree = (task_id - 1)*per_task_rotation\n",
        "\n",
        "    train_transforms = torchvision.transforms.Compose([\n",
        "        RotationTransform(rotation_degree),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    test_transforms = torchvision.transforms.Compose([\n",
        "        RotationTransform(rotation_degree),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    train_dataset = MNIST('./data/', train=True, download=True, transform=train_transforms)\n",
        "    test_dataset = MNIST('./data/', train=False, download=True, transform=test_transforms)\n",
        "    end_idx = int(len(train_dataset.data) * 0.6)\n",
        "    shuffle = torch.randperm(len(train_dataset.data))\n",
        "    idx = shuffle[:end_idx].long()\n",
        "    for i in idx:\n",
        "        train_dataset.data[i] = torch.randn(train_dataset.data[i].size())\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "    test_loader = torch.utils.data.DataLoader(MNIST('./data/', train=False, download=True, transform=test_transforms),  batch_size=256, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def get_rotated_mnist(task_id, batch_size, per_task_rotation):\n",
        "    print('Rotated MNIST')\n",
        "    rotation_degree = (task_id - 1)*per_task_rotation\n",
        "\n",
        "    transforms = torchvision.transforms.Compose([\n",
        "        RotationTransform(rotation_degree),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(MNIST('./data/', train=True, download=True, transform=transforms), batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "    test_loader = torch.utils.data.DataLoader(MNIST('./data/', train=False, download=True, transform=transforms),  batch_size=256, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oJhQZTR8LyR"
      },
      "source": [
        "# CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7ce1yYKvgfx"
      },
      "outputs": [],
      "source": [
        "def fast_cifar_loader(loaders, task_id, eval=True, device='cpu'):\n",
        "    trains, evals = [], []\n",
        "    if eval:\n",
        "        train_loader, eval_loader = loaders\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            trains.append([data, target, task_id])\n",
        "\n",
        "        for data, target in eval_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            evals.append([data, target, task_id])\n",
        "        return trains, evals\n",
        "    else:\n",
        "        for data, target in loaders:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            trains.append([data, target, task_id])\n",
        "        return trains\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "def get_split_cifar100(task_id, batch_size, cifar_train, cifar_test):\n",
        "    # Calculate class range for the task\n",
        "    start_class = (task_id - 1) * 5\n",
        "    end_class = task_id * 5\n",
        "\n",
        "    # Get indices of samples belonging to the current task's classes\n",
        "    train_indices = np.where((np.array(cifar_train.targets) >= start_class) &\n",
        "                             (np.array(cifar_train.targets) < end_class))[0]\n",
        "\n",
        "    test_indices = np.where((np.array(cifar_test.targets) >= start_class) &\n",
        "                            (np.array(cifar_test.targets) < end_class))[0]\n",
        "\n",
        "    # Create DataLoader for the training and testing subsets\n",
        "    train_loader = DataLoader(Subset(cifar_train, train_indices),\n",
        "                              batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(Subset(cifar_test, test_indices),\n",
        "                             batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def get_imbalanced_split_cifar100(task_id, batch_size, cifar_train, cifar_test):\n",
        "    # Predefined shuffle of classes to introduce imbalance\n",
        "    class_shuffle = [25, 11, 23, 76, 12, 30, 62,  6, 89, 44, 84, 29, 82,  3, 10, 24, 64, 72,\n",
        "                     21,  8, 63, 71, 68, 74,  5, 86, 22, 58, 95, 19, 47, 54, 56,  2, 20, 96,\n",
        "                     57, 38, 80, 66,  1, 59, 16, 97, 18, 73, 31, 77, 99, 15, 46, 27, 83, 40,\n",
        "                     48, 88, 33, 36, 81, 55, 85, 14, 13,  7, 65, 50, 78, 43, 91,  4, 69, 52,\n",
        "                     41, 94, 34, 51, 37,  9, 90, 35, 92, 26, 42,  0, 17, 87, 53, 93, 32, 28,\n",
        "                     75, 67, 49, 79, 61, 60, 70, 98, 45, 39]\n",
        "\n",
        "    n_class = 100\n",
        "    img_max = len(cifar_train.targets) // n_class\n",
        "    imb_factor = 1 / 10.\n",
        "\n",
        "    # Create imbalanced indices for training data\n",
        "    indices_per_class = []\n",
        "    for class_number in range(n_class):\n",
        "        class_indices = np.where(np.array(cifar_train.targets) == class_shuffle[class_number])[0]\n",
        "        num_samples = int(img_max * (imb_factor ** (class_number / (n_class - 1))))\n",
        "        indices_per_class.append(class_indices[:num_samples])\n",
        "\n",
        "    imbalanced_indices = np.concatenate(indices_per_class)\n",
        "    np.random.shuffle(imbalanced_indices)\n",
        "\n",
        "    # Create a new imbalanced CIFAR-100 training set\n",
        "    cifar_train_new = copy.deepcopy(cifar_train)\n",
        "    cifar_train_new.data = cifar_train.data[imbalanced_indices]\n",
        "    cifar_train_new.targets = [cifar_train.targets[i] for i in imbalanced_indices]\n",
        "\n",
        "    # Determine class range for the current task\n",
        "    start_class = (task_id - 1) * 5\n",
        "    end_class = task_id * 5\n",
        "\n",
        "    # Get indices for the current task's classes\n",
        "    train_indices = [i for i, target in enumerate(cifar_train_new.targets) if start_class <= target < end_class]\n",
        "    test_indices = [i for i, target in enumerate(cifar_test.targets) if start_class <= target < end_class]\n",
        "\n",
        "    # Create DataLoaders for the current task\n",
        "    train_loader = DataLoader(Subset(cifar_train_new, train_indices), batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(Subset(cifar_test, test_indices), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    print('Imbalanced SplitCifar100')\n",
        "    if task_id == 1:\n",
        "        print('Number of instances per class:', [len(indices) for indices in indices_per_class])\n",
        "    current_task_targets = np.array(cifar_train_new.targets)[train_indices]\n",
        "    print('Number of instances per class for task {}: {}'.format(\n",
        "        task_id, [np.sum(current_task_targets == c) for c in range(start_class, end_class)]\n",
        "    ))\n",
        "\n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwoXYfV88ga9"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkbVYHou8l6R"
      },
      "outputs": [],
      "source": [
        "class Coreset(torch.utils.data.Dataset):\n",
        "    def __init__(self, set_size, input_shape=[784]):\n",
        "        data_shape = [set_size] + input_shape\n",
        "\n",
        "        self.data = torch.zeros(data_shape)\n",
        "        self.targets = torch.ones((set_size)) * -1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx]\n",
        "        y = self.targets[idx]\n",
        "        return x, y\n",
        "\n",
        "\n",
        "def get_all_loaders(config, per_task_rotation=9, is_coreset=True):\n",
        "\n",
        "    dataset = config['dataset'].lower()\n",
        "    loaders = {'sequential': {}, 'coreset': {}}\n",
        "    class_arr = range(0, 100)\n",
        "\n",
        "    cifar_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),])\n",
        "    cifar_train = torchvision.datasets.CIFAR100('./data/', train=True, download=True, transform=cifar_transforms)\n",
        "    cifar_test = torchvision.datasets.CIFAR100('./data/', train=False, download=True, transform=cifar_transforms)\n",
        "    if is_coreset:\n",
        "        print('loading coreset placeholder {}'.format(dataset))\n",
        "        for task in range(1, config['num_tasks']+1):\n",
        "            loaders['sequential'][task], loaders['coreset'][task] = {}, {}\n",
        "            print(\"loading {} for task {}\".format(dataset, task))\n",
        "            num_example_per_task = config['memory_size']//task\n",
        "            classes = np.random.choice(class_arr, 5, replace=False)\n",
        "            if 'mnist' in dataset:\n",
        "              if 'noisy' in dataset:\n",
        "                  seq_loader_train , seq_loader_val = fast_mnist_loader(get_balanced_noisy_rotated_mnist(task, config['stream_size'], per_task_rotation), 'cpu')\n",
        "              else:\n",
        "                  seq_loader_train , seq_loader_val = fast_mnist_loader(get_rotated_mnist(task, config['stream_size'], per_task_rotation), 'cpu')\n",
        "              loaders['coreset'][task]['train'] = Coreset(num_example_per_task)\n",
        "            if 'cifar' in dataset:\n",
        "              if 'imb' in dataset:\n",
        "                  seq_loader_train , seq_loader_val = fast_cifar_loader(get_imbalanced_split_cifar100(task, config['stream_size'], cifar_train, cifar_test), task, 'cpu')\n",
        "              else:\n",
        "                  seq_loader_train , seq_loader_val = fast_cifar_loader(get_split_cifar100(task, config['stream_size'], cifar_train, cifar_test), task, 'cpu')\n",
        "              loaders['coreset'][task]['train'] = Coreset(num_example_per_task, [3, 32, 32])\n",
        "            loaders['sequential'][task]['train'], loaders['sequential'][task]['val'] = seq_loader_train, seq_loader_val\n",
        "\n",
        "        return loaders\n",
        "    else:\n",
        "        # Load sequential tasks\n",
        "\n",
        "\n",
        "        for task in range(1, config['num_tasks']+1):\n",
        "            loaders['sequential'][task] = {}\n",
        "            print(\"loading {} for task {}\".format(dataset, task))\n",
        "            if 'noisy' in dataset:\n",
        "                seq_loader_train , seq_loader_val = fast_mnist_loader(get_balanced_noisy_rotated_mnist(task, config['stream_size'], per_task_rotation), 'cpu')\n",
        "            elif 'mnist' in dataset:\n",
        "               seq_loader_train , seq_loader_val = fast_mnist_loader(get_rotated_mnist(task, config['stream_size'], per_task_rotation), 'cpu')\n",
        "            elif 'imb' in dataset:\n",
        "                seq_loader_train , seq_loader_val = fast_cifar_loader(get_imbalanced_split_cifar100(task, config['stream_size'], cifar_train, cifar_test), task, 'cpu')\n",
        "            else:\n",
        "                seq_loader_train , seq_loader_val = fast_cifar_loader(get_split_cifar100(task, config['stream_size'], cifar_train, cifar_test), task, 'cpu')\n",
        "            seq_loader_train , seq_loader_val = fast_cifar_loader(get_split_cifar100(task, config['stream_size'], cifar_train, cifar_test), task, 'cpu')\n",
        "            loaders['sequential'][task]['train'], loaders['sequential'][task]['val'] = seq_loader_train, seq_loader_val\n",
        "        return loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTQY_o0Fz8sO",
        "outputId": "d8f019bd-3519-4551-d491-7ce40a1da289"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "loading coreset placeholder rot-mnist\n",
            "loading rot-mnist for task 1\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 2\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 3\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 4\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 5\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 6\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 7\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 8\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 9\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 10\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 11\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 12\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 13\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 14\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 15\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 16\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 17\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 18\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 19\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 20\n",
            "Rotated MNIST\n",
            "---- Task 1 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 83.46\n",
            "Epoch 0.2 >> (class accuracy): [92.9592, 96.0352, 72.093, 85.4455, 63.1365, 81.9507, 82.1503, 84.6304, 84.5996, 89.7919]\n",
            "Epoch 0.4 >> (per-task accuracy): 90.35\n",
            "Epoch 0.4 >> (class accuracy): [96.2245, 97.7974, 80.7171, 87.4257, 91.9552, 87.4439, 89.4572, 87.2568, 92.1971, 92.2696]\n",
            "Epoch 0.6 >> (per-task accuracy): 92.98\n",
            "Epoch 0.6 >> (class accuracy): [96.2245, 98.8546, 86.7248, 90.297, 95.0102, 93.8341, 93.6326, 91.6342, 91.1704, 92.0714]\n",
            "Epoch 0.8 >> (per-task accuracy): 94.83\n",
            "Epoch 0.8 >> (class accuracy): [97.6531, 98.9427, 91.5698, 94.0594, 96.5377, 96.0762, 95.0939, 92.9961, 92.7105, 92.4678]\n",
            "Epoch 1.0 >> (per-task accuracy): 95.6\n",
            "Epoch 1.0 >> (class accuracy): [98.2653, 98.9427, 93.7984, 94.8515, 97.4542, 96.7489, 94.8852, 94.0661, 94.0452, 92.7651]\n",
            "OCS >> Task 1: {'accuracy': 95.6, 'per_class_accuracy': [98.2653, 98.9427, 93.7984, 94.8515, 97.4542, 96.7489, 94.8852, 94.0661, 94.0452, 92.7651], 'loss': 0.16567434660196304}\n",
            "OCS >> (average accuracy): 95.6\n",
            "OCS >> (Forgetting): 0.0\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 2 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 86.14\n",
            "Epoch 0.2 >> (class accuracy): [96.0204, 98.0617, 78.1008, 85.9406, 89.8167, 77.13, 92.38, 87.4514, 75.77, 78.6918]\n",
            "Epoch 0.4 >> (per-task accuracy): 87.19\n",
            "Epoch 0.4 >> (class accuracy): [94.5918, 98.5022, 83.0426, 91.1881, 88.2892, 75.8969, 90.7098, 86.5759, 73.2033, 87.2151]\n",
            "Epoch 0.6 >> (per-task accuracy): 88.61\n",
            "Epoch 0.6 >> (class accuracy): [97.2449, 98.1498, 82.9457, 91.9802, 88.0855, 80.157, 92.4843, 87.1595, 76.8994, 88.999]\n",
            "Epoch 0.8 >> (per-task accuracy): 89.44\n",
            "Epoch 0.8 >> (class accuracy): [96.7347, 97.9736, 83.2364, 92.8713, 89.1039, 82.8475, 93.3194, 89.0078, 77.3101, 90.2874]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1750/1459498902.py:12: RuntimeWarning: divide by zero encountered in scalar floor_divide\n",
            "  if (num_residuals // num_class) > 0:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1.0 >> (per-task accuracy): 90.03\n",
            "Epoch 1.0 >> (class accuracy): [97.7551, 98.4141, 85.7558, 93.6634, 88.9002, 81.6143, 93.0063, 89.2996, 78.6448, 91.2785]\n",
            "OCS >> Task 1: {'accuracy': 89.16, 'per_class_accuracy': [96.9388, 96.7401, 84.1085, 93.3663, 90.3259, 78.2511, 94.1545, 88.9105, 79.5688, 87.3142], 'loss': 0.3896568247616291}\n",
            "OCS >> Task 2: {'accuracy': 90.03, 'per_class_accuracy': [97.7551, 98.4141, 85.7558, 93.6634, 88.9002, 81.6143, 93.0063, 89.2996, 78.6448, 91.2785], 'loss': 0.34185475299954415}\n",
            "OCS >> (average accuracy): 89.595\n",
            "OCS >> (Forgetting): 0.06439999999999997\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 3 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 83.78\n",
            "Epoch 0.2 >> (class accuracy): [95.8163, 98.1498, 74.2248, 85.4455, 74.4399, 70.0673, 90.8142, 88.1323, 77.5154, 80.1784]\n",
            "Epoch 0.4 >> (per-task accuracy): 85.25\n",
            "Epoch 0.4 >> (class accuracy): [97.0408, 96.3877, 73.8372, 89.1089, 87.9837, 81.0538, 87.5783, 80.642, 75.8727, 81.665]\n",
            "Epoch 0.6 >> (per-task accuracy): 86.49\n",
            "Epoch 0.6 >> (class accuracy): [98.3673, 95.9471, 78.1008, 88.1188, 90.4277, 81.1659, 89.0397, 79.1829, 81.5195, 81.9623]\n",
            "Epoch 0.8 >> (per-task accuracy): 88.36\n",
            "Epoch 0.8 >> (class accuracy): [98.2653, 95.3304, 81.8798, 91.4851, 91.8534, 81.9507, 92.0668, 82.393, 82.2382, 85.1338]\n",
            "Epoch 1.0 >> (per-task accuracy): 88.77\n",
            "Epoch 1.0 >> (class accuracy): [97.8571, 96.7401, 83.0426, 88.8119, 92.8717, 84.417, 91.1273, 82.5875, 82.3409, 86.9177]\n",
            "OCS >> Task 1: {'accuracy': 83.93, 'per_class_accuracy': [96.7347, 85.9912, 77.907, 82.5743, 92.5662, 80.6054, 91.1273, 80.7393, 72.7926, 78.3944], 'loss': 0.602496665096283}\n",
            "OCS >> Task 2: {'accuracy': 88.4, 'per_class_accuracy': [96.8367, 95.3304, 83.9147, 87.8218, 91.8534, 84.3049, 93.9457, 83.6576, 80.0821, 85.4311], 'loss': 0.4038702524423599}\n",
            "OCS >> Task 3: {'accuracy': 88.77, 'per_class_accuracy': [97.8571, 96.7401, 83.0426, 88.8119, 92.8717, 84.417, 91.1273, 82.5875, 82.3409, 86.9177], 'loss': 0.38937614521980285}\n",
            "OCS >> (average accuracy): 87.03333333333335\n",
            "OCS >> (Forgetting): 0.09434999999999988\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 4 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 79.48\n",
            "Epoch 0.2 >> (class accuracy): [95.0, 95.859, 62.5, 89.3069, 67.5153, 53.8117, 88.4134, 84.6304, 73.8193, 79.5837]\n",
            "Epoch 0.4 >> (per-task accuracy): 82.21\n",
            "Epoch 0.4 >> (class accuracy): [96.6327, 86.0793, 71.6085, 87.0297, 77.5967, 82.0628, 89.2484, 78.7938, 65.8111, 87.116]\n",
            "Epoch 0.6 >> (per-task accuracy): 84.36\n",
            "Epoch 0.6 >> (class accuracy): [96.4286, 88.1057, 78.7791, 88.6139, 90.835, 84.7534, 91.3361, 73.8327, 73.1006, 78.1962]\n",
            "Epoch 0.8 >> (per-task accuracy): 85.81\n",
            "Epoch 0.8 >> (class accuracy): [96.9388, 86.2555, 78.5853, 89.0099, 90.224, 85.9865, 89.7704, 78.3074, 79.9795, 83.7463]\n",
            "Epoch 1.0 >> (per-task accuracy): 86.1\n",
            "Epoch 1.0 >> (class accuracy): [97.1429, 88.1057, 83.3333, 89.703, 90.5295, 88.9013, 90.9186, 81.0311, 71.7659, 79.9802]\n",
            "OCS >> Task 1: {'accuracy': 76.55, 'per_class_accuracy': [97.6531, 77.2687, 67.2481, 76.9307, 85.8452, 71.5247, 86.2213, 76.6537, 67.1458, 59.5639], 'loss': 0.8959437033653259}\n",
            "OCS >> Task 2: {'accuracy': 84.87, 'per_class_accuracy': [97.8571, 91.9824, 79.5543, 86.0396, 88.7984, 82.3991, 91.6493, 82.7821, 75.5647, 71.556], 'loss': 0.5368551463127136}\n",
            "OCS >> Task 3: {'accuracy': 87.9, 'per_class_accuracy': [98.0612, 94.185, 83.9147, 90.495, 91.1405, 86.7713, 93.5282, 85.4086, 77.6181, 77.4034], 'loss': 0.412593000793457}\n",
            "OCS >> Task 4: {'accuracy': 86.1, 'per_class_accuracy': [97.1429, 88.1057, 83.3333, 89.703, 90.5295, 88.9013, 90.9186, 81.0311, 71.7659, 79.9802], 'loss': 0.47548677072525025}\n",
            "OCS >> (average accuracy): 83.855\n",
            "OCS >> (Forgetting): 0.12493333333333326\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 5 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 75.89\n",
            "Epoch 0.2 >> (class accuracy): [93.8776, 96.4758, 60.562, 81.2871, 77.3931, 29.8206, 83.0898, 84.2412, 76.8994, 68.4836]\n",
            "Epoch 0.4 >> (per-task accuracy): 77.07\n",
            "Epoch 0.4 >> (class accuracy): [92.0408, 85.1101, 72.6744, 73.3663, 76.6802, 76.2332, 78.81, 77.1401, 57.5975, 79.8811]\n",
            "Epoch 0.6 >> (per-task accuracy): 78.29\n",
            "Epoch 0.6 >> (class accuracy): [93.0612, 77.533, 72.1899, 83.4653, 75.9674, 82.1749, 83.9248, 77.1401, 55.7495, 82.2597]\n",
            "Epoch 0.8 >> (per-task accuracy): 79.19\n",
            "Epoch 0.8 >> (class accuracy): [95.6122, 71.8062, 68.6047, 87.6238, 83.4012, 82.1749, 89.2484, 80.0584, 54.9281, 80.1784]\n",
            "Epoch 1.0 >> (per-task accuracy): 80.91\n",
            "Epoch 1.0 >> (class accuracy): [93.1633, 78.1498, 68.314, 83.2673, 86.8635, 84.7534, 89.2484, 82.7821, 63.7577, 80.1784]\n",
            "OCS >> Task 1: {'accuracy': 73.3, 'per_class_accuracy': [95.9184, 73.5683, 64.9225, 73.6634, 85.5397, 67.713, 83.1942, 79.0856, 51.3347, 58.1764], 'loss': 0.9628176555633545}\n",
            "OCS >> Task 2: {'accuracy': 81.79, 'per_class_accuracy': [95.0, 90.4846, 73.6434, 82.5743, 86.8635, 78.5874, 88.4134, 84.7276, 65.1951, 71.3578], 'loss': 0.6122803822517395}\n",
            "OCS >> Task 3: {'accuracy': 84.91, 'per_class_accuracy': [94.2857, 94.6256, 77.3256, 85.9406, 88.2892, 82.287, 89.7704, 87.5486, 72.2793, 75.5203], 'loss': 0.47513540477752686}\n",
            "OCS >> Task 4: {'accuracy': 84.71, 'per_class_accuracy': [93.3673, 91.3656, 77.4225, 85.8416, 88.391, 86.2108, 89.666, 85.0195, 69.1992, 80.1784], 'loss': 0.47810675182342527}\n",
            "OCS >> Task 5: {'accuracy': 80.91, 'per_class_accuracy': [93.1633, 78.1498, 68.314, 83.2673, 86.8635, 84.7534, 89.2484, 82.7821, 63.7577, 80.1784], 'loss': 0.5901836193561554}\n",
            "OCS >> (average accuracy): 81.124\n",
            "OCS >> (Forgetting): 0.14422499999999996\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 6 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 70.13\n",
            "Epoch 0.2 >> (class accuracy): [96.7347, 94.7137, 68.5078, 75.7426, 74.6436, 0.1121, 69.7286, 76.751, 66.8378, 66.997]\n",
            "Epoch 0.4 >> (per-task accuracy): 66.2\n",
            "Epoch 0.4 >> (class accuracy): [86.2245, 69.4273, 58.7209, 61.4851, 56.0081, 61.9955, 70.6681, 55.8366, 62.115, 79.3855]\n",
            "Epoch 0.6 >> (per-task accuracy): 69.08\n",
            "Epoch 0.6 >> (class accuracy): [88.7755, 56.652, 69.6705, 62.7723, 70.6721, 68.4978, 74.4259, 58.3658, 61.3963, 81.8632]\n",
            "Epoch 0.8 >> (per-task accuracy): 72.85\n",
            "Epoch 0.8 >> (class accuracy): [91.8367, 53.4802, 73.2558, 66.9307, 80.4481, 75.0, 85.4906, 60.7977, 65.2977, 79.9802]\n",
            "Epoch 1.0 >> (per-task accuracy): 74.7\n",
            "Epoch 1.0 >> (class accuracy): [93.5714, 54.6256, 78.0039, 69.604, 82.7902, 75.2242, 85.8038, 63.2296, 67.7618, 80.1784]\n",
            "OCS >> Task 1: {'accuracy': 68.33, 'per_class_accuracy': [96.1224, 75.5947, 60.0775, 57.6238, 81.1609, 62.5561, 80.167, 75.6809, 39.2197, 54.3112], 'loss': 1.0675324736595153}\n",
            "OCS >> Task 2: {'accuracy': 77.31, 'per_class_accuracy': [96.4286, 91.0132, 68.314, 71.0891, 84.0122, 72.1973, 85.3862, 81.5175, 53.3881, 67.889], 'loss': 0.7392601832389831}\n",
            "OCS >> Task 3: {'accuracy': 80.83, 'per_class_accuracy': [96.5306, 94.0969, 73.4496, 75.8416, 85.2342, 74.3274, 87.0564, 81.2257, 65.8111, 72.8444], 'loss': 0.5980171394824981}\n",
            "OCS >> Task 4: {'accuracy': 82.31, 'per_class_accuracy': [95.5102, 89.6035, 79.4574, 77.3267, 86.3544, 78.6996, 88.6221, 78.3074, 67.8645, 80.4757], 'loss': 0.559645825958252}\n",
            "OCS >> Task 5: {'accuracy': 80.16, 'per_class_accuracy': [95.102, 72.8634, 80.4264, 75.5446, 85.4379, 78.9238, 88.2046, 73.7354, 70.3285, 82.557], 'loss': 0.6287443470954895}\n",
            "OCS >> Task 6: {'accuracy': 74.7, 'per_class_accuracy': [93.5714, 54.6256, 78.0039, 69.604, 82.7902, 75.2242, 85.8038, 63.2296, 67.7618, 80.1784], 'loss': 0.8397433954715728}\n",
            "OCS >> (average accuracy): 77.27333333333333\n",
            "OCS >> (Forgetting): 0.17811999999999995\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 7 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 53.51\n",
            "Epoch 0.2 >> (class accuracy): [95.8163, 83.1718, 47.5775, 75.7426, 2.7495, 5.2691, 87.6827, 0.0, 36.1396, 93.7562]\n",
            "Epoch 0.4 >> (per-task accuracy): 60.85\n",
            "Epoch 0.4 >> (class accuracy): [82.6531, 73.2159, 49.1279, 55.1485, 50.4073, 52.4664, 70.4593, 35.6031, 61.6016, 76.9078]\n",
            "Epoch 0.6 >> (per-task accuracy): 64.42\n",
            "Epoch 0.6 >> (class accuracy): [83.1633, 57.9736, 65.8915, 47.3267, 61.2016, 61.7713, 75.8873, 52.0428, 61.499, 79.0882]\n",
            "Epoch 0.8 >> (per-task accuracy): 67.74\n",
            "Epoch 0.8 >> (class accuracy): [89.2857, 57.9736, 65.0194, 55.1485, 63.6456, 70.5157, 84.5511, 51.6537, 60.7803, 81.8632]\n",
            "Epoch 1.0 >> (per-task accuracy): 68.69\n",
            "Epoch 1.0 >> (class accuracy): [91.9388, 52.6872, 69.186, 53.0693, 70.1629, 72.4215, 83.9248, 50.1946, 64.7844, 82.6561]\n",
            "OCS >> Task 1: {'accuracy': 66.55, 'per_class_accuracy': [94.7959, 74.978, 59.3992, 56.5347, 75.8656, 60.8744, 77.8706, 71.8872, 40.4517, 51.9326], 'loss': 1.0792525764465333}\n",
            "OCS >> Task 2: {'accuracy': 74.71, 'per_class_accuracy': [94.5918, 90.5727, 66.1822, 69.505, 78.3096, 69.2825, 82.5678, 78.3074, 49.384, 66.1051], 'loss': 0.8054843185424805}\n",
            "OCS >> Task 3: {'accuracy': 77.48, 'per_class_accuracy': [95.3061, 95.4185, 67.8295, 74.3564, 79.4297, 70.4036, 84.7599, 78.8911, 55.8522, 69.8712], 'loss': 0.6933236022472382}\n",
            "OCS >> Task 4: {'accuracy': 79.34, 'per_class_accuracy': [94.898, 94.185, 69.9612, 74.0594, 81.9756, 75.3363, 86.952, 76.07, 61.6016, 76.6105], 'loss': 0.6401861485958099}\n",
            "OCS >> Task 5: {'accuracy': 78.68, 'per_class_accuracy': [93.9796, 87.2247, 71.3178, 71.6832, 80.0407, 76.2332, 87.0564, 72.9572, 66.3244, 79.3855], 'loss': 0.653832585144043}\n",
            "OCS >> Task 6: {'accuracy': 74.22, 'per_class_accuracy': [92.3469, 68.37, 68.314, 65.0495, 76.6802, 76.3453, 86.2213, 64.2023, 68.5832, 78.3944], 'loss': 0.7922158427238465}\n",
            "OCS >> Task 7: {'accuracy': 68.69, 'per_class_accuracy': [91.9388, 52.6872, 69.186, 53.0693, 70.1629, 72.4215, 83.9248, 50.1946, 64.7844, 82.6561], 'loss': 1.0143059120178222}\n",
            "OCS >> (average accuracy): 74.23857142857143\n",
            "OCS >> (Forgetting): 0.2043666666666666\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 8 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 36.63\n",
            "Epoch 0.2 >> (class accuracy): [96.1224, 20.8811, 41.8605, 0.6931, 28.9206, 0.0, 88.2046, 10.5058, 9.0349, 71.3578]\n",
            "Epoch 0.4 >> (per-task accuracy): 54.75\n",
            "Epoch 0.4 >> (class accuracy): [80.7143, 61.1454, 52.0349, 33.9604, 50.8147, 50.0, 53.2359, 19.2607, 65.1951, 81.4668]\n",
            "Epoch 0.6 >> (per-task accuracy): 57.43\n",
            "Epoch 0.6 >> (class accuracy): [84.7959, 39.3833, 65.9884, 33.0693, 59.0631, 58.0717, 70.4593, 42.4125, 51.1294, 73.6373]\n",
            "Epoch 0.8 >> (per-task accuracy): 60.62\n",
            "Epoch 0.8 >> (class accuracy): [75.6122, 42.9075, 61.4341, 33.8614, 67.2098, 71.1883, 81.4196, 55.3502, 43.3265, 78.4936]\n",
            "Epoch 1.0 >> (per-task accuracy): 61.57\n",
            "Epoch 1.0 >> (class accuracy): [80.6122, 46.7841, 67.7326, 28.3168, 71.6904, 73.991, 81.3152, 46.5953, 54.5175, 69.1774]\n",
            "OCS >> Task 1: {'accuracy': 64.3, 'per_class_accuracy': [93.7755, 68.1057, 56.1047, 50.198, 77.0876, 50.3363, 77.7662, 67.8016, 47.2279, 53.9148], 'loss': 1.1536788851737976}\n",
            "OCS >> Task 2: {'accuracy': 71.12, 'per_class_accuracy': [92.9592, 85.7269, 62.8876, 60.495, 79.8371, 57.6233, 82.0459, 73.5409, 49.8973, 63.6274], 'loss': 0.8970307231903076}\n",
            "OCS >> Task 3: {'accuracy': 74.15, 'per_class_accuracy': [92.2449, 94.2731, 64.9225, 65.7426, 82.1792, 60.3139, 83.6117, 75.1946, 52.9774, 66.6006], 'loss': 0.787656252002716}\n",
            "OCS >> Task 4: {'accuracy': 75.58, 'per_class_accuracy': [91.0204, 97.0925, 66.9574, 67.4257, 83.0957, 66.3677, 83.8205, 72.8599, 52.0534, 71.8533], 'loss': 0.7309279961585998}\n",
            "OCS >> Task 5: {'accuracy': 75.98, 'per_class_accuracy': [89.5918, 94.8018, 67.0543, 65.3465, 81.9756, 70.852, 84.3424, 72.9572, 56.8789, 73.6373], 'loss': 0.7292345746040344}\n",
            "OCS >> Task 6: {'accuracy': 73.42, 'per_class_accuracy': [83.0612, 87.2247, 68.314, 58.1188, 78.9206, 74.6637, 85.6994, 64.6887, 61.807, 71.0605], 'loss': 0.8136305914878845}\n",
            "OCS >> Task 7: {'accuracy': 69.39, 'per_class_accuracy': [83.1633, 68.0176, 71.4147, 43.9604, 75.6619, 75.1121, 84.238, 58.463, 62.731, 73.2408], 'loss': 0.9577883605003357}\n",
            "OCS >> Task 8: {'accuracy': 61.57, 'per_class_accuracy': [80.6122, 46.7841, 67.7326, 28.3168, 71.6904, 73.991, 81.3152, 46.5953, 54.5175, 69.1774], 'loss': 1.2464552492141723}\n",
            "OCS >> (average accuracy): 70.68875\n",
            "OCS >> (Forgetting): 0.2360857142857142\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 9 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 18.32\n",
            "Epoch 0.2 >> (class accuracy): [0.0, 0.0, 13.7597, 0.0, 0.0, 99.6637, 0.0, 75.1946, 0.0, 2.775]\n",
            "Epoch 0.4 >> (per-task accuracy): 47.78\n",
            "Epoch 0.4 >> (class accuracy): [84.4898, 50.837, 47.8682, 16.1386, 35.7434, 60.3139, 33.0898, 3.7938, 59.3429, 88.5035]\n",
            "Epoch 0.6 >> (per-task accuracy): 57.37\n",
            "Epoch 0.6 >> (class accuracy): [85.6122, 45.4626, 38.469, 34.0594, 61.7108, 70.4036, 77.1399, 41.9261, 43.6345, 80.4757]\n",
            "Epoch 0.8 >> (per-task accuracy): 61.21\n",
            "Epoch 0.8 >> (class accuracy): [85.8163, 46.5198, 43.5078, 62.2772, 71.3849, 67.1525, 83.8205, 57.0039, 20.5339, 77.7998]\n",
            "Epoch 1.0 >> (per-task accuracy): 64.45\n",
            "Epoch 1.0 >> (class accuracy): [89.4898, 48.9868, 51.6473, 52.6733, 65.6823, 68.2735, 86.8476, 81.9066, 29.2608, 72.7453]\n",
            "OCS >> Task 1: {'accuracy': 61.0, 'per_class_accuracy': [91.9388, 82.2026, 47.9651, 55.6436, 65.6823, 59.1928, 59.2902, 54.8638, 50.924, 40.4361], 'loss': 1.2334311723709106}\n",
            "OCS >> Task 2: {'accuracy': 67.16, 'per_class_accuracy': [92.7551, 93.9207, 52.907, 64.5545, 68.7373, 63.9013, 65.9708, 63.6187, 51.232, 50.8424], 'loss': 1.0445913049697877}\n",
            "OCS >> Task 3: {'accuracy': 70.64, 'per_class_accuracy': [93.3673, 97.1806, 56.0078, 71.6832, 73.2179, 63.3408, 72.9645, 68.7743, 51.848, 54.4103], 'loss': 0.9268863286972046}\n",
            "OCS >> Task 4: {'accuracy': 73.34, 'per_class_accuracy': [92.2449, 97.7093, 59.1085, 75.3465, 76.4766, 67.8251, 77.8706, 72.6654, 50.1027, 60.7532], 'loss': 0.8444703774452209}\n",
            "OCS >> Task 5: {'accuracy': 76.24, 'per_class_accuracy': [92.8571, 98.0617, 61.3372, 76.6337, 74.1344, 70.6278, 81.4196, 77.9183, 56.4682, 69.8712], 'loss': 0.7663776894569397}\n",
            "OCS >> Task 6: {'accuracy': 75.92, 'per_class_accuracy': [90.8163, 95.9471, 59.4961, 76.2376, 71.0794, 70.9641, 84.6555, 79.4747, 56.7762, 71.0605], 'loss': 0.7505046544075012}\n",
            "OCS >> Task 7: {'accuracy': 75.02, 'per_class_accuracy': [90.5102, 87.3128, 62.0155, 65.2475, 69.0428, 72.4215, 87.7871, 82.5875, 55.1335, 76.7096], 'loss': 0.7658525299072265}\n",
            "OCS >> Task 8: {'accuracy': 70.53, 'per_class_accuracy': [90.3061, 68.0176, 58.8178, 57.3267, 70.2648, 72.3094, 88.4134, 81.2257, 43.8398, 75.9167], 'loss': 0.8978524035453797}\n",
            "OCS >> Task 9: {'accuracy': 64.45, 'per_class_accuracy': [89.4898, 48.9868, 51.6473, 52.6733, 65.6823, 68.2735, 86.8476, 81.9066, 29.2608, 72.7453], 'loss': 1.1063410148620605}\n",
            "OCS >> (average accuracy): 70.47777777777779\n",
            "OCS >> (Forgetting): 0.24368749999999995\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 10 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 32.54\n",
            "Epoch 0.2 >> (class accuracy): [35.9184, 66.9604, 60.562, 7.7228, 49.4908, 28.8117, 0.1044, 0.0, 0.0, 68.8801]\n",
            "Epoch 0.4 >> (per-task accuracy): 49.76\n",
            "Epoch 0.4 >> (class accuracy): [57.449, 66.1674, 70.2519, 35.6436, 15.9878, 46.5247, 64.8225, 6.6148, 44.7639, 87.2151]\n",
            "Epoch 0.6 >> (per-task accuracy): 53.32\n",
            "Epoch 0.6 >> (class accuracy): [66.1224, 34.185, 87.6938, 16.8317, 17.4134, 50.5605, 75.6785, 30.9339, 77.7207, 79.1873]\n",
            "Epoch 0.8 >> (per-task accuracy): 61.02\n",
            "Epoch 0.8 >> (class accuracy): [86.7347, 65.9912, 69.9612, 89.505, 28.2077, 42.3767, 75.5741, 46.9844, 25.154, 76.3132]\n",
            "Epoch 1.0 >> (per-task accuracy): 59.89\n",
            "Epoch 1.0 >> (class accuracy): [87.6531, 64.2291, 52.4225, 52.2772, 39.3075, 83.5202, 83.9248, 56.2257, 0.8214, 80.3766]\n",
            "OCS >> Task 1: {'accuracy': 50.15, 'per_class_accuracy': [90.102, 54.7137, 42.2481, 35.7426, 47.7597, 11.9955, 58.0376, 55.8366, 75.5647, 26.9574], 'loss': 1.6803398843765258}\n",
            "OCS >> Task 2: {'accuracy': 55.77, 'per_class_accuracy': [89.2857, 71.2775, 41.2791, 48.4158, 47.7597, 15.4709, 63.5699, 65.7588, 78.4394, 31.9128], 'loss': 1.4440684381484985}\n",
            "OCS >> Task 3: {'accuracy': 60.82, 'per_class_accuracy': [88.5714, 85.1101, 40.6008, 65.0495, 55.9063, 20.9641, 67.4322, 65.856, 68.0698, 44.5986], 'loss': 1.2510884231567383}\n",
            "OCS >> Task 4: {'accuracy': 64.65, 'per_class_accuracy': [88.7755, 93.5683, 40.0194, 74.3564, 59.3686, 37.2197, 68.8935, 66.0506, 58.0082, 54.5094], 'loss': 1.1231219093322753}\n",
            "OCS >> Task 5: {'accuracy': 68.13, 'per_class_accuracy': [89.1837, 96.9163, 43.9922, 78.9109, 62.3218, 51.4574, 72.0251, 64.0078, 49.076, 68.4836], 'loss': 1.000490268802643}\n",
            "OCS >> Task 6: {'accuracy': 67.91, 'per_class_accuracy': [87.2449, 97.0925, 45.155, 77.5248, 59.165, 65.6951, 76.2004, 57.1984, 35.6263, 74.6283], 'loss': 0.9795911228179932}\n",
            "OCS >> Task 7: {'accuracy': 68.39, 'per_class_accuracy': [87.8571, 97.0044, 53.3915, 69.2079, 56.9246, 76.2332, 76.5136, 56.323, 28.3368, 79.2864], 'loss': 0.9482232486724853}\n",
            "OCS >> Task 8: {'accuracy': 66.76, 'per_class_accuracy': [89.898, 93.0396, 56.9767, 62.8713, 56.5173, 81.278, 80.3758, 47.9572, 16.9405, 80.0793], 'loss': 0.9764000346183777}\n",
            "OCS >> Task 9: {'accuracy': 62.88, 'per_class_accuracy': [88.6735, 82.467, 55.6202, 52.1782, 46.6395, 83.1839, 82.6722, 50.3891, 6.4682, 80.1784], 'loss': 1.0965450008392335}\n",
            "OCS >> Task 10: {'accuracy': 59.89, 'per_class_accuracy': [87.6531, 64.2291, 52.4225, 52.2772, 39.3075, 83.5202, 83.9248, 56.2257, 0.8214, 80.3766], 'loss': 1.256644109916687}\n",
            "OCS >> (average accuracy): 62.535000000000004\n",
            "OCS >> (Forgetting): 0.32771111111111106\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 11 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 26.96\n",
            "Epoch 0.2 >> (class accuracy): [95.4082, 5.815, 24.7093, 0.099, 0.0, 0.0, 60.2296, 0.0, 0.0, 85.4311]\n",
            "Epoch 0.4 >> (per-task accuracy): 21.21\n",
            "Epoch 0.4 >> (class accuracy): [99.4898, 0.0, 27.8101, 0.0, 0.0, 0.0, 61.1691, 0.0, 0.0, 27.0565]\n",
            "Epoch 0.6 >> (per-task accuracy): 37.52\n",
            "Epoch 0.6 >> (class accuracy): [92.8571, 0.0, 58.7209, 26.5347, 0.2037, 16.8161, 83.5073, 0.0, 12.3203, 88.8008]\n",
            "Epoch 0.8 >> (per-task accuracy): 43.44\n",
            "Epoch 0.8 >> (class accuracy): [79.6939, 3.8767, 50.7752, 47.3267, 1.222, 45.6278, 80.6889, 8.9494, 32.2382, 91.0803]\n",
            "Epoch 1.0 >> (per-task accuracy): 51.41\n",
            "Epoch 1.0 >> (class accuracy): [72.2449, 42.0264, 44.186, 43.1683, 13.0346, 54.2601, 79.2276, 36.6732, 45.0719, 86.9177]\n",
            "OCS >> Task 1: {'accuracy': 36.25, 'per_class_accuracy': [87.0408, 9.0749, 30.7171, 34.6535, 36.2525, 15.0224, 66.9102, 12.0623, 30.2875, 44.7968], 'loss': 1.827875842666626}\n",
            "OCS >> Task 2: {'accuracy': 40.73, 'per_class_accuracy': [88.9796, 12.0705, 37.4031, 43.7624, 40.6314, 16.3677, 70.4593, 20.9144, 31.2115, 49.2567], 'loss': 1.7945817323684692}\n",
            "OCS >> Task 3: {'accuracy': 44.38, 'per_class_accuracy': [90.4082, 20.4405, 39.2442, 57.8218, 42.4644, 14.6861, 66.1795, 24.1245, 32.7515, 57.6809], 'loss': 1.753997712135315}\n",
            "OCS >> Task 4: {'accuracy': 46.99, 'per_class_accuracy': [91.2245, 30.3965, 41.0853, 62.9703, 42.3625, 18.9462, 65.6576, 24.6109, 32.1355, 61.447], 'loss': 1.725424359703064}\n",
            "OCS >> Task 5: {'accuracy': 52.85, 'per_class_accuracy': [91.9388, 50.2203, 43.7016, 68.3168, 36.0489, 22.7578, 62.5261, 37.4514, 40.2464, 73.3399], 'loss': 1.665552870941162}\n",
            "OCS >> Task 6: {'accuracy': 56.51, 'per_class_accuracy': [90.8163, 63.5242, 46.5116, 68.2178, 31.5682, 29.0359, 59.6033, 41.4397, 51.0267, 80.0793], 'loss': 1.6109584753036499}\n",
            "OCS >> Task 7: {'accuracy': 59.56, 'per_class_accuracy': [89.3878, 69.2511, 55.3295, 63.5644, 21.1813, 38.2287, 62.1086, 51.07, 59.5483, 82.4579], 'loss': 1.5494673904418945}\n",
            "OCS >> Task 8: {'accuracy': 61.58, 'per_class_accuracy': [86.4286, 76.2996, 59.3992, 60.7921, 19.6538, 42.6009, 66.4927, 52.1401, 62.423, 85.6293], 'loss': 1.4983921096801758}\n",
            "OCS >> Task 9: {'accuracy': 61.37, 'per_class_accuracy': [82.0408, 75.3304, 57.1705, 54.9505, 15.7841, 47.1973, 70.8768, 58.7549, 61.807, 86.4222], 'loss': 1.470868196105957}\n",
            "OCS >> Task 10: {'accuracy': 57.46, 'per_class_accuracy': [75.8163, 60.0881, 53.5853, 48.4158, 12.3218, 50.1121, 74.1127, 55.3502, 55.9548, 87.9088], 'loss': 1.4906676145553588}\n",
            "OCS >> Task 11: {'accuracy': 51.41, 'per_class_accuracy': [72.2449, 42.0264, 44.186, 43.1683, 13.0346, 54.2601, 79.2276, 36.6732, 45.0719, 86.9177], 'loss': 1.5436875015258789}\n",
            "OCS >> (average accuracy): 51.73545454545455\n",
            "OCS >> (Forgetting): 0.43831999999999993\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 12 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 22.41\n",
            "Epoch 0.2 >> (class accuracy): [79.2857, 0.2643, 1.5504, 0.0, 0.0, 0.0, 52.9228, 0.1946, 0.0, 92.7651]\n",
            "Epoch 0.4 >> (per-task accuracy): 25.39\n",
            "Epoch 0.4 >> (class accuracy): [14.5918, 0.0, 0.0, 0.0, 0.0, 0.0, 63.048, 97.6654, 80.9035, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 34.96\n",
            "Epoch 0.6 >> (class accuracy): [85.8163, 0.0, 0.6783, 5.9406, 9.2668, 0.0, 86.0125, 97.9572, 68.3778, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 40.77\n",
            "Epoch 0.8 >> (class accuracy): [83.2653, 0.0, 11.2403, 43.9604, 26.4766, 0.0, 85.6994, 97.9572, 61.6016, 1.2884]\n",
            "Epoch 1.0 >> (per-task accuracy): 46.03\n",
            "Epoch 1.0 >> (class accuracy): [74.2857, 0.0, 17.9264, 69.0099, 40.7332, 7.1749, 80.8977, 97.3735, 59.2402, 17.443]\n",
            "OCS >> Task 1: {'accuracy': 32.77, 'per_class_accuracy': [69.3878, 0.0, 10.1744, 38.9109, 55.0916, 0.8969, 59.3946, 46.9844, 37.885, 12.7849], 'loss': 2.0221301162719727}\n",
            "OCS >> Task 2: {'accuracy': 36.95, 'per_class_accuracy': [73.7755, 0.0, 13.7597, 40.8911, 59.6741, 1.6816, 58.7683, 57.6848, 49.076, 18.0377], 'loss': 1.9949566511154175}\n",
            "OCS >> Task 3: {'accuracy': 38.88, 'per_class_accuracy': [75.8163, 0.0, 14.1473, 53.3663, 63.6456, 1.1211, 49.0605, 55.8366, 54.7228, 24.5788], 'loss': 1.9823859523773193}\n",
            "OCS >> Task 4: {'accuracy': 39.08, 'per_class_accuracy': [79.7959, 0.0, 12.6938, 56.2376, 63.7475, 1.2332, 43.5282, 56.2257, 61.499, 19.4252], 'loss': 1.9728502244949342}\n",
            "OCS >> Task 5: {'accuracy': 41.16, 'per_class_accuracy': [82.551, 0.0, 12.4031, 55.3465, 64.2566, 1.009, 41.858, 66.9261, 69.1992, 21.5064], 'loss': 1.947819810295105}\n",
            "OCS >> Task 6: {'accuracy': 42.05, 'per_class_accuracy': [85.3061, 0.0, 12.0155, 53.0693, 59.4705, 1.4574, 46.5553, 71.4981, 78.4394, 16.551], 'loss': 1.9242423706054688}\n",
            "OCS >> Task 7: {'accuracy': 42.69, 'per_class_accuracy': [86.3265, 0.0, 19.2829, 49.2079, 52.2403, 2.8027, 53.7578, 77.2374, 82.3409, 7.7304], 'loss': 1.8972731422424316}\n",
            "OCS >> Task 8: {'accuracy': 44.56, 'per_class_accuracy': [87.3469, 0.0, 22.9651, 55.8416, 46.945, 3.8117, 65.3445, 83.2685, 81.7248, 2.5768], 'loss': 1.8568595430374146}\n",
            "OCS >> Task 9: {'accuracy': 44.93, 'per_class_accuracy': [84.3878, 0.0, 25.2907, 59.0099, 36.1507, 5.6054, 72.7557, 88.5214, 81.0062, 0.7929], 'loss': 1.8204553783416748}\n",
            "OCS >> Task 10: {'accuracy': 45.29, 'per_class_accuracy': [80.0, 0.0, 29.5543, 63.4653, 31.8737, 5.157, 75.8873, 91.7315, 77.2074, 1.7839], 'loss': 1.7932377437591553}\n",
            "OCS >> Task 11: {'accuracy': 46.43, 'per_class_accuracy': [77.6531, 0.0, 24.8062, 67.7228, 38.4929, 7.3991, 81.6284, 95.2335, 67.7618, 7.6313], 'loss': 1.7745235425949097}\n",
            "OCS >> Task 12: {'accuracy': 46.03, 'per_class_accuracy': [74.2857, 0.0, 17.9264, 69.0099, 40.7332, 7.1749, 80.8977, 97.3735, 59.2402, 17.443], 'loss': 1.7948059982299804}\n",
            "OCS >> (average accuracy): 41.73500000000001\n",
            "OCS >> (Forgetting): 0.5425545454545454\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 13 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 17.39\n",
            "Epoch 0.2 >> (class accuracy): [60.9184, 0.0, 0.0, 0.0, 0.0, 0.0, 27.9749, 0.2918, 0.0, 86.3231]\n",
            "Epoch 0.4 >> (per-task accuracy): 23.17\n",
            "Epoch 0.4 >> (class accuracy): [64.0816, 0.0, 0.0, 2.7723, 0.0, 0.0, 66.0752, 100.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 28.0\n",
            "Epoch 0.6 >> (class accuracy): [91.8367, 0.0, 0.0, 7.7228, 0.0, 0.0, 85.6994, 97.3735, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 31.04\n",
            "Epoch 0.8 >> (class accuracy): [89.1837, 0.0, 1.3566, 35.5446, 0.0, 0.0, 89.2484, 97.2763, 0.2053, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 35.53\n",
            "Epoch 1.0 >> (class accuracy): [83.5714, 0.0, 6.1047, 70.8911, 0.0, 0.0, 90.501, 97.7626, 5.7495, 2.6759]\n",
            "OCS >> Task 1: {'accuracy': 24.92, 'per_class_accuracy': [75.8163, 0.0, 0.6783, 46.4356, 0.0, 0.0, 63.6743, 62.7432, 1.7454, 0.0991], 'loss': 2.131716565322876}\n",
            "OCS >> Task 2: {'accuracy': 26.24, 'per_class_accuracy': [78.7755, 0.0, 1.6473, 41.2871, 0.0, 0.0, 66.0752, 73.8327, 2.5667, 0.0991], 'loss': 2.1175853267669678}\n",
            "OCS >> Task 3: {'accuracy': 25.75, 'per_class_accuracy': [78.9796, 0.0, 2.2287, 41.5842, 0.0, 0.0, 62.1086, 70.1362, 3.4908, 0.7929], 'loss': 2.110872709274292}\n",
            "OCS >> Task 4: {'accuracy': 25.44, 'per_class_accuracy': [81.0204, 0.0, 2.4225, 40.396, 0.0, 0.0, 59.6033, 67.3152, 5.2361, 0.2973], 'loss': 2.112566345977783}\n",
            "OCS >> Task 5: {'accuracy': 25.76, 'per_class_accuracy': [82.1429, 0.0, 2.4225, 36.6337, 0.0, 0.0, 58.6639, 70.6226, 7.3922, 1.5857], 'loss': 2.1054571727752687}\n",
            "OCS >> Task 6: {'accuracy': 26.62, 'per_class_accuracy': [84.0816, 0.0, 2.5194, 37.5248, 0.0, 0.0, 60.334, 72.3735, 10.5749, 0.7929], 'loss': 2.10210380859375}\n",
            "OCS >> Task 7: {'accuracy': 28.45, 'per_class_accuracy': [85.3061, 0.0, 4.9419, 35.4455, 0.0, 0.0, 66.7015, 77.5292, 16.2218, 0.5946], 'loss': 2.0938526206970214}\n",
            "OCS >> Task 8: {'accuracy': 31.41, 'per_class_accuracy': [88.6735, 0.0, 8.2364, 40.8911, 0.0, 0.0, 73.7996, 86.284, 18.3778, 0.0991], 'loss': 2.0733392639160155}\n",
            "OCS >> Task 9: {'accuracy': 33.82, 'per_class_accuracy': [88.1633, 0.0, 9.0116, 51.9802, 0.0, 0.0, 81.1065, 91.6342, 18.4805, 0.0991], 'loss': 2.05090125579834}\n",
            "OCS >> Task 10: {'accuracy': 34.97, 'per_class_accuracy': [86.5306, 0.0, 15.1163, 55.7426, 0.0, 0.0, 84.7599, 93.677, 15.9138, 0.0], 'loss': 2.017987664794922}\n",
            "OCS >> Task 11: {'accuracy': 36.38, 'per_class_accuracy': [86.3265, 0.0, 16.1822, 64.2574, 0.0, 0.0, 88.2046, 96.2062, 14.5791, 0.0], 'loss': 1.9881617877960205}\n",
            "OCS >> Task 12: {'accuracy': 36.5, 'per_class_accuracy': [86.2245, 0.0, 13.1783, 67.3267, 0.0, 0.0, 89.7704, 97.8599, 11.2936, 1.2884], 'loss': 1.9841548389434815}\n",
            "OCS >> Task 13: {'accuracy': 35.53, 'per_class_accuracy': [83.5714, 0.0, 6.1047, 70.8911, 0.0, 0.0, 90.501, 97.7626, 5.7495, 2.6759], 'loss': 1.9934550243377684}\n",
            "OCS >> (average accuracy): 30.137692307692305\n",
            "OCS >> (Forgetting): 0.6591166666666666\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 14 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 14.26\n",
            "Epoch 0.2 >> (class accuracy): [32.1429, 0.0, 0.0, 0.0, 0.0, 0.0, 21.5031, 0.1946, 0.0, 89.4945]\n",
            "Epoch 0.4 >> (per-task accuracy): 16.38\n",
            "Epoch 0.4 >> (class accuracy): [0.0, 0.0, 0.0, 14.2574, 0.0, 93.8341, 60.4384, 7.5875, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 20.48\n",
            "Epoch 0.6 >> (class accuracy): [17.1429, 0.0, 0.0, 12.0792, 0.0, 82.287, 90.2923, 15.4669, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 28.96\n",
            "Epoch 0.8 >> (class accuracy): [65.4082, 0.0, 1.0659, 24.0594, 0.0, 75.1121, 93.5282, 42.3152, 0.0, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 32.12\n",
            "Epoch 1.0 >> (class accuracy): [73.1633, 0.0, 5.2326, 27.2277, 0.0, 69.1704, 92.7975, 64.2023, 0.0, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 19.27, 'per_class_accuracy': [59.0816, 0.0, 0.0, 23.0693, 0.0, 48.2063, 68.3716, 2.9183, 0.0, 0.0], 'loss': 2.2345967262268065}\n",
            "OCS >> Task 2: {'accuracy': 19.43, 'per_class_accuracy': [61.3265, 0.0, 0.0969, 18.2178, 0.0, 45.9641, 72.8601, 4.7665, 0.0, 0.0], 'loss': 2.2274973625183105}\n",
            "OCS >> Task 3: {'accuracy': 18.83, 'per_class_accuracy': [65.8163, 0.0, 0.0, 20.9901, 0.0, 32.6233, 74.0084, 2.5292, 0.0, 0.0], 'loss': 2.224282102203369}\n",
            "OCS >> Task 4: {'accuracy': 18.1, 'per_class_accuracy': [72.8571, 0.0, 0.2907, 17.1287, 0.0, 22.0852, 73.4864, 1.8482, 0.0, 0.0], 'loss': 2.2253484352111816}\n",
            "OCS >> Task 5: {'accuracy': 17.53, 'per_class_accuracy': [74.898, 0.0, 0.6783, 16.6337, 0.0, 13.9013, 73.5908, 1.4591, 0.0, 0.0], 'loss': 2.2223467845916747}\n",
            "OCS >> Task 6: {'accuracy': 17.15, 'per_class_accuracy': [79.5918, 0.0, 1.5504, 10.5941, 0.0, 11.5471, 72.6514, 1.2646, 0.0, 0.0], 'loss': 2.2239496669769285}\n",
            "OCS >> Task 7: {'accuracy': 17.77, 'per_class_accuracy': [81.6327, 0.0, 3.876, 4.3564, 0.0, 14.9103, 75.4697, 3.5992, 0.0, 0.0], 'loss': 2.221239696121216}\n",
            "OCS >> Task 8: {'accuracy': 20.34, 'per_class_accuracy': [86.5306, 0.0, 4.845, 7.8218, 0.0, 21.861, 79.5407, 9.7276, 0.0, 0.0], 'loss': 2.211979535293579}\n",
            "OCS >> Task 9: {'accuracy': 24.08, 'per_class_accuracy': [87.3469, 0.0, 6.5891, 11.4851, 0.0, 31.5022, 86.3257, 25.2918, 0.0, 0.0], 'loss': 2.200962467956543}\n",
            "OCS >> Task 10: {'accuracy': 28.5, 'per_class_accuracy': [84.0816, 0.0, 11.9186, 11.8812, 0.0, 43.722, 87.4739, 53.9883, 0.0, 0.0], 'loss': 2.185376171875}\n",
            "OCS >> Task 11: {'accuracy': 33.17, 'per_class_accuracy': [85.6122, 0.0, 15.3101, 29.1089, 0.0, 50.5605, 91.7537, 67.7043, 0.0, 0.0], 'loss': 2.165280708694458}\n",
            "OCS >> Task 12: {'accuracy': 34.88, 'per_class_accuracy': [84.2857, 0.0, 14.8256, 31.5842, 0.0, 60.8744, 93.3194, 73.249, 0.0, 0.0], 'loss': 2.1530068706512453}\n",
            "OCS >> Task 13: {'accuracy': 35.01, 'per_class_accuracy': [77.2449, 0.0, 10.4651, 38.4158, 0.0, 65.1345, 93.5282, 75.0, 0.0, 0.0], 'loss': 2.1510761699676513}\n",
            "OCS >> Task 14: {'accuracy': 32.12, 'per_class_accuracy': [73.1633, 0.0, 5.2326, 27.2277, 0.0, 69.1704, 92.7975, 64.2023, 0.0, 0.0], 'loss': 2.1554900245666504}\n",
            "OCS >> (average accuracy): 24.012857142857143\n",
            "OCS >> (Forgetting): 0.7221076923076921\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 15 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 13.76\n",
            "Epoch 0.2 >> (class accuracy): [30.2041, 0.0, 0.0, 0.0, 0.0, 0.0, 27.3486, 0.0, 0.0, 81.0704]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.0\n",
            "Epoch 0.4 >> (class accuracy): [0.0, 0.0, 0.0, 0.396, 0.0, 100.0, 0.4175, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 10.91\n",
            "Epoch 0.6 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 99.7758, 20.9812, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 19.24\n",
            "Epoch 0.8 >> (class accuracy): [45.5102, 0.0, 0.0, 0.0, 0.0, 92.4888, 68.1628, 0.0, 0.0, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 22.65\n",
            "Epoch 1.0 >> (class accuracy): [69.3878, 0.0, 0.0, 0.297, 0.0, 82.8475, 83.2985, 4.3774, 0.0, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 16.65, 'per_class_accuracy': [48.2653, 0.0, 0.0, 1.5842, 0.0, 87.3318, 41.4405, 0.0, 0.0, 0.0], 'loss': 2.265992475128174}\n",
            "OCS >> Task 2: {'accuracy': 17.32, 'per_class_accuracy': [48.7755, 0.0, 0.0, 0.9901, 0.0, 84.9776, 50.7307, 0.0, 0.0, 0.0], 'loss': 2.2613628311157226}\n",
            "OCS >> Task 3: {'accuracy': 18.25, 'per_class_accuracy': [57.9592, 0.0, 0.0, 2.6733, 0.0, 76.4574, 57.2025, 0.0, 0.0, 0.0], 'loss': 2.2590802883148196}\n",
            "OCS >> Task 4: {'accuracy': 17.89, 'per_class_accuracy': [66.0204, 0.0, 0.0, 0.8911, 0.0, 64.574, 58.142, 0.0, 0.0, 0.0], 'loss': 2.2601501396179198}\n",
            "OCS >> Task 5: {'accuracy': 17.16, 'per_class_accuracy': [74.0816, 0.0, 0.0, 0.396, 0.0, 48.2063, 58.0376, 0.0, 0.0, 0.0], 'loss': 2.2565650596618654}\n",
            "OCS >> Task 6: {'accuracy': 16.96, 'per_class_accuracy': [78.8776, 0.0, 0.0, 0.198, 0.0, 42.6009, 56.4718, 0.0, 0.0, 0.0], 'loss': 2.259260276031494}\n",
            "OCS >> Task 7: {'accuracy': 17.82, 'per_class_accuracy': [83.3673, 0.0, 0.0, 0.099, 0.0, 43.8341, 59.8121, 0.0, 0.0, 0.0], 'loss': 2.258972459030151}\n",
            "OCS >> Task 8: {'accuracy': 18.66, 'per_class_accuracy': [86.4286, 0.0, 0.0, 0.0, 0.0, 52.2422, 57.7244, 0.0, 0.0, 0.0], 'loss': 2.253587328338623}\n",
            "OCS >> Task 9: {'accuracy': 20.25, 'per_class_accuracy': [87.6531, 0.0, 0.0, 0.0, 0.0, 63.7892, 62.2129, 0.0973, 0.0, 0.0], 'loss': 2.249020398712158}\n",
            "OCS >> Task 10: {'accuracy': 21.09, 'per_class_accuracy': [82.3469, 0.0, 0.0, 0.0, 0.0, 73.5426, 65.9708, 1.3619, 0.0, 0.0], 'loss': 2.2421669174194334}\n",
            "OCS >> Task 11: {'accuracy': 22.61, 'per_class_accuracy': [83.8776, 0.0, 0.0, 0.0, 0.0, 78.3632, 74.739, 2.3346, 0.0, 0.0], 'loss': 2.2310639987945557}\n",
            "OCS >> Task 12: {'accuracy': 23.19, 'per_class_accuracy': [83.2653, 0.0, 0.0, 0.0, 0.0, 82.7354, 77.5574, 2.1401, 0.0, 0.0], 'loss': 2.222117350387573}\n",
            "OCS >> Task 13: {'accuracy': 23.5, 'per_class_accuracy': [73.4694, 0.0, 0.0, 0.099, 0.0, 83.9686, 81.1065, 10.0195, 0.0, 0.0], 'loss': 2.21804899597168}\n",
            "OCS >> Task 14: {'accuracy': 22.73, 'per_class_accuracy': [70.2041, 0.0, 0.0, 0.198, 0.0, 83.5202, 80.6889, 6.323, 0.0, 0.0], 'loss': 2.217607149505615}\n",
            "OCS >> Task 15: {'accuracy': 22.65, 'per_class_accuracy': [69.3878, 0.0, 0.0, 0.297, 0.0, 82.8475, 83.2985, 4.3774, 0.0, 0.0], 'loss': 2.2199675994873047}\n",
            "OCS >> (average accuracy): 19.782\n",
            "OCS >> (Forgetting): 0.7602285714285714\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 16 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 14.3\n",
            "Epoch 0.2 >> (class accuracy): [37.2449, 0.0, 0.0, 0.0, 0.0, 0.0, 36.1169, 0.0, 0.0, 71.2587]\n",
            "Epoch 0.4 >> (per-task accuracy): 16.7\n",
            "Epoch 0.4 >> (class accuracy): [6.5306, 0.0, 0.0, 4.0594, 0.0, 56.0538, 96.5553, 0.0, 14.3737, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 19.53\n",
            "Epoch 0.6 >> (class accuracy): [31.8367, 0.0, 0.0, 8.1188, 0.0, 55.7175, 96.4509, 0.0, 14.1684, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 22.24\n",
            "Epoch 0.8 >> (class accuracy): [75.4082, 0.0, 0.0, 18.9109, 0.0, 36.0987, 93.4238, 0.0, 7.9055, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 18.12\n",
            "Epoch 1.0 >> (class accuracy): [81.4286, 0.0, 0.0, 8.7129, 0.0, 5.6054, 88.8309, 0.0, 2.5667, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 15.64, 'per_class_accuracy': [81.8367, 0.0, 0.0, 0.099, 0.0, 4.3722, 75.3653, 0.0, 0.0, 0.0], 'loss': 2.281190579986572}\n",
            "OCS >> Task 2: {'accuracy': 15.33, 'per_class_accuracy': [79.7959, 0.0, 0.0, 0.0, 0.0, 3.5874, 75.0522, 0.0, 0.0, 0.0], 'loss': 2.2776223224639893}\n",
            "OCS >> Task 3: {'accuracy': 15.14, 'per_class_accuracy': [79.4898, 0.0, 0.0, 0.0, 0.0, 1.4574, 75.261, 0.0, 0.1027, 0.0], 'loss': 2.275808661270142}\n",
            "OCS >> Task 4: {'accuracy': 14.75, 'per_class_accuracy': [77.9592, 0.0, 0.0, 0.0, 0.0, 0.0, 74.2171, 0.0, 0.0, 0.0], 'loss': 2.2766332736968993}\n",
            "OCS >> Task 5: {'accuracy': 14.78, 'per_class_accuracy': [79.2857, 0.0, 0.0, 0.0, 0.0, 0.0, 73.1733, 0.0, 0.0, 0.0], 'loss': 2.2732708477020265}\n",
            "OCS >> Task 6: {'accuracy': 14.74, 'per_class_accuracy': [80.2041, 0.0, 0.0, 0.0, 0.0, 0.0, 71.7119, 0.0, 0.1027, 0.0], 'loss': 2.2756577987670896}\n",
            "OCS >> Task 7: {'accuracy': 15.04, 'per_class_accuracy': [79.898, 0.0, 0.0, 0.0, 0.0, 0.0, 75.261, 0.0, 0.0, 0.0], 'loss': 2.27547631111145}\n",
            "OCS >> Task 8: {'accuracy': 15.8, 'per_class_accuracy': [85.9184, 0.0, 0.0, 0.0, 0.0, 0.0, 77.0355, 0.0, 0.0, 0.0], 'loss': 2.271999509811401}\n",
            "OCS >> Task 9: {'accuracy': 16.52, 'per_class_accuracy': [86.9388, 0.0, 0.0, 0.0, 0.0, 0.0, 83.5073, 0.0, 0.0, 0.0], 'loss': 2.269915900802612}\n",
            "OCS >> Task 10: {'accuracy': 16.53, 'per_class_accuracy': [84.4898, 0.0, 0.0, 0.0, 0.0, 0.0, 86.1169, 0.0, 0.0, 0.0], 'loss': 2.266624766921997}\n",
            "OCS >> Task 11: {'accuracy': 17.38, 'per_class_accuracy': [87.7551, 0.0, 0.0, 0.198, 0.0, 0.1121, 91.3361, 0.0, 0.0, 0.0], 'loss': 2.25969479637146}\n",
            "OCS >> Task 12: {'accuracy': 17.86, 'per_class_accuracy': [89.7959, 0.0, 0.0, 0.5941, 0.0, 0.4484, 92.9019, 0.0, 0.616, 0.0], 'loss': 2.2535364070892334}\n",
            "OCS >> Task 13: {'accuracy': 17.73, 'per_class_accuracy': [85.8163, 0.0, 0.0, 2.1782, 0.0, 0.4484, 94.1545, 0.0, 0.4107, 0.0], 'loss': 2.250067569732666}\n",
            "OCS >> Task 14: {'accuracy': 17.84, 'per_class_accuracy': [84.4898, 0.0, 0.0, 5.2475, 0.0, 0.5605, 93.215, 0.0, 0.5133, 0.0], 'loss': 2.245746792221069}\n",
            "OCS >> Task 15: {'accuracy': 17.97, 'per_class_accuracy': [83.3673, 0.0, 0.0, 8.1188, 0.0, 1.5695, 90.7098, 0.0, 1.54, 0.0], 'loss': 2.2455470596313476}\n",
            "OCS >> Task 16: {'accuracy': 18.12, 'per_class_accuracy': [81.4286, 0.0, 0.0, 8.7129, 0.0, 5.6054, 88.8309, 0.0, 2.5667, 0.0], 'loss': 2.24172204246521}\n",
            "OCS >> (average accuracy): 16.323124999999997\n",
            "OCS >> (Forgetting): 0.7939666666666666\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 17 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 14.76\n",
            "Epoch 0.2 >> (class accuracy): [20.3061, 0.0, 0.0, 0.0, 0.0, 0.0, 48.1211, 0.0, 0.0, 80.8722]\n",
            "Epoch 0.4 >> (per-task accuracy): 11.54\n",
            "Epoch 0.4 >> (class accuracy): [14.898, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 5.1335, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 15.25\n",
            "Epoch 0.6 >> (class accuracy): [34.4898, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 23.5113, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 18.1\n",
            "Epoch 0.8 >> (class accuracy): [62.8571, 0.0, 0.0, 0.0, 0.0, 0.0, 98.8518, 0.0, 25.3593, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 18.24\n",
            "Epoch 1.0 >> (class accuracy): [75.7143, 0.0, 0.0, 0.0, 0.0, 0.0, 95.929, 0.0, 16.7351, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 15.01, 'per_class_accuracy': [70.5102, 0.0, 0.0, 0.0, 0.0, 0.0, 84.5511, 0.0, 0.0, 0.0], 'loss': 2.2932751640319826}\n",
            "OCS >> Task 2: {'accuracy': 14.55, 'per_class_accuracy': [66.6327, 0.0, 0.0, 0.0, 0.0, 0.0, 83.6117, 0.0, 0.1027, 0.0], 'loss': 2.2897695888519287}\n",
            "OCS >> Task 3: {'accuracy': 14.62, 'per_class_accuracy': [68.8776, 0.0, 0.0, 0.0, 0.0, 0.0, 81.7328, 0.0, 0.4107, 0.0], 'loss': 2.2877170948028565}\n",
            "OCS >> Task 4: {'accuracy': 14.42, 'per_class_accuracy': [67.0408, 0.0, 0.0, 0.0, 0.0, 0.0, 80.6889, 0.0, 1.232, 0.0], 'loss': 2.2885197719573975}\n",
            "OCS >> Task 5: {'accuracy': 14.61, 'per_class_accuracy': [70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.9582, 0.0, 0.924, 0.0], 'loss': 2.2851914768218995}\n",
            "OCS >> Task 6: {'accuracy': 14.82, 'per_class_accuracy': [71.2245, 0.0, 0.0, 0.0, 0.0, 0.0, 79.7495, 0.0, 2.0534, 0.0], 'loss': 2.287552048110962}\n",
            "OCS >> Task 7: {'accuracy': 14.62, 'per_class_accuracy': [67.9592, 0.0, 0.0, 0.0, 0.0, 0.0, 81.0021, 0.0, 2.0534, 0.0], 'loss': 2.2874229522705076}\n",
            "OCS >> Task 8: {'accuracy': 15.19, 'per_class_accuracy': [71.8367, 0.0, 0.0, 0.0, 0.0, 0.0, 83.0898, 0.0, 1.9507, 0.0], 'loss': 2.2852705780029297}\n",
            "OCS >> Task 9: {'accuracy': 15.55, 'per_class_accuracy': [71.5306, 0.0, 0.0, 0.0, 0.0, 0.0, 88.2046, 0.0, 0.924, 0.0], 'loss': 2.2846626014709472}\n",
            "OCS >> Task 10: {'accuracy': 15.62, 'per_class_accuracy': [70.6122, 0.0, 0.0, 0.0, 0.0, 0.0, 90.501, 0.0, 0.308, 0.0], 'loss': 2.2838280700683593}\n",
            "OCS >> Task 11: {'accuracy': 16.57, 'per_class_accuracy': [75.4082, 0.0, 0.0, 0.0, 0.0, 0.0, 94.0501, 0.0, 1.7454, 0.0], 'loss': 2.280325619125366}\n",
            "OCS >> Task 12: {'accuracy': 17.94, 'per_class_accuracy': [81.5306, 0.0, 0.0, 0.0, 0.0, 0.0, 95.929, 0.0, 7.8029, 0.0], 'loss': 2.276896508026123}\n",
            "OCS >> Task 13: {'accuracy': 17.53, 'per_class_accuracy': [76.2245, 0.0, 0.0, 0.0, 0.0, 0.0, 97.286, 0.0, 7.5975, 0.0], 'loss': 2.2747382595062255}\n",
            "OCS >> Task 14: {'accuracy': 17.97, 'per_class_accuracy': [77.1429, 0.0, 0.0, 0.0, 0.0, 0.0, 96.5553, 0.0, 11.9097, 0.0], 'loss': 2.2703837635040283}\n",
            "OCS >> Task 15: {'accuracy': 18.44, 'per_class_accuracy': [75.6122, 0.0, 0.0, 0.0, 0.0, 0.0, 95.929, 0.0, 18.8912, 0.0], 'loss': 2.26754659576416}\n",
            "OCS >> Task 16: {'accuracy': 19.14, 'per_class_accuracy': [75.9184, 0.0, 0.0, 0.0, 0.0, 0.0, 95.6159, 0.0, 26.078, 0.0], 'loss': 2.2626337574005126}\n",
            "OCS >> Task 17: {'accuracy': 18.24, 'per_class_accuracy': [75.7143, 0.0, 0.0, 0.0, 0.0, 0.0, 95.929, 0.0, 16.7351, 0.0], 'loss': 2.263464926147461}\n",
            "OCS >> (average accuracy): 16.167058823529413\n",
            "OCS >> (Forgetting): 0.795625\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 18 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 14.04\n",
            "Epoch 0.2 >> (class accuracy): [22.551, 0.0, 0.0, 0.0, 0.0, 0.0, 36.2213, 0.0, 0.0, 82.8543]\n",
            "Epoch 0.4 >> (per-task accuracy): 20.63\n",
            "Epoch 0.4 >> (class accuracy): [28.8776, 0.0, 0.0, 72.9703, 0.0, 0.0, 29.1232, 0.0, 64.5791, 13.3796]\n",
            "Epoch 0.6 >> (per-task accuracy): 16.25\n",
            "Epoch 0.6 >> (class accuracy): [7.449, 0.0, 0.0, 64.4554, 0.0, 0.0, 0.0, 0.0, 92.5051, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 20.03\n",
            "Epoch 0.8 >> (class accuracy): [40.0, 0.0, 0.0, 86.1386, 0.0, 0.0, 0.0, 0.0, 76.078, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 23.49\n",
            "Epoch 1.0 >> (class accuracy): [76.1224, 0.0, 0.0, 91.5842, 0.0, 0.0, 11.2735, 0.0, 58.5216, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 13.35, 'per_class_accuracy': [31.6327, 0.0, 0.0, 77.8218, 0.0, 0.0, 0.2088, 0.0, 24.3326, 0.0], 'loss': 2.2921738677978514}\n",
            "OCS >> Task 2: {'accuracy': 13.71, 'per_class_accuracy': [26.4286, 0.0, 0.0, 76.0396, 0.0, 0.0, 0.0, 0.0, 35.3183, 0.0], 'loss': 2.289941421508789}\n",
            "OCS >> Task 3: {'accuracy': 15.08, 'per_class_accuracy': [35.5102, 0.0, 0.0, 73.0693, 0.0, 0.0, 0.0, 0.0, 43.3265, 0.0], 'loss': 2.2886739589691163}\n",
            "OCS >> Task 4: {'accuracy': 15.38, 'per_class_accuracy': [43.0612, 0.0, 0.0, 50.7921, 0.0, 0.0, 0.0, 0.0, 61.9097, 0.0], 'loss': 2.2901813175201418}\n",
            "OCS >> Task 5: {'accuracy': 17.92, 'per_class_accuracy': [64.898, 0.0, 0.0, 37.0297, 0.0, 0.0, 0.1044, 0.0, 80.1848, 0.0], 'loss': 2.2874786930084228}\n",
            "OCS >> Task 6: {'accuracy': 17.33, 'per_class_accuracy': [76.1224, 0.0, 0.0, 17.7228, 0.0, 0.0, 0.0, 0.0, 82.9569, 0.0], 'loss': 2.290171422576904}\n",
            "OCS >> Task 7: {'accuracy': 17.4, 'per_class_accuracy': [81.0204, 0.0, 0.0, 9.0099, 0.0, 0.0, 0.2088, 0.0, 87.577, 0.0], 'loss': 2.2910315967559813}\n",
            "OCS >> Task 8: {'accuracy': 17.73, 'per_class_accuracy': [87.551, 0.0, 0.0, 9.0099, 0.0, 0.0, 0.3132, 0.0, 84.2916, 0.0], 'loss': 2.2888788017272947}\n",
            "OCS >> Task 9: {'accuracy': 17.88, 'per_class_accuracy': [89.1837, 0.0, 0.0, 13.5644, 0.0, 0.0, 0.3132, 0.0, 79.4661, 0.0], 'loss': 2.2888357696533204}\n",
            "OCS >> Task 10: {'accuracy': 17.94, 'per_class_accuracy': [90.7143, 0.0, 0.0, 11.2871, 0.0, 0.0, 0.3132, 0.0, 80.9035, 0.0], 'loss': 2.288155007171631}\n",
            "OCS >> Task 11: {'accuracy': 19.27, 'per_class_accuracy': [93.9796, 0.0, 0.0, 19.3069, 0.0, 0.0, 1.7745, 0.0, 81.5195, 0.0], 'loss': 2.2863489109039308}\n",
            "OCS >> Task 12: {'accuracy': 20.29, 'per_class_accuracy': [96.0204, 0.0, 0.0, 24.9505, 0.0, 0.0, 1.7745, 0.0, 84.0862, 0.0], 'loss': 2.284844205856323}\n",
            "OCS >> Task 13: {'accuracy': 22.69, 'per_class_accuracy': [93.5714, 0.0, 0.0, 45.3465, 0.0, 0.0, 4.6973, 0.0, 87.1663, 0.0], 'loss': 2.2840463790893555}\n",
            "OCS >> Task 14: {'accuracy': 24.0, 'per_class_accuracy': [92.3469, 0.0, 0.0, 61.9802, 0.0, 0.0, 6.3674, 0.0, 82.9569, 0.0], 'loss': 2.2816134784698487}\n",
            "OCS >> Task 15: {'accuracy': 26.16, 'per_class_accuracy': [92.1429, 0.0, 0.0, 79.802, 0.0, 0.0, 11.3779, 0.0, 81.9302, 0.0], 'loss': 2.278178748321533}\n",
            "OCS >> Task 16: {'accuracy': 26.57, 'per_class_accuracy': [89.7959, 0.0, 0.0, 87.2277, 0.0, 0.0, 12.7349, 0.0, 79.4661, 0.0], 'loss': 2.272337664413452}\n",
            "OCS >> Task 17: {'accuracy': 25.06, 'per_class_accuracy': [80.7143, 0.0, 0.0, 88.6139, 0.0, 0.0, 11.5866, 0.0, 72.7926, 0.0], 'loss': 2.2721698692321777}\n",
            "OCS >> Task 18: {'accuracy': 23.49, 'per_class_accuracy': [76.1224, 0.0, 0.0, 91.5842, 0.0, 0.0, 11.2735, 0.0, 58.5216, 0.0], 'loss': 2.2717097064971923}\n",
            "OCS >> (average accuracy): 19.513888888888893\n",
            "OCS >> (Forgetting): 0.7632000000000001\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 19 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 14.51\n",
            "Epoch 0.2 >> (class accuracy): [21.6327, 0.0, 0.0, 0.0, 0.0, 0.0, 40.2923, 0.0, 0.0, 84.5391]\n",
            "Epoch 0.4 >> (per-task accuracy): 17.37\n",
            "Epoch 0.4 >> (class accuracy): [92.2449, 0.0, 0.0, 1.4851, 0.0, 0.0, 61.1691, 0.0, 5.6468, 17.5421]\n",
            "Epoch 0.6 >> (per-task accuracy): 18.2\n",
            "Epoch 0.6 >> (class accuracy): [96.5306, 0.0, 0.0, 3.4653, 0.0, 0.0, 37.8914, 0.0, 48.8706, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 17.98\n",
            "Epoch 0.8 >> (class accuracy): [98.5714, 0.0, 0.0, 2.4752, 0.0, 0.0, 32.7766, 0.0, 50.616, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 15.62\n",
            "Epoch 1.0 >> (class accuracy): [98.9796, 0.0, 0.0, 4.1584, 0.0, 0.0, 41.4405, 0.0, 15.7084, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 11.37, 'per_class_accuracy': [99.898, 0.0, 0.0, 1.2871, 0.0, 0.0, 4.9061, 0.0, 10.0616, 0.0], 'loss': 2.2949466831207275}\n",
            "OCS >> Task 2: {'accuracy': 11.65, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.198, 0.0, 0.0, 4.5929, 0.0, 14.4764, 0.0], 'loss': 2.292726324462891}\n",
            "OCS >> Task 3: {'accuracy': 11.77, 'per_class_accuracy': [99.5918, 0.0, 0.0, 0.0, 0.0, 0.0, 7.2025, 0.0, 13.5524, 0.0], 'loss': 2.291887907791138}\n",
            "OCS >> Task 4: {'accuracy': 11.62, 'per_class_accuracy': [99.5918, 0.0, 0.0, 0.0, 0.0, 0.0, 6.1587, 0.0, 13.039, 0.0], 'loss': 2.2933693603515626}\n",
            "OCS >> Task 5: {'accuracy': 12.03, 'per_class_accuracy': [99.6939, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6534, 0.0, 19.6099, 0.0], 'loss': 2.2911279289245607}\n",
            "OCS >> Task 6: {'accuracy': 11.55, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0271, 0.0, 15.1951, 0.0], 'loss': 2.293495887374878}\n",
            "OCS >> Task 7: {'accuracy': 11.91, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 0.0, 0.0, 9.9165, 0.0, 12.0123, 0.0], 'loss': 2.2940120082855224}\n",
            "OCS >> Task 8: {'accuracy': 11.45, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1148, 0.0, 12.0123, 0.0], 'loss': 2.292328237915039}\n",
            "OCS >> Task 9: {'accuracy': 10.69, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7578, 0.0, 5.5441, 0.0], 'loss': 2.2921529705047607}\n",
            "OCS >> Task 10: {'accuracy': 10.56, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.0, 0.0, 0.0, 5.428, 0.0, 2.6694, 0.0], 'loss': 2.2923392169952392}\n",
            "OCS >> Task 11: {'accuracy': 11.21, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.0, 0.0, 0.0, 11.8998, 0.0, 2.9774, 0.0], 'loss': 2.291320700454712}\n",
            "OCS >> Task 12: {'accuracy': 11.43, 'per_class_accuracy': [99.5918, 0.0, 0.0, 0.0, 0.0, 0.0, 15.2401, 0.0, 2.1561, 0.0], 'loss': 2.290482716369629}\n",
            "OCS >> Task 13: {'accuracy': 12.88, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.0, 0.0, 0.0, 27.7662, 0.0, 4.5175, 0.0], 'loss': 2.29057119140625}\n",
            "OCS >> Task 14: {'accuracy': 12.88, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.198, 0.0, 0.0, 30.3758, 0.0, 1.7454, 0.0], 'loss': 2.289122665786743}\n",
            "OCS >> Task 15: {'accuracy': 13.7, 'per_class_accuracy': [98.8776, 0.0, 0.0, 0.297, 0.0, 0.0, 37.4739, 0.0, 4.0041, 0.0], 'loss': 2.28709732170105}\n",
            "OCS >> Task 16: {'accuracy': 14.22, 'per_class_accuracy': [99.3878, 0.0, 0.0, 0.5941, 0.0, 0.0, 41.858, 0.0, 4.2094, 0.0], 'loss': 2.2818060615539553}\n",
            "OCS >> Task 17: {'accuracy': 14.82, 'per_class_accuracy': [99.2857, 0.0, 0.0, 1.5842, 0.0, 0.0, 45.7203, 0.0, 5.6468, 0.0], 'loss': 2.28075450592041}\n",
            "OCS >> Task 18: {'accuracy': 15.39, 'per_class_accuracy': [98.9796, 0.0, 0.0, 3.9604, 0.0, 0.0, 46.1378, 0.0, 8.9322, 0.0], 'loss': 2.2791185089111328}\n",
            "OCS >> Task 19: {'accuracy': 15.62, 'per_class_accuracy': [98.9796, 0.0, 0.0, 4.1584, 0.0, 0.0, 41.4405, 0.0, 15.7084, 0.0], 'loss': 2.2803449401855467}\n",
            "OCS >> (average accuracy): 12.460526315789474\n",
            "OCS >> (Forgetting): 0.83315\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "---- Task 20 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 14.05\n",
            "Epoch 0.2 >> (class accuracy): [11.9388, 0.0, 0.0, 0.0, 0.0, 0.0, 37.7871, 0.0, 0.0, 91.774]\n",
            "Epoch 0.4 >> (per-task accuracy): 19.02\n",
            "Epoch 0.4 >> (class accuracy): [5.6122, 0.0, 0.0, 52.1782, 0.0, 0.0, 85.3862, 0.0, 0.0, 49.7522]\n",
            "Epoch 0.6 >> (per-task accuracy): 17.09\n",
            "Epoch 0.6 >> (class accuracy): [0.0, 0.0, 0.0, 94.7525, 0.0, 0.0, 75.8873, 0.0, 0.0, 2.4777]\n",
            "Epoch 0.8 >> (per-task accuracy): 14.2\n",
            "Epoch 0.8 >> (class accuracy): [0.0, 0.0, 0.0, 99.604, 0.0, 0.0, 43.215, 0.0, 0.0, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 12.7\n",
            "Epoch 1.0 >> (class accuracy): [0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 27.1399, 0.0, 0.0, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 10.02, 'per_class_accuracy': [0.0, 0.0, 0.0, 98.4158, 0.0, 0.0, 0.8351, 0.0, 0.0, 0.0], 'loss': 2.2998467456817626}\n",
            "OCS >> Task 2: {'accuracy': 10.02, 'per_class_accuracy': [0.0, 0.0, 0.0, 98.5149, 0.0, 0.0, 0.7307, 0.0, 0.0, 0.0], 'loss': 2.2985078762054445}\n",
            "OCS >> Task 3: {'accuracy': 10.05, 'per_class_accuracy': [0.0, 0.0, 0.0, 98.5149, 0.0, 0.0, 1.0438, 0.0, 0.0, 0.0], 'loss': 2.297699324798584}\n",
            "OCS >> Task 4: {'accuracy': 10.17, 'per_class_accuracy': [0.0, 0.0, 0.0, 98.2178, 0.0, 0.0, 2.6096, 0.0, 0.0, 0.0], 'loss': 2.2988323219299316}\n",
            "OCS >> Task 5: {'accuracy': 10.36, 'per_class_accuracy': [0.0, 0.0, 0.0, 97.3267, 0.0, 0.0, 5.5324, 0.0, 0.0, 0.0], 'loss': 2.296809014129639}\n",
            "OCS >> Task 6: {'accuracy': 10.61, 'per_class_accuracy': [0.0, 0.0, 0.0, 94.9505, 0.0, 0.0, 10.6472, 0.0, 0.0, 0.0], 'loss': 2.2986599800109864}\n",
            "OCS >> Task 7: {'accuracy': 10.73, 'per_class_accuracy': [0.0, 0.0, 0.0, 88.8119, 0.0, 0.0, 18.3716, 0.0, 0.0, 0.0], 'loss': 2.2994214916229248}\n",
            "OCS >> Task 8: {'accuracy': 10.57, 'per_class_accuracy': [0.0, 0.0, 0.0, 89.0099, 0.0, 0.0, 16.4927, 0.0, 0.0, 0.0], 'loss': 2.298045182800293}\n",
            "OCS >> Task 9: {'accuracy': 10.83, 'per_class_accuracy': [0.0, 0.0, 0.0, 85.6436, 0.0, 0.0, 22.7557, 0.0, 0.0, 0.0], 'loss': 2.2978052722930906}\n",
            "OCS >> Task 10: {'accuracy': 10.77, 'per_class_accuracy': [0.0, 0.0, 0.0, 73.8614, 0.0, 0.0, 34.5511, 0.0, 0.0, 0.0], 'loss': 2.2978708290100096}\n",
            "OCS >> Task 11: {'accuracy': 12.15, 'per_class_accuracy': [0.0, 0.0, 0.0, 81.3861, 0.0, 0.0, 41.023, 0.0, 0.0, 0.0], 'loss': 2.2969157470703125}\n",
            "OCS >> Task 12: {'accuracy': 12.46, 'per_class_accuracy': [0.0, 0.0, 0.0, 83.0693, 0.0, 0.0, 42.4843, 0.0, 0.0, 0.0], 'loss': 2.2961596019744874}\n",
            "OCS >> Task 13: {'accuracy': 13.3, 'per_class_accuracy': [0.0, 0.0, 0.0, 88.9109, 0.0, 0.0, 45.0939, 0.0, 0.0, 0.0], 'loss': 2.296525260925293}\n",
            "OCS >> Task 14: {'accuracy': 13.12, 'per_class_accuracy': [0.0, 0.0, 0.0, 89.0099, 0.0, 0.0, 43.1106, 0.0, 0.0, 0.0], 'loss': 2.29572071723938}\n",
            "OCS >> Task 15: {'accuracy': 13.41, 'per_class_accuracy': [0.0, 0.0, 0.0, 93.0693, 0.0, 0.0, 41.858, 0.0, 0.0, 0.0], 'loss': 2.294767013168335}\n",
            "OCS >> Task 16: {'accuracy': 13.63, 'per_class_accuracy': [0.0, 0.0, 0.0, 96.6337, 0.0, 0.0, 40.3967, 0.0, 0.0, 0.0], 'loss': 2.2904775829315187}\n",
            "OCS >> Task 17: {'accuracy': 12.85, 'per_class_accuracy': [0.0, 0.0, 0.0, 98.4158, 0.0, 0.0, 30.3758, 0.0, 0.0, 0.0], 'loss': 2.289727654647827}\n",
            "OCS >> Task 18: {'accuracy': 12.67, 'per_class_accuracy': [0.0, 0.0, 0.0, 99.703, 0.0, 0.0, 27.1399, 0.0, 0.0, 0.0], 'loss': 2.2880007061004637}\n",
            "OCS >> Task 19: {'accuracy': 11.82, 'per_class_accuracy': [0.0, 0.0, 0.0, 99.901, 0.0, 0.0, 18.0585, 0.0, 0.0, 0.0], 'loss': 2.288931525039673}\n",
            "OCS >> Task 20: {'accuracy': 12.7, 'per_class_accuracy': [0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 27.1399, 0.0, 0.0, 0.0], 'loss': 2.2860999351501463}\n",
            "OCS >> (average accuracy): 11.611999999999998\n",
            "OCS >> (Forgetting): 0.8404526315789473\n",
            "Maximum per-task accuracies: [95.6]\n",
            "\n",
            "{'num_tasks': 20, 'per_task_rotation': 9, 'memory_size': 200, 'dataset': 'rot-mnist', 'device': 'cuda', 'momentum': 0.8, 'mlp_hiddens': 256, 'dropout': 0.2, 'lr_decay': 0.75, 'n_classes': 10, 'seq_lr': 0.005, 'stream_size': 100, 'ocspick': True, 'batch_size': 20, 'tau': 1000.0, 'ref_hyp': 10.0, 'n_substeps': 5}\n"
          ]
        }
      ],
      "source": [
        "DATASET = 'rot-mnist'\n",
        "HIDDENS = 256\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = {\n",
        "    'num_tasks': 20,\n",
        "    'per_task_rotation': 9,\n",
        "    'memory_size': 200,\n",
        "    'dataset': DATASET,\n",
        "    'device': DEVICE,\n",
        "    'momentum': 0.8,\n",
        "    'mlp_hiddens': HIDDENS,\n",
        "    'dropout': 0.2,\n",
        "    'lr_decay': 0.75 if 'rot-mnist' in DATASET else 0.8,\n",
        "    'n_classes': 10,\n",
        "    'seq_lr': 0.005,\n",
        "    'stream_size': 100,\n",
        "    'ocspick': True,\n",
        "    'batch_size': 20,\n",
        "     'tau': 1000.0,\n",
        "    'ref_hyp': 10. if 'rot-mnist' in DATASET else 50\n",
        "}\n",
        "\n",
        "log_dir =  f\"./summery/{config['dataset']}\"\n",
        "summary = SummaryWriter(log_dir)\n",
        "\n",
        "experiment = Experiment(api_key=\"hidden_key\", project_name=\"mnist\", disabled=True)\n",
        "\n",
        "loaders = get_all_loaders(config)\n",
        "\n",
        "\n",
        "def evaluate_model(model, task, loaders, config):\n",
        "    accuracies, losses = [], []\n",
        "    for t in range(1, task + 1):\n",
        "        metrics = eval_single_epoch(model, loaders['sequential'][t]['val'], config)\n",
        "        accuracies.append(metrics['accuracy'])\n",
        "        losses.append(metrics['loss'])\n",
        "        print(f'OCS >> Task {t}: {metrics}')\n",
        "    return accuracies, losses\n",
        "\n",
        "def main():\n",
        "    setup_experiment(experiment, config)\n",
        "\n",
        "    max_accuracies = [0.0] * config['num_tasks']\n",
        "    for task in range(1, config['num_tasks'] + 1):\n",
        "        print(f'---- Task {task} (OCS) ----')\n",
        "        model = train_task_sequentially(task, loaders, config, summary)\n",
        "\n",
        "        accuracies, _ = evaluate_model(model, task, loaders, config)\n",
        "        max_accuracies = [max(acc, max_acc) for acc, max_acc in zip(accuracies, max_accuracies)]\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies)\n",
        "        if task > 1:\n",
        "            forgetting = np.mean(np.array(max_accuracies[:task - 1]) - np.array(accuracies[:task - 1]))/ 100\n",
        "        else:\n",
        "            forgetting = 0.0\n",
        "\n",
        "        print(f\"OCS >> (average accuracy): {avg_accuracy}\")\n",
        "        print(f\"OCS >> (Forgetting): {forgetting}\")\n",
        "        summary.add_scalar('cl_average_accuracy', avg_accuracy, task - 1)\n",
        "        print(f'Maximum per-task accuracies: {max_accuracies}\\n')\n",
        "\n",
        "    print(config)\n",
        "    experiment.end()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jZpQ5kK1VHk",
        "outputId": "81a082f6-0884-43ed-d0e6-291b8f42c375"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "loading coreset placeholder rot-mnist\n",
            "loading rot-mnist for task 1\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 2\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 3\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 4\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 5\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 6\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 7\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 8\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 9\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 10\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 11\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 12\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 13\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 14\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 15\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 16\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 17\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 18\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 19\n",
            "Rotated MNIST\n",
            "loading rot-mnist for task 20\n",
            "Rotated MNIST\n",
            "---- Task 1 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 82.44\n",
            "Epoch 0.05 >> (class accuracy): [91.2245, 98.2379, 58.3333, 79.2079, 84.4196, 72.0852, 90.7098, 75.8755, 88.2957, 84.44]\n",
            "Epoch 0.1 >> (per-task accuracy): 87.47\n",
            "Epoch 0.1 >> (class accuracy): [97.1429, 98.4141, 78.1008, 71.9802, 98.0652, 87.4439, 89.2484, 89.9805, 84.9076, 78.7909]\n",
            "Epoch 0.15 >> (per-task accuracy): 91.85\n",
            "Epoch 0.15 >> (class accuracy): [94.1837, 98.8546, 90.2132, 89.802, 97.9633, 89.6861, 94.572, 92.4125, 88.2957, 81.665]\n",
            "Epoch 0.2 >> (per-task accuracy): 93.0\n",
            "Epoch 0.2 >> (class accuracy): [95.5102, 98.6784, 85.3682, 90.9901, 96.6395, 96.861, 92.0668, 92.7043, 91.9918, 89.1972]\n",
            "Epoch 0.25 >> (per-task accuracy): 93.89\n",
            "Epoch 0.25 >> (class accuracy): [97.7551, 99.0308, 92.2481, 85.5446, 97.0468, 98.2063, 94.0501, 93.5798, 89.8357, 91.5758]\n",
            "Epoch 0.3 >> (per-task accuracy): 94.51\n",
            "Epoch 0.3 >> (class accuracy): [97.551, 98.8546, 92.2481, 88.6139, 97.1487, 98.6547, 93.737, 93.0934, 91.5811, 93.6571]\n",
            "Epoch 0.35 >> (per-task accuracy): 95.83\n",
            "Epoch 0.35 >> (class accuracy): [97.8571, 98.8546, 95.2519, 90.396, 97.1487, 98.8789, 94.3633, 96.4981, 95.5852, 93.4589]\n",
            "Epoch 0.4 >> (per-task accuracy): 95.88\n",
            "Epoch 0.4 >> (class accuracy): [98.0612, 99.207, 94.2829, 91.7822, 97.3523, 99.2152, 94.4676, 95.6226, 92.8131, 95.9366]\n",
            "Epoch 0.45 >> (per-task accuracy): 96.6\n",
            "Epoch 0.45 >> (class accuracy): [98.5714, 99.2952, 95.155, 91.9802, 97.7597, 98.6547, 95.8246, 95.3307, 97.3306, 96.1348]\n",
            "Epoch 0.5 >> (per-task accuracy): 96.98\n",
            "Epoch 0.5 >> (class accuracy): [99.0816, 99.2952, 96.3178, 96.4356, 96.945, 98.3184, 95.7203, 94.4553, 98.2546, 94.9455]\n",
            "Epoch 0.55 >> (per-task accuracy): 96.7\n",
            "Epoch 0.55 >> (class accuracy): [98.5714, 99.5595, 96.2209, 94.2574, 97.0468, 98.991, 94.1545, 95.5253, 95.6879, 96.8285]\n",
            "Epoch 0.6 >> (per-task accuracy): 95.55\n",
            "Epoch 0.6 >> (class accuracy): [98.0612, 99.6476, 97.9651, 88.3168, 97.1487, 99.4395, 96.1378, 96.4981, 85.4209, 96.5312]\n",
            "Epoch 0.65 >> (per-task accuracy): 97.52\n",
            "Epoch 0.65 >> (class accuracy): [98.5714, 99.4714, 96.8992, 97.4257, 96.945, 98.0942, 95.7203, 96.9844, 97.8439, 97.0268]\n",
            "Epoch 0.7 >> (per-task accuracy): 97.72\n",
            "Epoch 0.7 >> (class accuracy): [98.8776, 99.2952, 97.2868, 97.2277, 98.3707, 98.5426, 96.8685, 96.0117, 97.2279, 97.4232]\n",
            "Epoch 0.75 >> (per-task accuracy): 97.65\n",
            "Epoch 0.75 >> (class accuracy): [99.3878, 99.3833, 97.1899, 98.4158, 97.9633, 98.2063, 97.7035, 96.3035, 95.0719, 96.7294]\n",
            "Epoch 0.8 >> (per-task accuracy): 97.82\n",
            "Epoch 0.8 >> (class accuracy): [99.5918, 99.6476, 97.7713, 96.5347, 97.556, 98.8789, 96.2422, 97.179, 96.6119, 98.0178]\n",
            "Epoch 0.85 >> (per-task accuracy): 97.84\n",
            "Epoch 0.85 >> (class accuracy): [98.9796, 99.7357, 98.062, 97.8218, 98.0652, 98.3184, 95.8246, 98.0545, 96.0986, 97.1259]\n",
            "Epoch 0.6 >> (per-task accuracy): 91.67\n",
            "Epoch 0.6 >> (class accuracy): [94.5918, 98.0617, 90.6977, 91.2871, 93.3809, 85.2018, 92.9019, 91.4397, 88.0903, 89.5937]\n",
            "Epoch 0.65 >> (per-task accuracy): 91.51\n",
            "Epoch 0.65 >> (class accuracy): [94.4898, 97.3568, 88.6628, 92.6733, 93.9919, 84.1928, 92.5887, 90.856, 88.0903, 90.783]\n",
            "Epoch 0.7 >> (per-task accuracy): 92.12\n",
            "Epoch 0.7 >> (class accuracy): [94.3878, 97.8855, 90.5039, 91.8812, 93.89, 86.3229, 93.5282, 92.7043, 89.8357, 88.999]\n",
            "Epoch 0.75 >> (per-task accuracy): 92.13\n",
            "Epoch 0.75 >> (class accuracy): [95.6122, 97.7093, 89.7287, 91.2871, 93.5845, 90.2466, 93.1106, 91.6342, 88.2957, 89.2963]\n",
            "Epoch 0.8 >> (per-task accuracy): 92.03\n",
            "Epoch 0.8 >> (class accuracy): [95.102, 97.7974, 89.6318, 91.4851, 93.279, 87.7803, 93.1106, 92.4125, 88.809, 89.7919]\n",
            "Epoch 0.85 >> (per-task accuracy): 91.94\n",
            "Epoch 0.85 >> (class accuracy): [94.898, 97.7093, 89.9225, 91.7822, 92.4644, 88.1166, 94.3633, 91.0506, 88.6037, 89.4945]\n",
            "Epoch 0.9 >> (per-task accuracy): 92.03\n",
            "Epoch 0.9 >> (class accuracy): [95.2041, 97.8855, 89.3411, 91.0891, 92.4644, 88.0045, 94.3633, 91.8288, 89.7331, 89.3954]\n",
            "Epoch 0.95 >> (per-task accuracy): 92.19\n",
            "Epoch 0.95 >> (class accuracy): [94.4898, 97.9736, 89.1473, 91.3861, 92.9735, 89.3498, 94.3633, 92.0233, 90.2464, 89.0981]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_19281/1459498902.py:12: RuntimeWarning: divide by zero encountered in scalar floor_divide\n",
            "  if (num_residuals // num_class) > 0:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1.0 >> (per-task accuracy): 91.98\n",
            "Epoch 1.0 >> (class accuracy): [94.898, 97.9736, 88.3721, 91.0891, 92.4644, 89.3498, 94.2589, 92.0233, 89.5277, 88.999]\n",
            "OCS >> Task 1: {'accuracy': 90.78, 'per_class_accuracy': [93.3673, 97.533, 85.1744, 89.703, 91.1405, 88.1166, 93.8413, 92.5097, 88.9117, 86.6204], 'loss': 0.38646575004905465}\n",
            "OCS >> Task 2: {'accuracy': 91.98, 'per_class_accuracy': [94.898, 97.9736, 88.3721, 91.0891, 92.4644, 89.3498, 94.2589, 92.0233, 89.5277, 88.999], 'loss': 0.32343514476362617}\n",
            "OCS >> (average accuracy): 91.38\n",
            "OCS >> (Forgetting): 0.07179999999999992\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 3 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 77.47\n",
            "Epoch 0.05 >> (class accuracy): [96.1224, 97.2687, 67.9264, 69.2079, 84.8269, 83.296, 81.3152, 64.5914, 52.9774, 75.9167]\n",
            "Epoch 0.1 >> (per-task accuracy): 81.22\n",
            "Epoch 0.1 >> (class accuracy): [95.4082, 96.9163, 75.1938, 90.396, 88.5947, 71.5247, 88.7265, 66.3424, 71.4579, 65.6095]\n",
            "Epoch 0.15 >> (per-task accuracy): 83.18\n",
            "Epoch 0.15 >> (class accuracy): [95.102, 96.4758, 82.1705, 89.2079, 85.947, 65.8072, 89.7704, 68.1907, 76.694, 79.5837]\n",
            "Epoch 0.2 >> (per-task accuracy): 83.78\n",
            "Epoch 0.2 >> (class accuracy): [95.0, 95.7709, 79.7481, 88.0198, 86.2525, 72.3094, 91.4405, 68.1907, 79.7741, 79.4846]\n",
            "Epoch 0.25 >> (per-task accuracy): 85.22\n",
            "Epoch 0.25 >> (class accuracy): [94.5918, 94.7137, 83.2364, 89.2079, 90.3259, 70.9641, 91.858, 73.4436, 81.6222, 80.2775]\n",
            "Epoch 0.3 >> (per-task accuracy): 85.44\n",
            "Epoch 0.3 >> (class accuracy): [95.102, 95.5947, 82.4612, 90.099, 88.2892, 73.7668, 91.6493, 76.9455, 78.6448, 79.8811]\n",
            "Epoch 0.35 >> (per-task accuracy): 85.63\n",
            "Epoch 0.35 >> (class accuracy): [97.0408, 97.1806, 83.0426, 89.2079, 89.5112, 74.5516, 87.9958, 77.0428, 81.1088, 77.5025]\n",
            "Epoch 0.4 >> (per-task accuracy): 85.92\n",
            "Epoch 0.4 >> (class accuracy): [95.102, 96.9163, 82.5581, 90.0, 90.5295, 74.6637, 88.2046, 81.0311, 80.5955, 77.4034]\n",
            "Epoch 0.45 >> (per-task accuracy): 85.26\n",
            "Epoch 0.45 >> (class accuracy): [95.9184, 97.1806, 81.3953, 87.9208, 89.7149, 72.1973, 89.666, 77.1401, 81.2115, 77.998]\n",
            "Epoch 0.5 >> (per-task accuracy): 86.22\n",
            "Epoch 0.5 >> (class accuracy): [96.0204, 97.0925, 81.7829, 90.6931, 89.4094, 75.3363, 93.0063, 79.1829, 79.3634, 78.3944]\n",
            "Epoch 0.55 >> (per-task accuracy): 86.09\n",
            "Epoch 0.55 >> (class accuracy): [95.2041, 96.652, 82.5581, 88.7129, 91.8534, 72.6457, 92.9019, 80.0584, 77.8234, 80.2775]\n",
            "Epoch 0.6 >> (per-task accuracy): 86.88\n",
            "Epoch 0.6 >> (class accuracy): [95.4082, 96.7401, 81.3953, 92.0792, 91.5479, 72.1973, 89.666, 82.9767, 81.2115, 83.1516]\n",
            "Epoch 0.65 >> (per-task accuracy): 87.05\n",
            "Epoch 0.65 >> (class accuracy): [94.5918, 96.652, 83.1395, 90.7921, 90.5295, 72.5336, 93.4238, 82.0039, 81.3142, 83.2507]\n",
            "Epoch 0.7 >> (per-task accuracy): 87.02\n",
            "Epoch 0.7 >> (class accuracy): [95.9184, 96.5639, 83.3333, 90.0, 90.224, 76.7937, 92.4843, 77.3346, 82.0329, 83.8454]\n",
            "Epoch 0.75 >> (per-task accuracy): 87.57\n",
            "Epoch 0.75 >> (class accuracy): [95.6122, 96.7401, 82.9457, 91.0891, 92.2607, 75.2242, 93.215, 77.3346, 85.0103, 84.5391]\n",
            "Epoch 0.8 >> (per-task accuracy): 87.45\n",
            "Epoch 0.8 >> (class accuracy): [96.0204, 96.7401, 82.1705, 90.8911, 92.5662, 73.991, 92.2756, 79.3774, 83.0595, 85.4311]\n",
            "Epoch 0.85 >> (per-task accuracy): 87.51\n",
            "Epoch 0.85 >> (class accuracy): [95.3061, 96.652, 83.0426, 90.6931, 92.057, 74.4395, 92.4843, 79.1829, 86.7556, 82.6561]\n",
            "Epoch 0.9 >> (per-task accuracy): 87.09\n",
            "Epoch 0.9 >> (class accuracy): [95.0, 96.8282, 81.5891, 91.4851, 91.3442, 77.2422, 93.3194, 77.7237, 80.5955, 84.1427]\n",
            "Epoch 0.95 >> (per-task accuracy): 86.85\n",
            "Epoch 0.95 >> (class accuracy): [95.5102, 96.8282, 81.7829, 90.6931, 90.5295, 77.4664, 93.3194, 77.2374, 79.7741, 83.7463]\n",
            "Epoch 1.0 >> (per-task accuracy): 87.01\n",
            "Epoch 1.0 >> (class accuracy): [95.4082, 96.7401, 80.4264, 91.3861, 92.2607, 77.2422, 93.0063, 77.4319, 81.1088, 83.5481]\n",
            "OCS >> Task 1: {'accuracy': 78.83, 'per_class_accuracy': [93.6735, 93.7445, 52.4225, 67.8218, 78.9206, 74.6637, 93.737, 80.1556, 74.23, 78.1962], 'loss': 1.0429340502262114}\n",
            "OCS >> Task 2: {'accuracy': 84.3, 'per_class_accuracy': [94.6939, 95.0661, 73.2558, 82.7723, 87.5764, 76.9058, 93.9457, 78.9883, 78.1314, 80.4757], 'loss': 0.6902098871856928}\n",
            "OCS >> Task 3: {'accuracy': 87.01, 'per_class_accuracy': [95.4082, 96.7401, 80.4264, 91.3861, 92.2607, 77.2422, 93.0063, 77.4319, 81.1088, 83.5481], 'loss': 0.5477434602022171}\n",
            "OCS >> (average accuracy): 83.38\n",
            "OCS >> (Forgetting): 0.16394999999999996\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 4 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 80.78\n",
            "Epoch 0.05 >> (class accuracy): [95.0, 95.859, 80.0388, 86.1386, 81.2627, 72.4215, 89.4572, 69.8444, 64.3737, 71.0605]\n",
            "Epoch 0.1 >> (per-task accuracy): 78.92\n",
            "Epoch 0.1 >> (class accuracy): [94.2857, 93.0396, 70.3488, 90.6931, 81.2627, 68.3857, 88.6221, 53.7938, 69.9179, 77.2052]\n",
            "Epoch 0.15 >> (per-task accuracy): 80.41\n",
            "Epoch 0.15 >> (class accuracy): [93.5714, 93.0396, 77.7132, 90.297, 79.3279, 71.861, 84.9687, 57.9767, 65.2977, 88.0079]\n",
            "Epoch 0.2 >> (per-task accuracy): 80.87\n",
            "Epoch 0.2 >> (class accuracy): [93.6735, 92.5991, 75.4845, 89.2079, 87.169, 74.3274, 87.5783, 59.8249, 61.2936, 86.0258]\n",
            "Epoch 0.25 >> (per-task accuracy): 82.59\n",
            "Epoch 0.25 >> (class accuracy): [94.4898, 93.7445, 74.3217, 88.8119, 88.9002, 77.4664, 88.4134, 64.2023, 67.7618, 86.6204]\n",
            "Epoch 0.3 >> (per-task accuracy): 82.78\n",
            "Epoch 0.3 >> (class accuracy): [94.2857, 91.9824, 76.938, 90.5941, 89.002, 72.0852, 87.4739, 69.0661, 68.4805, 86.1249]\n",
            "Epoch 0.35 >> (per-task accuracy): 82.71\n",
            "Epoch 0.35 >> (class accuracy): [92.9592, 94.2731, 78.1977, 92.0792, 89.2057, 72.0852, 86.6388, 65.2724, 67.5565, 86.7195]\n",
            "Epoch 0.4 >> (per-task accuracy): 82.86\n",
            "Epoch 0.4 >> (class accuracy): [94.0816, 92.5991, 75.3876, 92.2772, 87.78, 76.6816, 87.2651, 64.786, 68.8912, 87.6115]\n",
            "Epoch 0.45 >> (per-task accuracy): 83.4\n",
            "Epoch 0.45 >> (class accuracy): [95.9184, 94.0088, 78.9729, 85.4455, 89.613, 75.3363, 88.8309, 62.6459, 74.538, 87.4133]\n",
            "Epoch 0.5 >> (per-task accuracy): 83.39\n",
            "Epoch 0.5 >> (class accuracy): [94.5918, 94.3612, 77.0349, 91.6832, 88.6965, 75.3363, 88.1002, 66.1479, 70.0205, 86.3231]\n",
            "Epoch 0.55 >> (per-task accuracy): 83.6\n",
            "Epoch 0.55 >> (class accuracy): [94.4898, 94.2731, 75.4845, 92.3762, 89.613, 75.1121, 89.8747, 64.1051, 73.4086, 85.9267]\n",
            "Epoch 0.6 >> (per-task accuracy): 84.21\n",
            "Epoch 0.6 >> (class accuracy): [95.102, 94.6256, 77.6163, 92.4752, 88.7984, 76.1211, 88.7265, 69.1634, 70.9446, 86.9177]\n",
            "Epoch 0.65 >> (per-task accuracy): 83.5\n",
            "Epoch 0.65 >> (class accuracy): [94.6939, 94.3612, 77.6163, 91.7822, 87.3727, 74.5516, 88.4134, 68.5798, 68.1725, 87.6115]\n",
            "Epoch 0.7 >> (per-task accuracy): 83.53\n",
            "Epoch 0.7 >> (class accuracy): [94.2857, 94.3612, 78.7791, 92.6733, 85.947, 72.6457, 90.7098, 66.4397, 71.2526, 86.3231]\n",
            "Epoch 0.75 >> (per-task accuracy): 83.89\n",
            "Epoch 0.75 >> (class accuracy): [94.6939, 94.6256, 78.1008, 92.1782, 89.3075, 74.2152, 91.4405, 66.0506, 69.6099, 87.0168]\n",
            "Epoch 0.8 >> (per-task accuracy): 83.81\n",
            "Epoch 0.8 >> (class accuracy): [95.5102, 95.5947, 75.1938, 92.7723, 88.7984, 74.6637, 90.8142, 65.7588, 73.5113, 83.9445]\n",
            "Epoch 0.85 >> (per-task accuracy): 84.11\n",
            "Epoch 0.85 >> (class accuracy): [94.898, 94.5374, 75.1938, 92.4752, 90.3259, 75.7848, 91.2317, 67.607, 74.4353, 83.3499]\n",
            "Epoch 0.9 >> (per-task accuracy): 84.18\n",
            "Epoch 0.9 >> (class accuracy): [94.2857, 94.6256, 74.3217, 93.3663, 92.3625, 75.7848, 91.4405, 68.1907, 73.5113, 82.6561]\n",
            "Epoch 0.95 >> (per-task accuracy): 83.94\n",
            "Epoch 0.95 >> (class accuracy): [94.7959, 94.5374, 76.0659, 91.7822, 90.5295, 75.1121, 91.858, 67.1206, 72.0739, 84.1427]\n",
            "Epoch 1.0 >> (per-task accuracy): 84.6\n",
            "Epoch 1.0 >> (class accuracy): [95.4082, 94.7137, 78.1008, 92.7723, 91.0387, 75.1121, 91.2317, 65.4669, 77.4127, 83.449]\n",
            "OCS >> Task 1: {'accuracy': 70.74, 'per_class_accuracy': [91.7347, 88.1057, 43.7984, 66.3366, 63.6456, 51.9058, 93.3194, 70.9144, 59.6509, 75.4212], 'loss': 1.55426415681839}\n",
            "OCS >> Task 2: {'accuracy': 79.74, 'per_class_accuracy': [93.4694, 96.9163, 61.2403, 83.3663, 76.8839, 68.4978, 92.1712, 71.8872, 72.5873, 78.1962], 'loss': 0.9885289946317672}\n",
            "OCS >> Task 3: {'accuracy': 84.05, 'per_class_accuracy': [95.0, 97.4449, 72.2868, 91.0891, 86.8635, 72.9821, 92.7975, 69.6498, 78.6448, 81.9623], 'loss': 0.7240459156274796}\n",
            "OCS >> Task 4: {'accuracy': 84.6, 'per_class_accuracy': [95.4082, 94.7137, 78.1008, 92.7723, 91.0387, 75.1121, 91.2317, 65.4669, 77.4127, 83.449], 'loss': 0.6848206220000982}\n",
            "OCS >> (average accuracy): 79.7825\n",
            "OCS >> (Forgetting): 0.1978333333333333\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 5 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 76.04\n",
            "Epoch 0.05 >> (class accuracy): [91.0204, 95.9471, 80.1357, 80.297, 78.2077, 58.7444, 83.6117, 60.4086, 73.1006, 55.4014]\n",
            "Epoch 0.1 >> (per-task accuracy): 74.23\n",
            "Epoch 0.1 >> (class accuracy): [91.3265, 88.7225, 67.1512, 76.6337, 74.1344, 73.6547, 84.7599, 36.284, 71.7659, 77.7998]\n",
            "Epoch 0.15 >> (per-task accuracy): 76.33\n",
            "Epoch 0.15 >> (class accuracy): [92.6531, 91.1013, 60.7558, 80.5941, 81.3646, 77.3543, 87.2651, 47.7626, 68.7885, 75.7185]\n",
            "Epoch 0.2 >> (per-task accuracy): 77.57\n",
            "Epoch 0.2 >> (class accuracy): [90.8163, 91.0132, 66.8605, 80.396, 89.7149, 79.8206, 80.7933, 47.4708, 68.7885, 79.9802]\n",
            "Epoch 0.25 >> (per-task accuracy): 77.12\n",
            "Epoch 0.25 >> (class accuracy): [90.102, 91.8943, 70.5426, 77.7228, 91.8534, 72.9821, 78.7056, 48.249, 73.7166, 74.5292]\n",
            "Epoch 0.3 >> (per-task accuracy): 79.64\n",
            "Epoch 0.3 >> (class accuracy): [91.0204, 91.0132, 71.3178, 85.5446, 92.4644, 77.13, 82.1503, 55.2529, 71.2526, 78.6918]\n",
            "Epoch 0.35 >> (per-task accuracy): 79.77\n",
            "Epoch 0.35 >> (class accuracy): [95.2041, 91.8943, 69.7674, 82.0792, 89.7149, 80.3812, 84.9687, 53.0156, 69.4045, 81.1695]\n",
            "Epoch 0.4 >> (per-task accuracy): 79.51\n",
            "Epoch 0.4 >> (class accuracy): [94.5918, 93.304, 69.9612, 79.802, 89.7149, 76.5695, 87.7871, 48.5409, 72.4846, 81.9623]\n",
            "Epoch 0.45 >> (per-task accuracy): 80.0\n",
            "Epoch 0.45 >> (class accuracy): [90.8163, 94.0969, 69.0891, 84.5545, 93.0754, 76.9058, 86.8476, 48.6381, 73.2033, 82.2597]\n",
            "Epoch 0.5 >> (per-task accuracy): 80.48\n",
            "Epoch 0.5 >> (class accuracy): [92.0408, 94.5374, 69.6705, 85.6436, 91.446, 78.139, 87.3695, 53.7938, 68.8912, 82.557]\n",
            "Epoch 0.55 >> (per-task accuracy): 80.72\n",
            "Epoch 0.55 >> (class accuracy): [91.8367, 93.1278, 71.8023, 85.0495, 91.7515, 79.7085, 87.1608, 52.7237, 72.2793, 81.4668]\n",
            "Epoch 0.6 >> (per-task accuracy): 80.78\n",
            "Epoch 0.6 >> (class accuracy): [90.5102, 94.0969, 67.7326, 84.9505, 91.9552, 78.8117, 87.1608, 57.6848, 71.9713, 82.3588]\n",
            "Epoch 0.65 >> (per-task accuracy): 81.43\n",
            "Epoch 0.65 >> (class accuracy): [90.7143, 93.2159, 73.5465, 84.8515, 92.668, 80.6054, 88.7265, 55.5447, 72.2793, 81.8632]\n",
            "Epoch 0.7 >> (per-task accuracy): 80.98\n",
            "Epoch 0.7 >> (class accuracy): [92.1429, 94.0969, 72.2868, 86.8317, 89.8167, 77.13, 87.7871, 52.4319, 72.7926, 83.7463]\n",
            "Epoch 0.75 >> (per-task accuracy): 80.91\n",
            "Epoch 0.75 >> (class accuracy): [90.9184, 93.4802, 70.3488, 86.7327, 91.446, 79.2601, 87.2651, 53.8911, 72.6899, 82.6561]\n",
            "Epoch 0.8 >> (per-task accuracy): 81.04\n",
            "Epoch 0.8 >> (class accuracy): [91.4286, 94.185, 71.9961, 84.4554, 92.8717, 78.6996, 88.1002, 56.1284, 69.5072, 82.3588]\n",
            "Epoch 0.85 >> (per-task accuracy): 81.57\n",
            "Epoch 0.85 >> (class accuracy): [90.3061, 93.7445, 69.9612, 84.6535, 89.8167, 79.8206, 90.1879, 58.8521, 73.922, 84.0436]\n",
            "Epoch 0.9 >> (per-task accuracy): 81.23\n",
            "Epoch 0.9 >> (class accuracy): [91.0204, 94.0969, 68.2171, 85.4455, 90.0204, 79.0359, 91.023, 57.7821, 71.1499, 84.0436]\n",
            "Epoch 0.95 >> (per-task accuracy): 81.64\n",
            "Epoch 0.95 >> (class accuracy): [90.7143, 94.0088, 71.0271, 84.9505, 91.5479, 80.4933, 91.023, 56.7121, 72.7926, 82.8543]\n",
            "Epoch 1.0 >> (per-task accuracy): 80.78\n",
            "Epoch 1.0 >> (class accuracy): [91.3265, 93.7445, 66.0853, 85.3465, 91.3442, 79.0359, 91.4405, 56.7121, 70.5339, 81.9623]\n",
            "OCS >> Task 1: {'accuracy': 66.32, 'per_class_accuracy': [88.0612, 89.7797, 42.1512, 50.6931, 63.6456, 49.8879, 92.4843, 71.7899, 43.6345, 67.7899], 'loss': 1.7735641683578491}\n",
            "OCS >> Task 2: {'accuracy': 75.53, 'per_class_accuracy': [91.3265, 97.4449, 54.7481, 69.2079, 74.9491, 66.3677, 92.0668, 71.5953, 61.807, 73.3399], 'loss': 1.1624286857128143}\n",
            "OCS >> Task 3: {'accuracy': 81.24, 'per_class_accuracy': [91.0204, 97.8855, 67.8295, 84.5545, 86.1507, 74.6637, 94.6764, 67.1206, 68.4805, 78.3944], 'loss': 0.8443898060560227}\n",
            "OCS >> Task 4: {'accuracy': 82.92, 'per_class_accuracy': [90.102, 97.7974, 74.7093, 87.9208, 91.9552, 78.8117, 94.3633, 62.9377, 69.7125, 79.6829], 'loss': 0.7359140830636024}\n",
            "OCS >> Task 5: {'accuracy': 80.78, 'per_class_accuracy': [91.3265, 93.7445, 66.0853, 85.3465, 91.3442, 79.0359, 91.4405, 56.7121, 70.5339, 81.9623], 'loss': 0.8190062425613404}\n",
            "OCS >> (average accuracy): 77.35799999999999\n",
            "OCS >> (Forgetting): 0.21457499999999996\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 6 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 72.34\n",
            "Epoch 0.05 >> (class accuracy): [93.8776, 94.7137, 65.9884, 78.6139, 75.0509, 45.4036, 81.6284, 56.9066, 66.7351, 59.9604]\n",
            "Epoch 0.1 >> (per-task accuracy): 69.98\n",
            "Epoch 0.1 >> (class accuracy): [89.898, 86.6079, 57.5581, 76.1386, 70.6721, 69.1704, 85.2818, 41.8288, 51.4374, 70.5649]\n",
            "Epoch 0.15 >> (per-task accuracy): 71.46\n",
            "Epoch 0.15 >> (class accuracy): [86.2245, 86.5198, 53.7791, 70.8911, 81.0591, 70.7399, 87.2651, 45.428, 60.6776, 72.0515]\n",
            "Epoch 0.2 >> (per-task accuracy): 73.52\n",
            "Epoch 0.2 >> (class accuracy): [89.5918, 90.4846, 55.6202, 79.802, 82.8921, 72.9821, 78.1837, 52.3346, 56.2628, 76.0159]\n",
            "Epoch 0.25 >> (per-task accuracy): 74.92\n",
            "Epoch 0.25 >> (class accuracy): [87.8571, 88.8987, 58.1395, 81.4851, 84.7251, 77.5785, 84.6555, 51.4591, 61.499, 72.9435]\n",
            "Epoch 0.3 >> (per-task accuracy): 75.22\n",
            "Epoch 0.3 >> (class accuracy): [87.6531, 89.8678, 57.655, 78.2178, 87.3727, 75.2242, 85.6994, 57.0039, 59.8563, 73.2408]\n",
            "Epoch 0.35 >> (per-task accuracy): 77.3\n",
            "Epoch 0.35 >> (class accuracy): [90.9184, 90.6608, 63.7597, 81.0891, 89.7149, 73.7668, 84.5511, 60.8949, 63.8604, 72.9435]\n",
            "Epoch 0.4 >> (per-task accuracy): 76.49\n",
            "Epoch 0.4 >> (class accuracy): [88.2653, 90.3084, 58.9147, 82.4752, 87.9837, 76.4574, 82.3591, 58.2685, 61.3963, 77.8989]\n",
            "Epoch 0.45 >> (per-task accuracy): 76.92\n",
            "Epoch 0.45 >> (class accuracy): [88.1633, 90.4846, 61.6279, 80.8911, 91.2424, 75.6726, 81.0021, 61.5759, 62.0123, 75.7185]\n",
            "Epoch 0.5 >> (per-task accuracy): 76.27\n",
            "Epoch 0.5 >> (class accuracy): [87.3469, 92.2467, 58.7209, 79.4059, 91.0387, 74.5516, 79.7495, 63.3268, 60.5749, 74.5292]\n",
            "Epoch 0.55 >> (per-task accuracy): 76.84\n",
            "Epoch 0.55 >> (class accuracy): [85.9184, 91.2775, 59.6899, 80.8911, 90.0204, 76.6816, 85.0731, 62.6459, 61.807, 73.7364]\n",
            "Epoch 0.6 >> (per-task accuracy): 77.5\n",
            "Epoch 0.6 >> (class accuracy): [84.0816, 92.2467, 59.9806, 80.297, 92.4644, 79.7085, 82.9854, 64.2023, 65.1951, 73.3399]\n",
            "Epoch 0.65 >> (per-task accuracy): 77.13\n",
            "Epoch 0.65 >> (class accuracy): [87.1429, 91.5419, 60.7558, 80.198, 91.7515, 77.8027, 83.1942, 61.8677, 60.9856, 75.4212]\n",
            "Epoch 0.7 >> (per-task accuracy): 77.36\n",
            "Epoch 0.7 >> (class accuracy): [87.8571, 91.0132, 65.0194, 78.0198, 92.2607, 76.4574, 82.2547, 63.716, 61.3963, 74.7275]\n",
            "Epoch 0.75 >> (per-task accuracy): 76.3\n",
            "Epoch 0.75 >> (class accuracy): [86.9388, 89.6035, 59.8837, 79.3069, 92.7699, 78.2511, 82.7766, 61.4786, 57.1869, 74.4301]\n",
            "Epoch 0.8 >> (per-task accuracy): 76.83\n",
            "Epoch 0.8 >> (class accuracy): [88.0612, 90.4846, 60.8527, 80.8911, 91.1405, 78.4753, 83.6117, 64.1051, 55.5441, 74.5292]\n",
            "Epoch 0.85 >> (per-task accuracy): 76.16\n",
            "Epoch 0.85 >> (class accuracy): [86.9388, 91.2775, 59.593, 77.9208, 91.5479, 78.8117, 83.8205, 63.2296, 52.9774, 74.8266]\n",
            "Epoch 0.9 >> (per-task accuracy): 77.05\n",
            "Epoch 0.9 >> (class accuracy): [87.551, 90.7489, 60.0775, 81.1881, 92.2607, 79.0359, 84.6555, 62.4514, 56.5708, 75.5203]\n",
            "Epoch 0.95 >> (per-task accuracy): 78.43\n",
            "Epoch 0.95 >> (class accuracy): [89.1837, 91.2775, 60.7558, 84.2574, 91.5479, 79.148, 85.1775, 65.2724, 61.9097, 75.3221]\n",
            "Epoch 1.0 >> (per-task accuracy): 77.28\n",
            "Epoch 1.0 >> (class accuracy): [89.2857, 89.9559, 57.9457, 81.2871, 90.5295, 77.9148, 86.7432, 64.2996, 57.0842, 77.4034]\n",
            "OCS >> Task 1: {'accuracy': 60.48, 'per_class_accuracy': [89.1837, 78.0617, 34.2054, 42.2772, 59.776, 31.3901, 92.0668, 65.4669, 44.1478, 65.0149], 'loss': 2.144743554496765}\n",
            "OCS >> Task 2: {'accuracy': 70.62, 'per_class_accuracy': [91.2245, 92.8634, 42.2481, 61.5842, 69.9593, 52.13, 92.6931, 68.2879, 60.1643, 72.1506], 'loss': 1.4295515770435334}\n",
            "OCS >> Task 3: {'accuracy': 77.42, 'per_class_accuracy': [91.7347, 97.533, 56.9767, 76.2376, 80.2444, 68.9462, 93.6326, 67.3152, 68.3778, 71.3578], 'loss': 1.0193008305072784}\n",
            "OCS >> Task 4: {'accuracy': 81.23, 'per_class_accuracy': [90.8163, 97.9736, 63.6628, 82.9703, 87.169, 76.6816, 93.9457, 70.3307, 72.2793, 75.223], 'loss': 0.7841790870547295}\n",
            "OCS >> Task 5: {'accuracy': 81.02, 'per_class_accuracy': [90.7143, 95.7709, 64.5349, 83.8614, 90.0204, 79.2601, 90.8142, 68.677, 65.0924, 80.4757], 'loss': 0.7726859580516815}\n",
            "OCS >> Task 6: {'accuracy': 77.28, 'per_class_accuracy': [89.2857, 89.9559, 57.9457, 81.2871, 90.5295, 77.9148, 86.7432, 64.2996, 57.0842, 77.4034], 'loss': 0.909821292424202}\n",
            "OCS >> (average accuracy): 74.675\n",
            "OCS >> (Forgetting): 0.23805999999999994\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 7 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 60.38\n",
            "Epoch 0.05 >> (class accuracy): [91.8367, 49.7797, 59.3992, 85.4455, 51.5275, 27.3543, 77.7662, 64.9805, 21.7659, 71.556]\n",
            "Epoch 0.1 >> (per-task accuracy): 64.5\n",
            "Epoch 0.1 >> (class accuracy): [87.1429, 69.3392, 51.8411, 78.4158, 68.8391, 47.5336, 86.2213, 42.8988, 54.6201, 57.78]\n",
            "Epoch 0.15 >> (per-task accuracy): 69.22\n",
            "Epoch 0.15 >> (class accuracy): [88.6735, 90.6608, 47.5775, 75.4455, 70.6721, 48.7668, 79.2276, 50.7782, 66.1191, 71.0605]\n",
            "Epoch 0.2 >> (per-task accuracy): 71.52\n",
            "Epoch 0.2 >> (class accuracy): [85.6122, 86.2555, 54.4574, 77.7228, 75.8656, 58.296, 83.1942, 50.5837, 69.7125, 71.9524]\n",
            "Epoch 0.25 >> (per-task accuracy): 72.9\n",
            "Epoch 0.25 >> (class accuracy): [86.5306, 87.3128, 59.8837, 78.2178, 72.5051, 64.6861, 83.6117, 52.3346, 70.1232, 72.5471]\n",
            "Epoch 0.3 >> (per-task accuracy): 74.39\n",
            "Epoch 0.3 >> (class accuracy): [86.6327, 85.6388, 71.7054, 76.3366, 76.9857, 62.3318, 82.0459, 58.6576, 65.6057, 76.0159]\n",
            "Epoch 0.35 >> (per-task accuracy): 73.91\n",
            "Epoch 0.35 >> (class accuracy): [85.0, 85.815, 64.1473, 79.3069, 76.2729, 66.3677, 82.2547, 57.8794, 64.3737, 76.3132]\n",
            "Epoch 0.4 >> (per-task accuracy): 74.92\n",
            "Epoch 0.4 >> (class accuracy): [84.6939, 86.696, 65.6008, 78.3168, 79.2261, 72.3094, 82.0459, 60.9922, 63.347, 75.0248]\n",
            "Epoch 0.45 >> (per-task accuracy): 75.46\n",
            "Epoch 0.45 >> (class accuracy): [85.9184, 88.37, 61.8217, 76.2376, 79.9389, 71.9731, 79.8539, 63.5214, 66.1191, 79.6829]\n",
            "Epoch 0.5 >> (per-task accuracy): 76.0\n",
            "Epoch 0.5 >> (class accuracy): [84.4898, 88.0176, 67.2481, 76.2376, 80.8554, 75.1121, 81.6284, 64.5914, 64.1684, 76.7096]\n",
            "Epoch 0.55 >> (per-task accuracy): 75.47\n",
            "Epoch 0.55 >> (class accuracy): [84.6939, 88.7225, 67.6357, 80.0, 80.0407, 72.7578, 76.7223, 63.716, 61.807, 77.0069]\n",
            "Epoch 0.6 >> (per-task accuracy): 75.52\n",
            "Epoch 0.6 >> (class accuracy): [82.6531, 88.5463, 64.438, 77.8218, 82.2811, 73.4305, 79.3319, 61.5759, 65.2977, 78.6918]\n",
            "Epoch 0.65 >> (per-task accuracy): 76.38\n",
            "Epoch 0.65 >> (class accuracy): [85.102, 88.1938, 64.6318, 77.5248, 80.8554, 77.2422, 80.3758, 66.2451, 65.8111, 77.106]\n",
            "Epoch 0.7 >> (per-task accuracy): 75.42\n",
            "Epoch 0.7 >> (class accuracy): [83.2653, 88.37, 64.8256, 79.0099, 80.2444, 72.5336, 81.3152, 63.4241, 62.0123, 77.8989]\n",
            "Epoch 0.75 >> (per-task accuracy): 76.46\n",
            "Epoch 0.75 >> (class accuracy): [84.898, 89.2511, 64.6318, 79.604, 86.3544, 74.2152, 81.524, 64.3969, 60.9856, 77.6016]\n",
            "Epoch 0.8 >> (per-task accuracy): 77.51\n",
            "Epoch 0.8 >> (class accuracy): [85.4082, 89.6916, 65.8915, 79.505, 85.5397, 73.4305, 81.4196, 68.1907, 66.6324, 78.0971]\n",
            "Epoch 0.85 >> (per-task accuracy): 77.81\n",
            "Epoch 0.85 >> (class accuracy): [86.7347, 89.6035, 64.6318, 77.7228, 85.5397, 77.3543, 82.7766, 65.7588, 66.9405, 80.3766]\n",
            "Epoch 0.9 >> (per-task accuracy): 77.84\n",
            "Epoch 0.9 >> (class accuracy): [87.9592, 88.8106, 67.9264, 76.7327, 81.7719, 77.6906, 84.238, 65.4669, 65.1951, 81.9623]\n",
            "Epoch 0.95 >> (per-task accuracy): 77.22\n",
            "Epoch 0.95 >> (class accuracy): [85.5102, 89.6916, 61.0465, 77.4257, 83.6049, 78.0269, 85.8038, 68.2879, 63.7577, 78.4936]\n",
            "Epoch 1.0 >> (per-task accuracy): 78.01\n",
            "Epoch 1.0 >> (class accuracy): [84.7959, 90.1322, 68.7984, 78.4158, 84.0122, 76.7937, 85.2818, 65.6615, 64.8871, 80.3766]\n",
            "OCS >> Task 1: {'accuracy': 59.62, 'per_class_accuracy': [86.9388, 76.0352, 30.2326, 46.3366, 59.165, 33.296, 89.1441, 66.7315, 51.848, 53.9148], 'loss': 2.1651472079277037}\n",
            "OCS >> Task 2: {'accuracy': 69.5, 'per_class_accuracy': [88.5714, 92.8634, 39.0504, 62.7723, 67.8208, 54.3722, 91.6493, 69.5525, 63.4497, 62.3389], 'loss': 1.492498528957367}\n",
            "OCS >> Task 3: {'accuracy': 75.58, 'per_class_accuracy': [88.3673, 97.4449, 56.1047, 76.5347, 76.6802, 67.1525, 92.7975, 71.8872, 64.8871, 61.6452], 'loss': 1.0887669372558593}\n",
            "OCS >> Task 4: {'accuracy': 79.49, 'per_class_accuracy': [86.1224, 98.1498, 65.9884, 82.5743, 82.4847, 74.8879, 93.5282, 70.9144, 70.3285, 68.1863], 'loss': 0.8465263966560364}\n",
            "OCS >> Task 5: {'accuracy': 81.39, 'per_class_accuracy': [87.3469, 95.7709, 69.4767, 84.2574, 84.5214, 81.278, 92.6931, 73.4436, 69.5072, 74.6283], 'loss': 0.7333659567713737}\n",
            "OCS >> Task 6: {'accuracy': 79.74, 'per_class_accuracy': [85.9184, 95.3304, 67.345, 81.4851, 85.5397, 81.7265, 88.9353, 71.9844, 67.3511, 70.8622], 'loss': 0.7819923717737198}\n",
            "OCS >> Task 7: {'accuracy': 78.01, 'per_class_accuracy': [84.7959, 90.1322, 68.7984, 78.4158, 84.0122, 76.7937, 85.2818, 65.6615, 64.8871, 80.3766], 'loss': 0.8638679404973983}\n",
            "OCS >> (average accuracy): 74.76142857142858\n",
            "OCS >> (Forgetting): 0.23739999999999994\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 8 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 37.35\n",
            "Epoch 0.05 >> (class accuracy): [95.102, 1.1454, 22.2868, 85.1485, 1.6293, 0.0, 27.7662, 18.5798, 31.7248, 90.9812]\n",
            "Epoch 0.1 >> (per-task accuracy): 58.33\n",
            "Epoch 0.1 >> (class accuracy): [88.0612, 42.2026, 47.5775, 58.4158, 48.5743, 37.2197, 78.7056, 42.8016, 73.5113, 68.4836]\n",
            "Epoch 0.15 >> (per-task accuracy): 60.75\n",
            "Epoch 0.15 >> (class accuracy): [87.6531, 42.6432, 43.314, 65.1485, 48.5743, 41.704, 85.595, 51.9455, 71.6632, 71.9524]\n",
            "Epoch 0.2 >> (per-task accuracy): 62.56\n",
            "Epoch 0.2 >> (class accuracy): [87.9592, 46.1674, 46.5116, 68.6139, 52.8513, 48.5426, 85.4906, 57.6848, 66.6324, 67.7899]\n",
            "Epoch 0.25 >> (per-task accuracy): 65.44\n",
            "Epoch 0.25 >> (class accuracy): [86.4286, 53.5683, 53.876, 68.2178, 54.1752, 57.287, 85.8038, 63.9105, 64.0657, 69.1774]\n",
            "Epoch 0.3 >> (per-task accuracy): 67.08\n",
            "Epoch 0.3 >> (class accuracy): [85.8163, 65.7269, 52.4225, 70.9901, 61.2016, 59.9776, 83.4029, 61.7704, 62.2177, 68.0872]\n",
            "Epoch 0.35 >> (per-task accuracy): 66.63\n",
            "Epoch 0.35 >> (class accuracy): [86.1224, 57.1806, 56.3953, 70.7921, 60.7943, 61.6592, 84.9687, 63.035, 57.9055, 69.3756]\n",
            "Epoch 0.4 >> (per-task accuracy): 66.01\n",
            "Epoch 0.4 >> (class accuracy): [87.3469, 47.2247, 54.845, 64.6535, 64.664, 73.4305, 83.4029, 56.323, 59.2402, 73.8355]\n",
            "Epoch 0.45 >> (per-task accuracy): 68.1\n",
            "Epoch 0.45 >> (class accuracy): [85.7143, 56.2996, 60.9496, 69.0099, 64.3585, 70.9641, 85.4906, 57.2957, 61.191, 72.9435]\n",
            "Epoch 0.5 >> (per-task accuracy): 69.54\n",
            "Epoch 0.5 >> (class accuracy): [85.8163, 61.4978, 57.4612, 73.6634, 66.4969, 71.4126, 88.1002, 61.1868, 60.6776, 71.7542]\n",
            "Epoch 0.55 >> (per-task accuracy): 69.25\n",
            "Epoch 0.55 >> (class accuracy): [84.7959, 60.7048, 61.2403, 70.9901, 65.5804, 73.7668, 86.952, 58.3658, 61.499, 71.556]\n",
            "Epoch 0.6 >> (per-task accuracy): 71.13\n",
            "Epoch 0.6 >> (class accuracy): [85.3061, 71.5419, 60.8527, 69.604, 68.3299, 77.13, 85.2818, 63.9105, 60.1643, 70.8622]\n",
            "Epoch 0.65 >> (per-task accuracy): 71.36\n",
            "Epoch 0.65 >> (class accuracy): [84.1837, 72.6872, 61.7248, 67.5248, 69.4501, 75.6726, 85.1775, 64.5914, 60.883, 73.0426]\n",
            "Epoch 0.7 >> (per-task accuracy): 71.91\n",
            "Epoch 0.7 >> (class accuracy): [84.2857, 69.7797, 64.0504, 68.6139, 69.7556, 78.2511, 86.0125, 62.8405, 64.0657, 73.5382]\n",
            "Epoch 0.75 >> (per-task accuracy): 71.72\n",
            "Epoch 0.75 >> (class accuracy): [84.4898, 72.4229, 56.4922, 71.4851, 68.8391, 78.4753, 86.1169, 63.8132, 64.0657, 72.9435]\n",
            "Epoch 0.8 >> (per-task accuracy): 72.82\n",
            "Epoch 0.8 >> (class accuracy): [84.3878, 74.7137, 63.0814, 71.4851, 70.3666, 77.2422, 87.1608, 62.5486, 64.9897, 73.6373]\n",
            "Epoch 0.85 >> (per-task accuracy): 72.75\n",
            "Epoch 0.85 >> (class accuracy): [83.9796, 74.2731, 60.9496, 71.1881, 69.7556, 78.0269, 85.8038, 65.7588, 64.7844, 74.4301]\n",
            "Epoch 0.9 >> (per-task accuracy): 72.48\n",
            "Epoch 0.9 >> (class accuracy): [85.8163, 71.7181, 60.7558, 69.505, 68.9409, 79.8206, 85.4906, 65.2724, 64.1684, 75.3221]\n",
            "Epoch 0.95 >> (per-task accuracy): 72.39\n",
            "Epoch 0.95 >> (class accuracy): [85.7143, 73.0396, 61.2403, 72.6733, 66.5988, 80.2691, 84.1336, 64.1051, 62.8337, 75.0248]\n",
            "Epoch 1.0 >> (per-task accuracy): 73.41\n",
            "Epoch 1.0 >> (class accuracy): [83.3673, 74.7137, 62.2093, 70.0, 70.9776, 79.3722, 87.7871, 64.1051, 64.7844, 78.3944]\n",
            "OCS >> Task 1: {'accuracy': 58.9, 'per_class_accuracy': [86.9388, 75.859, 26.5504, 48.7129, 51.1202, 35.0897, 86.8476, 64.1051, 53.0801, 58.2755], 'loss': 2.1020920786857604}\n",
            "OCS >> Task 2: {'accuracy': 67.6, 'per_class_accuracy': [88.9796, 92.9515, 35.562, 61.4851, 59.776, 52.4664, 88.309, 66.3424, 62.2177, 65.0149], 'loss': 1.5401822468757629}\n",
            "OCS >> Task 3: {'accuracy': 72.29, 'per_class_accuracy': [88.8776, 97.6211, 52.2287, 70.9901, 66.2933, 63.565, 91.2317, 68.9689, 61.2936, 59.0684], 'loss': 1.20811197078228}\n",
            "OCS >> Task 4: {'accuracy': 75.27, 'per_class_accuracy': [88.8776, 97.533, 62.3062, 76.7327, 69.3483, 70.9641, 91.4405, 67.8016, 64.4764, 61.0505], 'loss': 1.017052308154106}\n",
            "OCS >> Task 5: {'accuracy': 76.44, 'per_class_accuracy': [86.3265, 94.3612, 62.3062, 77.4257, 68.2281, 78.0269, 90.7098, 70.5253, 65.6057, 69.6729], 'loss': 0.9141282616138459}\n",
            "OCS >> Task 6: {'accuracy': 76.21, 'per_class_accuracy': [85.8163, 92.0705, 61.8217, 76.7327, 71.4868, 80.8296, 91.4405, 70.6226, 66.8378, 64.0238], 'loss': 0.9304904480934143}\n",
            "OCS >> Task 7: {'accuracy': 76.7, 'per_class_accuracy': [85.2041, 86.4317, 65.6008, 75.6436, 70.3666, 81.0538, 90.1879, 68.9689, 69.0965, 74.6283], 'loss': 0.9165693125724792}\n",
            "OCS >> Task 8: {'accuracy': 73.41, 'per_class_accuracy': [83.3673, 74.7137, 62.2093, 70.0, 70.9776, 79.3722, 87.7871, 64.1051, 64.7844, 78.3944], 'loss': 1.0995748477935792}\n",
            "OCS >> (average accuracy): 72.10249999999999\n",
            "OCS >> (Forgetting): 0.2604428571428571\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 9 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 41.79\n",
            "Epoch 0.05 >> (class accuracy): [66.1224, 8.2819, 72.7713, 56.2376, 0.3055, 0.0, 31.2109, 22.3735, 82.5462, 77.5025]\n",
            "Epoch 0.1 >> (per-task accuracy): 51.46\n",
            "Epoch 0.1 >> (class accuracy): [76.9388, 33.8326, 47.4806, 63.5644, 30.5499, 38.1166, 68.9979, 19.2607, 54.7228, 83.6472]\n",
            "Epoch 0.15 >> (per-task accuracy): 54.85\n",
            "Epoch 0.15 >> (class accuracy): [81.0204, 36.0352, 43.8953, 57.6238, 55.8045, 35.8744, 75.1566, 37.4514, 68.4805, 60.1586]\n",
            "Epoch 0.2 >> (per-task accuracy): 56.58\n",
            "Epoch 0.2 >> (class accuracy): [82.9592, 31.8943, 46.8992, 62.4752, 56.4155, 36.6592, 76.618, 45.428, 67.1458, 62.6363]\n",
            "Epoch 0.25 >> (per-task accuracy): 58.4\n",
            "Epoch 0.25 >> (class accuracy): [86.5306, 28.9868, 50.0, 62.2772, 56.4155, 45.0673, 79.9582, 48.3463, 66.3244, 64.7175]\n",
            "Epoch 0.3 >> (per-task accuracy): 59.67\n",
            "Epoch 0.3 >> (class accuracy): [85.9184, 27.3128, 48.6434, 63.4653, 54.0733, 51.5695, 82.1503, 51.1673, 66.0164, 71.8533]\n",
            "Epoch 0.35 >> (per-task accuracy): 60.33\n",
            "Epoch 0.35 >> (class accuracy): [85.8163, 29.0749, 49.4186, 64.4554, 54.3788, 56.6143, 80.0626, 51.4591, 67.3511, 70.3667]\n",
            "Epoch 0.4 >> (per-task accuracy): 60.86\n",
            "Epoch 0.4 >> (class accuracy): [85.6122, 31.1894, 46.9961, 64.3564, 54.1752, 61.2108, 77.6618, 54.572, 67.1458, 71.4569]\n",
            "Epoch 0.45 >> (per-task accuracy): 62.09\n",
            "Epoch 0.45 >> (class accuracy): [85.102, 31.9824, 48.8372, 64.7525, 58.554, 62.2197, 79.5407, 59.3385, 68.1725, 68.1863]\n",
            "Epoch 0.5 >> (per-task accuracy): 63.71\n",
            "Epoch 0.5 >> (class accuracy): [84.898, 34.0088, 54.9419, 65.2475, 57.943, 66.4798, 79.2276, 60.7977, 68.5832, 70.664]\n",
            "Epoch 0.55 >> (per-task accuracy): 64.2\n",
            "Epoch 0.55 >> (class accuracy): [84.7959, 37.2687, 52.0349, 67.2277, 57.8411, 63.3408, 83.6117, 58.5603, 70.0205, 72.5471]\n",
            "Epoch 0.6 >> (per-task accuracy): 64.7\n",
            "Epoch 0.6 >> (class accuracy): [85.8163, 38.2379, 50.0, 64.7525, 59.4705, 69.6188, 80.8977, 60.7004, 71.4579, 71.8533]\n",
            "Epoch 0.65 >> (per-task accuracy): 66.11\n",
            "Epoch 0.65 >> (class accuracy): [85.6122, 39.207, 55.7171, 66.8317, 59.6741, 72.1973, 81.524, 59.7276, 72.8953, 73.5382]\n",
            "Epoch 0.7 >> (per-task accuracy): 66.33\n",
            "Epoch 0.7 >> (class accuracy): [86.1224, 42.2026, 57.4612, 65.3465, 61.2016, 73.3184, 82.0459, 59.7276, 68.8912, 72.448]\n",
            "Epoch 0.75 >> (per-task accuracy): 66.78\n",
            "Epoch 0.75 >> (class accuracy): [85.5102, 44.4053, 56.3953, 67.1287, 61.9145, 72.3094, 82.881, 59.7276, 69.3018, 73.3399]\n",
            "Epoch 0.8 >> (per-task accuracy): 68.31\n",
            "Epoch 0.8 >> (class accuracy): [84.898, 53.4802, 57.5581, 70.5941, 61.609, 72.7578, 81.8372, 63.3268, 69.6099, 71.1596]\n",
            "Epoch 0.85 >> (per-task accuracy): 68.96\n",
            "Epoch 0.85 >> (class accuracy): [83.8776, 54.0088, 56.5891, 70.0, 62.9328, 74.1031, 82.9854, 64.5914, 70.1232, 74.2319]\n",
            "Epoch 0.9 >> (per-task accuracy): 69.31\n",
            "Epoch 0.9 >> (class accuracy): [85.6122, 55.7709, 55.2326, 70.297, 65.6823, 73.2063, 83.2985, 66.0506, 69.0965, 72.448]\n",
            "Epoch 0.95 >> (per-task accuracy): 69.61\n",
            "Epoch 0.95 >> (class accuracy): [84.1837, 54.8018, 57.1705, 69.2079, 62.9328, 76.9058, 83.2985, 65.1751, 72.3819, 74.1328]\n",
            "Epoch 1.0 >> (per-task accuracy): 69.54\n",
            "Epoch 1.0 >> (class accuracy): [83.0612, 59.4714, 55.7171, 69.0099, 64.8676, 77.4664, 82.4635, 65.2724, 69.1992, 72.3489]\n",
            "OCS >> Task 1: {'accuracy': 57.52, 'per_class_accuracy': [80.7143, 79.9119, 28.0039, 39.0099, 45.723, 32.1749, 84.7599, 65.9533, 54.6201, 60.7532], 'loss': 2.0758421634674074}\n",
            "OCS >> Task 2: {'accuracy': 64.79, 'per_class_accuracy': [85.102, 93.1278, 37.7907, 48.5149, 52.2403, 49.1031, 85.6994, 66.7315, 58.7269, 67.1952], 'loss': 1.5899651211738586}\n",
            "OCS >> Task 3: {'accuracy': 69.48, 'per_class_accuracy': [86.7347, 97.9736, 53.9729, 58.1188, 64.7658, 55.4933, 87.5783, 69.7471, 57.8029, 58.672], 'loss': 1.2888074582099915}\n",
            "OCS >> Task 4: {'accuracy': 71.3, 'per_class_accuracy': [87.7551, 97.6211, 63.8566, 63.3663, 67.6171, 60.0897, 87.8914, 67.5097, 55.8522, 57.78], 'loss': 1.139270623922348}\n",
            "OCS >> Task 5: {'accuracy': 72.86, 'per_class_accuracy': [86.1224, 94.0969, 63.0814, 68.9109, 63.7475, 71.1883, 87.1608, 70.6226, 58.2136, 63.2309], 'loss': 1.029360272836685}\n",
            "OCS >> Task 6: {'accuracy': 73.25, 'per_class_accuracy': [85.4082, 91.9824, 61.1434, 73.2673, 64.8676, 73.5426, 87.2651, 71.4008, 63.7577, 58.3746], 'loss': 1.0422889864444733}\n",
            "OCS >> Task 7: {'accuracy': 73.98, 'per_class_accuracy': [84.5918, 87.3128, 63.7597, 74.5545, 59.4705, 76.4574, 87.6827, 72.179, 68.0698, 65.0149], 'loss': 1.0059475513458251}\n",
            "OCS >> Task 8: {'accuracy': 71.97, 'per_class_accuracy': [83.8776, 71.1894, 62.2093, 69.3069, 62.831, 79.4843, 86.1169, 69.7471, 68.8912, 67.9881], 'loss': 1.0942663376808166}\n",
            "OCS >> Task 9: {'accuracy': 69.54, 'per_class_accuracy': [83.0612, 59.4714, 55.7171, 69.0099, 64.8676, 77.4664, 82.4635, 65.2724, 69.1992, 72.3489], 'loss': 1.245262888240814}\n",
            "OCS >> (average accuracy): 69.41000000000001\n",
            "OCS >> (Forgetting): 0.28566249999999993\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 10 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 10.38\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.5837, 0.0, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 38.74\n",
            "Epoch 0.1 >> (class accuracy): [65.5102, 0.9692, 37.9845, 13.5644, 47.1487, 27.5785, 67.8497, 31.9066, 33.3676, 67.3935]\n",
            "Epoch 0.15 >> (per-task accuracy): 51.45\n",
            "Epoch 0.15 >> (class accuracy): [74.898, 22.467, 49.7093, 40.9901, 44.1955, 48.2063, 70.7724, 53.8911, 55.3388, 58.8702]\n",
            "Epoch 0.2 >> (per-task accuracy): 55.46\n",
            "Epoch 0.2 >> (class accuracy): [76.8367, 49.3392, 45.4457, 44.6535, 52.6477, 37.8924, 75.261, 52.3346, 65.4004, 55.6987]\n",
            "Epoch 0.25 >> (per-task accuracy): 56.32\n",
            "Epoch 0.25 >> (class accuracy): [74.2857, 62.7313, 48.062, 44.3564, 40.7332, 41.0314, 75.1566, 71.1089, 57.2895, 46.8781]\n",
            "Epoch 0.3 >> (per-task accuracy): 58.12\n",
            "Epoch 0.3 >> (class accuracy): [80.102, 53.8326, 49.5155, 55.8416, 44.7047, 54.3722, 74.5303, 75.8755, 54.8255, 38.553]\n",
            "Epoch 0.35 >> (per-task accuracy): 57.7\n",
            "Epoch 0.35 >> (class accuracy): [76.7347, 57.0044, 47.8682, 41.7822, 45.6212, 52.9148, 81.1065, 71.3035, 55.3388, 48.1665]\n",
            "Epoch 0.4 >> (per-task accuracy): 58.91\n",
            "Epoch 0.4 >> (class accuracy): [76.1224, 60.0881, 45.8333, 43.7624, 43.3809, 52.8027, 83.9248, 79.2802, 61.6016, 42.8147]\n",
            "Epoch 0.45 >> (per-task accuracy): 61.2\n",
            "Epoch 0.45 >> (class accuracy): [77.1429, 63.8767, 48.2558, 52.3762, 51.5275, 60.6502, 81.2109, 77.2374, 55.8522, 44.4995]\n",
            "Epoch 0.5 >> (per-task accuracy): 61.53\n",
            "Epoch 0.5 >> (class accuracy): [76.3265, 66.2555, 48.7403, 57.2277, 47.9633, 60.3139, 79.2276, 72.8599, 56.1602, 50.3469]\n",
            "Epoch 0.55 >> (per-task accuracy): 62.42\n",
            "Epoch 0.55 >> (class accuracy): [76.7347, 66.4317, 46.8023, 55.7426, 49.6945, 58.9686, 81.7328, 76.8482, 60.6776, 50.7433]\n",
            "Epoch 0.6 >> (per-task accuracy): 62.93\n",
            "Epoch 0.6 >> (class accuracy): [76.1224, 65.2863, 47.9651, 56.2376, 50.9165, 63.3408, 82.881, 79.2802, 58.9322, 49.0585]\n",
            "Epoch 0.65 >> (per-task accuracy): 63.09\n",
            "Epoch 0.65 >> (class accuracy): [75.7143, 69.7797, 47.2868, 56.0396, 51.222, 62.3318, 81.6284, 77.3346, 59.4456, 50.1487]\n",
            "Epoch 0.7 >> (per-task accuracy): 63.67\n",
            "Epoch 0.7 >> (class accuracy): [76.3265, 70.3965, 47.9651, 57.6238, 50.2037, 65.1345, 81.3152, 79.8638, 58.5216, 49.4549]\n",
            "Epoch 0.75 >> (per-task accuracy): 64.69\n",
            "Epoch 0.75 >> (class accuracy): [76.9388, 70.7489, 45.0581, 62.4752, 51.5275, 68.1614, 82.4635, 80.3502, 59.0349, 50.6442]\n",
            "Epoch 0.8 >> (per-task accuracy): 64.18\n",
            "Epoch 0.8 >> (class accuracy): [77.1429, 72.6872, 43.7984, 68.3168, 48.778, 61.2108, 80.0626, 82.5875, 56.5708, 49.8513]\n",
            "Epoch 0.85 >> (per-task accuracy): 64.84\n",
            "Epoch 0.85 >> (class accuracy): [75.8163, 72.1586, 46.9961, 63.7624, 51.0183, 65.9193, 81.6284, 80.9339, 59.8563, 50.2478]\n",
            "Epoch 0.9 >> (per-task accuracy): 65.63\n",
            "Epoch 0.9 >> (class accuracy): [76.4286, 73.4802, 44.186, 64.7525, 52.8513, 65.2466, 81.7328, 79.0856, 62.423, 55.996]\n",
            "Epoch 0.95 >> (per-task accuracy): 65.33\n",
            "Epoch 0.95 >> (class accuracy): [77.3469, 72.9515, 42.6357, 63.7624, 54.9898, 67.8251, 81.3152, 79.2802, 59.9589, 53.5183]\n",
            "Epoch 1.0 >> (per-task accuracy): 66.16\n",
            "Epoch 1.0 >> (class accuracy): [78.4694, 70.3965, 47.3837, 61.5842, 55.7026, 70.6278, 82.1503, 79.2802, 59.2402, 57.5818]\n",
            "OCS >> Task 1: {'accuracy': 56.33, 'per_class_accuracy': [81.1224, 79.1189, 23.3527, 40.5941, 28.4114, 41.3677, 81.3152, 64.8833, 57.3922, 63.0327], 'loss': 2.1724131786346437}\n",
            "OCS >> Task 2: {'accuracy': 63.47, 'per_class_accuracy': [87.0408, 93.304, 31.5891, 50.099, 36.2525, 55.6054, 83.7161, 66.3424, 59.6509, 67.9881], 'loss': 1.7181384508132935}\n",
            "OCS >> Task 3: {'accuracy': 67.22, 'per_class_accuracy': [89.0816, 97.7974, 45.155, 52.7723, 43.279, 62.5561, 85.4906, 73.0545, 53.1828, 66.3033], 'loss': 1.4078669704914093}\n",
            "OCS >> Task 4: {'accuracy': 69.24, 'per_class_accuracy': [89.7959, 97.6211, 55.3295, 57.3267, 48.778, 69.3946, 86.5344, 71.0117, 48.0493, 65.5104], 'loss': 1.2550281559467316}\n",
            "OCS >> Task 5: {'accuracy': 69.6, 'per_class_accuracy': [89.4898, 94.8899, 59.3023, 60.9901, 43.279, 74.7758, 86.8476, 72.7626, 43.8398, 67.2944], 'loss': 1.1901258450508119}\n",
            "OCS >> Task 6: {'accuracy': 69.79, 'per_class_accuracy': [88.1633, 95.3304, 56.9767, 63.4653, 46.1303, 72.4215, 88.2046, 72.0817, 51.0267, 61.6452], 'loss': 1.1883349171161652}\n",
            "OCS >> Task 7: {'accuracy': 70.92, 'per_class_accuracy': [86.7347, 97.533, 58.624, 63.3663, 47.0468, 71.1883, 87.3695, 73.6381, 57.7002, 63.1318], 'loss': 1.1403353345394134}\n",
            "OCS >> Task 8: {'accuracy': 71.78, 'per_class_accuracy': [84.5918, 94.5374, 58.3333, 61.3861, 56.8228, 73.2063, 88.2046, 75.0973, 62.5257, 61.1497], 'loss': 1.124441443490982}\n",
            "OCS >> Task 9: {'accuracy': 70.51, 'per_class_accuracy': [83.0612, 86.1674, 56.7829, 60.099, 63.442, 70.6278, 85.3862, 74.6109, 63.963, 59.9604], 'loss': 1.190387640094757}\n",
            "OCS >> Task 10: {'accuracy': 66.16, 'per_class_accuracy': [78.4694, 70.3965, 47.3837, 61.5842, 55.7026, 70.6278, 82.1503, 79.2802, 59.2402, 57.5818], 'loss': 1.3891617059707642}\n",
            "OCS >> (average accuracy): 67.50199999999998\n",
            "OCS >> (Forgetting): 0.30308888888888885\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 11 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 33.71\n",
            "Epoch 0.05 >> (class accuracy): [67.1429, 52.7753, 71.124, 21.6832, 2.1385, 0.0, 1.9833, 26.1673, 87.4743, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 32.3\n",
            "Epoch 0.1 >> (class accuracy): [88.9796, 0.0, 53.6822, 59.703, 0.611, 0.0, 0.0, 0.3891, 30.5955, 88.5035]\n",
            "Epoch 0.15 >> (per-task accuracy): 41.57\n",
            "Epoch 0.15 >> (class accuracy): [72.0408, 7.8414, 45.6395, 69.1089, 33.5031, 6.0538, 22.4426, 29.4747, 46.9199, 82.7552]\n",
            "Epoch 0.2 >> (per-task accuracy): 46.46\n",
            "Epoch 0.2 >> (class accuracy): [67.6531, 39.5595, 46.5116, 52.7723, 50.3055, 12.3318, 33.7161, 39.9805, 57.4949, 61.7443]\n",
            "Epoch 0.25 >> (per-task accuracy): 46.86\n",
            "Epoch 0.25 >> (class accuracy): [70.2041, 42.7313, 49.2248, 44.3564, 53.2587, 16.8161, 36.1169, 43.0934, 57.2895, 53.221]\n",
            "Epoch 0.3 >> (per-task accuracy): 47.39\n",
            "Epoch 0.3 >> (class accuracy): [68.8776, 42.2907, 49.6124, 37.9208, 56.0081, 17.1525, 44.572, 48.1518, 55.7495, 51.6353]\n",
            "Epoch 0.35 >> (per-task accuracy): 48.85\n",
            "Epoch 0.35 >> (class accuracy): [71.0204, 42.0264, 52.8101, 38.6139, 51.0183, 23.6547, 46.4509, 52.3346, 52.6694, 56.3925]\n",
            "Epoch 0.4 >> (per-task accuracy): 50.51\n",
            "Epoch 0.4 >> (class accuracy): [70.5102, 46.2555, 53.0039, 45.2475, 52.8513, 22.3094, 50.1044, 53.1128, 52.4641, 57.0862]\n",
            "Epoch 0.45 >> (per-task accuracy): 51.64\n",
            "Epoch 0.45 >> (class accuracy): [72.2449, 46.7841, 54.7481, 43.8614, 52.6477, 26.009, 51.7745, 53.9883, 53.3881, 59.1675]\n",
            "Epoch 0.5 >> (per-task accuracy): 52.53\n",
            "Epoch 0.5 >> (class accuracy): [72.9592, 49.4273, 53.9729, 43.6634, 54.0733, 24.3274, 56.0543, 57.393, 56.0575, 55.3023]\n",
            "Epoch 0.55 >> (per-task accuracy): 54.16\n",
            "Epoch 0.55 >> (class accuracy): [74.5918, 53.3921, 54.0698, 48.2178, 50.9165, 28.139, 56.6806, 58.5603, 57.2895, 57.4827]\n",
            "Epoch 0.6 >> (per-task accuracy): 54.77\n",
            "Epoch 0.6 >> (class accuracy): [73.6735, 54.8018, 55.7171, 46.1386, 52.8513, 27.8027, 56.9937, 60.3113, 58.3162, 58.5728]\n",
            "Epoch 0.65 >> (per-task accuracy): 55.77\n",
            "Epoch 0.65 >> (class accuracy): [75.7143, 59.8238, 53.5853, 48.8119, 50.3055, 28.2511, 56.4718, 60.7977, 59.4456, 61.3479]\n",
            "Epoch 0.7 >> (per-task accuracy): 56.67\n",
            "Epoch 0.7 >> (class accuracy): [74.0816, 61.2335, 54.7481, 48.5149, 52.5458, 29.3722, 57.5157, 62.5486, 61.0883, 61.8434]\n",
            "Epoch 0.75 >> (per-task accuracy): 57.25\n",
            "Epoch 0.75 >> (class accuracy): [74.3878, 61.9383, 51.2597, 47.6238, 54.888, 30.157, 59.9165, 63.9105, 61.499, 63.9247]\n",
            "Epoch 0.8 >> (per-task accuracy): 57.76\n",
            "Epoch 0.8 >> (class accuracy): [73.2653, 63.7885, 52.5194, 48.5149, 55.2953, 29.7085, 59.0814, 64.8833, 64.0657, 63.1318]\n",
            "Epoch 0.85 >> (per-task accuracy): 58.05\n",
            "Epoch 0.85 >> (class accuracy): [72.7551, 64.141, 52.8101, 47.7228, 56.3136, 31.8386, 60.6472, 63.5214, 62.5257, 65.114]\n",
            "Epoch 0.9 >> (per-task accuracy): 58.47\n",
            "Epoch 0.9 >> (class accuracy): [73.6735, 66.3436, 52.2287, 48.0198, 55.1935, 31.8386, 61.3779, 64.1051, 62.423, 66.1051]\n",
            "Epoch 0.95 >> (per-task accuracy): 59.88\n",
            "Epoch 0.95 >> (class accuracy): [74.2857, 69.6035, 54.6512, 48.5149, 56.2118, 31.6143, 62.7349, 63.9105, 66.3244, 67.1952]\n",
            "Epoch 1.0 >> (per-task accuracy): 59.73\n",
            "Epoch 1.0 >> (class accuracy): [72.0408, 69.9559, 56.0078, 47.9208, 56.3136, 33.0717, 61.0647, 65.4669, 64.8871, 66.6997]\n",
            "OCS >> Task 1: {'accuracy': 55.03, 'per_class_accuracy': [80.7143, 82.1145, 27.8101, 39.4059, 26.1711, 27.9148, 77.6618, 59.9222, 59.5483, 64.3211], 'loss': 2.0702583362579348}\n",
            "OCS >> Task 2: {'accuracy': 61.09, 'per_class_accuracy': [85.2041, 93.0396, 36.2403, 46.0396, 36.6599, 41.5919, 80.3758, 59.4358, 60.1643, 67.4926], 'loss': 1.697178148651123}\n",
            "OCS >> Task 3: {'accuracy': 65.06, 'per_class_accuracy': [88.2653, 97.4449, 47.6744, 50.396, 43.5845, 54.5964, 80.0626, 64.9805, 56.5708, 62.7354], 'loss': 1.4364739156246185}\n",
            "OCS >> Task 4: {'accuracy': 65.88, 'per_class_accuracy': [88.7755, 97.0044, 54.845, 48.7129, 48.2688, 60.6502, 81.2109, 63.6187, 49.1786, 62.7354], 'loss': 1.3381294600486755}\n",
            "OCS >> Task 5: {'accuracy': 66.5, 'per_class_accuracy': [87.449, 97.0044, 58.3333, 54.1584, 41.2424, 67.6009, 80.2714, 67.8988, 44.4559, 62.9336], 'loss': 1.3007721102714538}\n",
            "OCS >> Task 6: {'accuracy': 66.13, 'per_class_accuracy': [86.7347, 97.6211, 55.7171, 58.3168, 42.5662, 61.5471, 82.6722, 65.7588, 45.6879, 60.555], 'loss': 1.3390226090431214}\n",
            "OCS >> Task 7: {'accuracy': 66.56, 'per_class_accuracy': [86.1224, 98.7665, 56.0078, 57.2277, 40.0204, 58.7444, 80.0626, 67.9961, 53.3881, 62.6363], 'loss': 1.3312072849273682}\n",
            "OCS >> Task 8: {'accuracy': 67.04, 'per_class_accuracy': [83.7755, 97.6211, 57.655, 52.3762, 52.8513, 51.9058, 80.0626, 70.7198, 59.7536, 58.7711], 'loss': 1.3190989342212678}\n",
            "OCS >> Task 9: {'accuracy': 67.12, 'per_class_accuracy': [82.1429, 96.0352, 61.0465, 51.4851, 59.0631, 43.2735, 77.453, 69.358, 64.4764, 61.2488], 'loss': 1.33044063205719}\n",
            "OCS >> Task 10: {'accuracy': 64.83, 'per_class_accuracy': [76.0204, 87.5771, 59.6899, 51.4851, 56.8228, 38.2287, 70.7724, 71.4008, 67.0431, 63.8256], 'loss': 1.4310546995162965}\n",
            "OCS >> Task 11: {'accuracy': 59.73, 'per_class_accuracy': [72.0408, 69.9559, 56.0078, 47.9208, 56.3136, 33.0717, 61.0647, 65.4669, 64.8871, 66.6997], 'loss': 1.7342827013015747}\n",
            "OCS >> (average accuracy): 64.08818181818182\n",
            "OCS >> (Forgetting): 0.33435999999999994\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 12 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 26.56\n",
            "Epoch 0.05 >> (class accuracy): [32.551, 24.4934, 10.7558, 54.7525, 30.3462, 0.0, 15.8664, 9.8249, 86.653, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 33.56\n",
            "Epoch 0.1 >> (class accuracy): [94.898, 0.0, 37.5969, 67.7228, 78.3096, 0.0, 0.0, 0.0, 32.0329, 27.0565]\n",
            "Epoch 0.15 >> (per-task accuracy): 35.54\n",
            "Epoch 0.15 >> (class accuracy): [72.2449, 0.4405, 45.155, 79.703, 69.6538, 0.2242, 13.8831, 0.7782, 31.3142, 43.4093]\n",
            "Epoch 0.2 >> (per-task accuracy): 44.92\n",
            "Epoch 0.2 >> (class accuracy): [63.0612, 48.6344, 44.186, 62.7723, 64.3585, 3.2511, 35.8038, 25.7782, 51.7454, 45.4906]\n",
            "Epoch 0.25 >> (per-task accuracy): 47.57\n",
            "Epoch 0.25 >> (class accuracy): [65.5102, 56.0352, 47.4806, 53.1683, 52.1385, 6.278, 37.1608, 39.5914, 56.4682, 56.5907]\n",
            "Epoch 0.3 >> (per-task accuracy): 46.17\n",
            "Epoch 0.3 >> (class accuracy): [68.0612, 55.7709, 43.1202, 42.5743, 53.666, 10.2018, 36.0125, 44.4553, 50.308, 52.7255]\n",
            "Epoch 0.35 >> (per-task accuracy): 46.83\n",
            "Epoch 0.35 >> (class accuracy): [67.449, 52.9515, 48.5465, 40.5941, 53.055, 10.9865, 36.4301, 55.642, 49.7947, 48.0674]\n",
            "Epoch 0.4 >> (per-task accuracy): 48.18\n",
            "Epoch 0.4 >> (class accuracy): [67.551, 52.8634, 47.6744, 39.4059, 52.444, 14.4619, 38.6221, 55.642, 51.848, 56.9871]\n",
            "Epoch 0.45 >> (per-task accuracy): 48.63\n",
            "Epoch 0.45 >> (class accuracy): [66.8367, 52.511, 47.3837, 43.1683, 51.0183, 20.1794, 38.2046, 60.6031, 46.7146, 55.6987]\n",
            "Epoch 0.5 >> (per-task accuracy): 49.78\n",
            "Epoch 0.5 >> (class accuracy): [68.7755, 53.1278, 42.8295, 42.3762, 55.9063, 30.4933, 41.2317, 66.8288, 44.5585, 48.9594]\n",
            "Epoch 0.55 >> (per-task accuracy): 49.51\n",
            "Epoch 0.55 >> (class accuracy): [62.7551, 53.3921, 45.155, 42.3762, 54.888, 23.0942, 41.7537, 69.6498, 46.7146, 51.5362]\n",
            "Epoch 0.6 >> (per-task accuracy): 50.81\n",
            "Epoch 0.6 >> (class accuracy): [65.2041, 55.5066, 46.0271, 45.9406, 55.499, 22.1973, 43.0063, 69.358, 47.0226, 54.2121]\n",
            "Epoch 0.65 >> (per-task accuracy): 51.08\n",
            "Epoch 0.65 >> (class accuracy): [61.6327, 55.5947, 46.9961, 45.8416, 55.2953, 20.9641, 45.8246, 70.428, 51.1294, 52.9237]\n",
            "Epoch 0.7 >> (per-task accuracy): 51.64\n",
            "Epoch 0.7 >> (class accuracy): [60.6122, 56.9163, 47.5775, 50.7921, 56.4155, 22.4215, 43.0063, 72.9572, 51.9507, 49.3558]\n",
            "Epoch 0.75 >> (per-task accuracy): 52.17\n",
            "Epoch 0.75 >> (class accuracy): [63.0612, 58.9427, 47.3837, 45.5446, 54.888, 24.7758, 45.6159, 74.6109, 54.9281, 47.7701]\n",
            "Epoch 0.8 >> (per-task accuracy): 52.21\n",
            "Epoch 0.8 >> (class accuracy): [61.2245, 57.9736, 45.6395, 45.4455, 54.277, 25.8969, 46.3466, 72.9572, 55.5441, 52.9237]\n",
            "Epoch 0.85 >> (per-task accuracy): 53.97\n",
            "Epoch 0.85 >> (class accuracy): [64.0816, 58.7665, 48.4496, 48.7129, 54.7862, 28.5874, 48.0167, 72.4708, 57.1869, 55.005]\n",
            "Epoch 0.9 >> (per-task accuracy): 55.22\n",
            "Epoch 0.9 >> (class accuracy): [65.3061, 59.8238, 50.6783, 49.901, 57.0265, 27.3543, 48.8518, 71.9844, 62.731, 54.8067]\n",
            "Epoch 0.95 >> (per-task accuracy): 54.74\n",
            "Epoch 0.95 >> (class accuracy): [64.898, 60.3524, 48.5465, 50.099, 54.7862, 30.0448, 49.4781, 72.7626, 56.8789, 55.8969]\n",
            "Epoch 1.0 >> (per-task accuracy): 54.81\n",
            "Epoch 1.0 >> (class accuracy): [65.8163, 59.6476, 46.7054, 50.495, 53.3605, 28.6996, 50.8351, 73.7354, 57.1869, 57.9782]\n",
            "OCS >> Task 1: {'accuracy': 54.14, 'per_class_accuracy': [81.0204, 74.978, 30.5233, 39.604, 22.8106, 29.148, 79.0188, 58.7549, 62.2177, 59.7621], 'loss': 2.0086232973098754}\n",
            "OCS >> Task 2: {'accuracy': 60.83, 'per_class_accuracy': [86.0204, 92.8634, 37.7907, 47.1287, 29.1242, 42.0404, 79.3319, 59.144, 65.1951, 65.0149], 'loss': 1.6807675307273864}\n",
            "OCS >> Task 3: {'accuracy': 63.7, 'per_class_accuracy': [88.1633, 95.7709, 48.2558, 50.198, 35.5397, 53.5874, 78.6013, 60.5058, 62.423, 59.8612], 'loss': 1.4484619396209717}\n",
            "OCS >> Task 4: {'accuracy': 64.25, 'per_class_accuracy': [88.4694, 95.7709, 51.5504, 50.396, 41.5479, 60.5381, 79.4363, 60.0195, 54.1068, 57.1853], 'loss': 1.3835595798015594}\n",
            "OCS >> Task 5: {'accuracy': 64.71, 'per_class_accuracy': [88.5714, 95.859, 52.2287, 53.8614, 35.7434, 68.0493, 78.81, 67.0233, 44.1478, 59.4648], 'loss': 1.3780834309577943}\n",
            "OCS >> Task 6: {'accuracy': 63.76, 'per_class_accuracy': [87.6531, 97.2687, 46.8992, 56.1386, 36.9654, 60.5381, 81.3152, 68.5798, 40.7598, 57.2844], 'loss': 1.4540871537208557}\n",
            "OCS >> Task 7: {'accuracy': 63.24, 'per_class_accuracy': [86.6327, 98.6784, 44.5736, 54.4554, 36.2525, 56.3901, 79.6451, 71.5953, 44.0452, 55.3023], 'loss': 1.4835847583293915}\n",
            "OCS >> Task 8: {'accuracy': 63.5, 'per_class_accuracy': [85.4082, 97.7974, 43.4109, 51.8812, 48.4725, 48.3184, 79.5407, 76.3619, 51.3347, 47.2745], 'loss': 1.4973936725616455}\n",
            "OCS >> Task 9: {'accuracy': 62.66, 'per_class_accuracy': [83.2653, 97.4449, 46.8992, 48.2178, 52.1385, 39.6861, 75.7829, 77.0428, 56.5708, 43.4093], 'loss': 1.5204317923545838}\n",
            "OCS >> Task 10: {'accuracy': 60.91, 'per_class_accuracy': [76.1224, 92.8634, 47.5775, 49.703, 47.8615, 36.435, 71.5031, 80.9339, 58.8296, 40.9316], 'loss': 1.5617066036224365}\n",
            "OCS >> Task 11: {'accuracy': 59.81, 'per_class_accuracy': [72.8571, 81.0573, 51.3566, 49.802, 50.8147, 34.5291, 63.9875, 79.572, 62.3203, 46.4817], 'loss': 1.6401922832489013}\n",
            "OCS >> Task 12: {'accuracy': 54.81, 'per_class_accuracy': [65.8163, 59.6476, 46.7054, 50.495, 53.3605, 28.6996, 50.8351, 73.7354, 57.1869, 57.9782], 'loss': 1.8624281505584717}\n",
            "OCS >> (average accuracy): 61.35999999999999\n",
            "OCS >> (Forgetting): 0.3600454545454545\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 13 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 18.97\n",
            "Epoch 0.05 >> (class accuracy): [36.8367, 0.0, 79.3605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0605]\n",
            "Epoch 0.1 >> (per-task accuracy): 18.38\n",
            "Epoch 0.1 >> (class accuracy): [83.6735, 0.0, 0.7752, 0.0, 0.0, 0.0, 0.1044, 0.0, 2.1561, 97.9187]\n",
            "Epoch 0.15 >> (per-task accuracy): 30.95\n",
            "Epoch 0.15 >> (class accuracy): [60.9184, 13.0396, 40.2132, 0.198, 39.5112, 0.0, 40.2923, 0.0, 26.1807, 89.5937]\n",
            "Epoch 0.2 >> (per-task accuracy): 39.57\n",
            "Epoch 0.2 >> (class accuracy): [57.9592, 56.652, 51.938, 10.099, 51.833, 3.6996, 40.8142, 26.2646, 10.0616, 79.9802]\n",
            "Epoch 0.25 >> (per-task accuracy): 44.72\n",
            "Epoch 0.25 >> (class accuracy): [62.3469, 64.0529, 45.6395, 7.9208, 59.9796, 10.9865, 31.0021, 53.1128, 34.1889, 71.3578]\n",
            "Epoch 0.3 >> (per-task accuracy): 44.39\n",
            "Epoch 0.3 >> (class accuracy): [63.5714, 63.1718, 51.5504, 12.3762, 44.1955, 10.0897, 24.739, 55.5447, 43.2238, 68.2854]\n",
            "Epoch 0.35 >> (per-task accuracy): 51.73\n",
            "Epoch 0.35 >> (class accuracy): [69.4898, 69.0749, 53.5853, 42.3762, 52.2403, 22.4215, 29.2276, 67.8016, 42.7105, 61.5461]\n",
            "Epoch 0.4 >> (per-task accuracy): 54.2\n",
            "Epoch 0.4 >> (class accuracy): [73.9796, 68.1057, 59.6899, 43.4653, 44.9084, 23.8789, 23.904, 77.5292, 55.3388, 64.222]\n",
            "Epoch 0.45 >> (per-task accuracy): 51.11\n",
            "Epoch 0.45 >> (class accuracy): [62.8571, 67.3128, 53.7791, 42.3762, 48.2688, 5.8296, 17.119, 77.1401, 59.4456, 67.9881]\n",
            "Epoch 0.5 >> (per-task accuracy): 52.27\n",
            "Epoch 0.5 >> (class accuracy): [61.0204, 69.5154, 55.0388, 29.4059, 52.9532, 5.8296, 29.5407, 80.7393, 66.3244, 63.8256]\n",
            "Epoch 0.55 >> (per-task accuracy): 51.75\n",
            "Epoch 0.55 >> (class accuracy): [53.4694, 67.7533, 47.9651, 28.0198, 61.5071, 5.8296, 31.9415, 78.3074, 72.2793, 62.7354]\n",
            "Epoch 0.6 >> (per-task accuracy): 53.46\n",
            "Epoch 0.6 >> (class accuracy): [58.9796, 74.5374, 43.314, 41.9802, 60.998, 5.8296, 33.5073, 78.8911, 60.2669, 67.4926]\n",
            "Epoch 0.65 >> (per-task accuracy): 53.21\n",
            "Epoch 0.65 >> (class accuracy): [51.9388, 77.9736, 41.9574, 39.2079, 59.776, 4.2601, 36.952, 81.6148, 64.5791, 64.5193]\n",
            "Epoch 0.7 >> (per-task accuracy): 50.6\n",
            "Epoch 0.7 >> (class accuracy): [44.6939, 77.1806, 42.2481, 29.505, 60.1833, 2.9148, 33.4029, 84.2412, 66.7351, 55.4014]\n",
            "Epoch 0.75 >> (per-task accuracy): 54.62\n",
            "Epoch 0.75 >> (class accuracy): [70.7143, 83.8767, 40.2132, 44.3564, 56.2118, 5.2691, 36.5344, 84.9222, 57.4949, 56.6898]\n",
            "Epoch 0.8 >> (per-task accuracy): 52.94\n",
            "Epoch 0.8 >> (class accuracy): [64.4898, 80.793, 40.3101, 30.396, 56.8228, 6.0538, 36.3257, 87.2568, 62.5257, 55.1041]\n",
            "Epoch 0.85 >> (per-task accuracy): 52.78\n",
            "Epoch 0.85 >> (class accuracy): [62.8571, 77.1806, 43.7016, 29.0099, 56.0081, 5.2691, 34.7599, 85.4086, 63.8604, 60.6541]\n",
            "Epoch 0.9 >> (per-task accuracy): 51.77\n",
            "Epoch 0.9 >> (class accuracy): [60.3061, 73.4802, 43.7016, 21.0891, 56.721, 4.5964, 31.7328, 83.7549, 66.4271, 67.1952]\n",
            "Epoch 0.95 >> (per-task accuracy): 52.58\n",
            "Epoch 0.95 >> (class accuracy): [56.9388, 73.4802, 47.3837, 27.4257, 53.1568, 3.5874, 29.2276, 85.6031, 70.8419, 68.9792]\n",
            "Epoch 1.0 >> (per-task accuracy): 54.12\n",
            "Epoch 1.0 >> (class accuracy): [56.5306, 71.1894, 54.6512, 38.1188, 58.0448, 4.0359, 27.0355, 85.0195, 70.9446, 66.5015]\n",
            "OCS >> Task 1: {'accuracy': 54.59, 'per_class_accuracy': [82.2449, 74.978, 28.5853, 48.6139, 16.1914, 25.6726, 74.4259, 66.9261, 63.655, 60.1586], 'loss': 2.0065633031845094}\n",
            "OCS >> Task 2: {'accuracy': 60.31, 'per_class_accuracy': [87.449, 89.5154, 36.531, 56.4356, 20.8758, 37.5561, 76.5136, 66.0506, 62.423, 64.5193], 'loss': 1.6859059692382812}\n",
            "OCS >> Task 3: {'accuracy': 62.16, 'per_class_accuracy': [89.7959, 95.2423, 49.9031, 58.5149, 26.9857, 49.6637, 74.9478, 64.4942, 56.5708, 50.446], 'loss': 1.5054678933143615}\n",
            "OCS >> Task 4: {'accuracy': 62.67, 'per_class_accuracy': [90.102, 96.4758, 55.0388, 58.4158, 34.6232, 58.296, 76.3048, 59.5331, 47.1253, 46.4817], 'loss': 1.437615141773224}\n",
            "OCS >> Task 5: {'accuracy': 62.47, 'per_class_accuracy': [89.6939, 96.652, 55.3295, 56.4356, 33.0957, 65.1345, 75.7829, 65.2724, 39.9384, 43.4093], 'loss': 1.45517495803833}\n",
            "OCS >> Task 6: {'accuracy': 62.34, 'per_class_accuracy': [87.7551, 97.6211, 50.969, 56.1386, 38.5947, 59.417, 78.1837, 69.4553, 36.7556, 43.9049], 'loss': 1.517045060968399}\n",
            "OCS >> Task 7: {'accuracy': 61.63, 'per_class_accuracy': [86.1224, 98.5903, 47.6744, 52.8713, 38.1874, 51.009, 78.0793, 76.2646, 40.3491, 41.5263], 'loss': 1.575991361951828}\n",
            "OCS >> Task 8: {'accuracy': 61.44, 'per_class_accuracy': [83.2653, 98.1498, 45.8333, 47.0297, 48.9817, 41.4798, 77.5574, 81.2257, 45.2772, 39.2468], 'loss': 1.6065494379997254}\n",
            "OCS >> Task 9: {'accuracy': 59.91, 'per_class_accuracy': [80.6122, 98.0617, 45.7364, 44.0594, 53.5642, 29.4843, 67.4322, 85.5058, 50.1027, 36.5709], 'loss': 1.6676486445426941}\n",
            "OCS >> Task 10: {'accuracy': 57.22, 'per_class_accuracy': [74.3878, 96.8282, 46.9961, 38.9109, 50.8147, 20.7399, 64.405, 86.0895, 54.4148, 29.7324], 'loss': 1.7482435829162597}\n",
            "OCS >> Task 11: {'accuracy': 58.16, 'per_class_accuracy': [69.3878, 93.8326, 53.4884, 40.9901, 52.444, 14.6861, 53.2359, 85.7977, 64.6817, 43.3102], 'loss': 1.7146786657333375}\n",
            "OCS >> Task 12: {'accuracy': 56.93, 'per_class_accuracy': [60.5102, 84.0529, 53.6822, 42.1782, 54.4807, 9.0807, 38.309, 84.4358, 70.0205, 62.7354], 'loss': 1.8272948530197144}\n",
            "OCS >> Task 13: {'accuracy': 54.12, 'per_class_accuracy': [56.5306, 71.1894, 54.6512, 38.1188, 58.0448, 4.0359, 27.0355, 85.0195, 70.9446, 66.5015], 'loss': 1.9874030822753905}\n",
            "OCS >> (average accuracy): 59.53461538461538\n",
            "OCS >> (Forgetting): 0.37974166666666664\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 14 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 22.07\n",
            "Epoch 0.05 >> (class accuracy): [4.5918, 28.6344, 38.7597, 6.7327, 62.7291, 0.0, 1.4614, 19.6498, 54.2094, 0.892]\n",
            "Epoch 0.1 >> (per-task accuracy): 11.05\n",
            "Epoch 0.1 >> (class accuracy): [9.7959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 17.53\n",
            "Epoch 0.15 >> (class accuracy): [78.0612, 0.0, 0.4845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 97.4232]\n",
            "Epoch 0.2 >> (per-task accuracy): 20.13\n",
            "Epoch 0.2 >> (class accuracy): [81.0204, 0.0, 21.7054, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9774, 95.7384]\n",
            "Epoch 0.25 >> (per-task accuracy): 24.18\n",
            "Epoch 0.25 >> (class accuracy): [67.6531, 0.0, 48.9341, 0.198, 1.4257, 0.0, 10.9603, 0.1946, 19.8152, 92.5669]\n",
            "Epoch 0.3 >> (per-task accuracy): 27.98\n",
            "Epoch 0.3 >> (class accuracy): [57.6531, 2.0264, 53.6822, 7.7228, 4.0733, 0.0, 18.5804, 8.1712, 38.6037, 89.1972]\n",
            "Epoch 0.35 >> (per-task accuracy): 33.95\n",
            "Epoch 0.35 >> (class accuracy): [53.2653, 20.6167, 46.124, 20.0, 11.4053, 0.0, 23.0689, 24.9027, 49.8973, 87.8097]\n",
            "Epoch 0.4 >> (per-task accuracy): 38.25\n",
            "Epoch 0.4 >> (class accuracy): [51.2245, 31.3656, 45.3488, 24.9505, 23.1161, 0.2242, 24.2171, 38.1323, 55.3388, 84.7374]\n",
            "Epoch 0.45 >> (per-task accuracy): 39.56\n",
            "Epoch 0.45 >> (class accuracy): [51.1224, 34.5374, 42.345, 24.1584, 30.3462, 0.8969, 22.2338, 45.6226, 57.7002, 82.4579]\n",
            "Epoch 0.5 >> (per-task accuracy): 40.22\n",
            "Epoch 0.5 >> (class accuracy): [52.449, 35.0661, 40.407, 24.6535, 37.3727, 1.7937, 20.4593, 50.0, 56.6735, 79.1873]\n",
            "Epoch 0.55 >> (per-task accuracy): 40.77\n",
            "Epoch 0.55 >> (class accuracy): [53.0612, 35.2423, 42.7326, 23.6634, 41.9552, 3.0269, 17.9541, 53.8911, 56.1602, 75.8176]\n",
            "Epoch 0.6 >> (per-task accuracy): 40.65\n",
            "Epoch 0.6 >> (class accuracy): [51.8367, 34.7137, 42.2481, 21.4851, 45.112, 3.9238, 19.2067, 54.6693, 54.4148, 74.9257]\n",
            "Epoch 0.65 >> (per-task accuracy): 41.49\n",
            "Epoch 0.65 >> (class accuracy): [53.8776, 34.0088, 40.6008, 22.1782, 48.3707, 5.2691, 21.19, 60.3113, 53.6961, 71.7542]\n",
            "Epoch 0.7 >> (per-task accuracy): 41.61\n",
            "Epoch 0.7 >> (class accuracy): [55.7143, 33.3921, 41.5698, 20.099, 50.3055, 6.0538, 20.3549, 59.4358, 52.9774, 72.7453]\n",
            "Epoch 0.75 >> (per-task accuracy): 41.67\n",
            "Epoch 0.75 >> (class accuracy): [56.2245, 32.8634, 41.4729, 20.297, 50.4073, 6.7265, 21.9207, 59.0467, 50.8214, 73.6373]\n",
            "Epoch 0.8 >> (per-task accuracy): 41.65\n",
            "Epoch 0.8 >> (class accuracy): [55.6122, 31.8943, 42.0543, 20.495, 53.1568, 6.9507, 21.3987, 60.5058, 49.8973, 71.3578]\n",
            "Epoch 0.85 >> (per-task accuracy): 41.85\n",
            "Epoch 0.85 >> (class accuracy): [57.9592, 31.1894, 39.3411, 20.8911, 52.2403, 7.287, 22.6514, 60.4086, 51.9507, 71.7542]\n",
            "Epoch 0.9 >> (per-task accuracy): 41.77\n",
            "Epoch 0.9 >> (class accuracy): [59.1837, 30.9251, 39.3411, 20.9901, 53.3605, 7.287, 22.6514, 58.9494, 49.076, 73.1417]\n",
            "Epoch 0.95 >> (per-task accuracy): 41.49\n",
            "Epoch 0.95 >> (class accuracy): [56.3265, 31.1013, 37.8876, 20.396, 54.0733, 7.9596, 22.547, 59.4358, 50.5133, 71.9524]\n",
            "Epoch 1.0 >> (per-task accuracy): 41.16\n",
            "Epoch 1.0 >> (class accuracy): [55.9184, 30.837, 38.0814, 20.0, 53.8697, 7.7354, 23.1733, 59.4358, 48.5626, 71.2587]\n",
            "OCS >> Task 1: {'accuracy': 53.26, 'per_class_accuracy': [80.4082, 62.467, 26.8411, 48.8119, 15.1731, 33.1839, 77.7662, 64.5914, 61.7043, 59.8612], 'loss': 1.7273954351425171}\n",
            "OCS >> Task 2: {'accuracy': 58.8, 'per_class_accuracy': [85.3061, 80.0881, 34.4961, 58.1188, 17.6171, 41.5919, 77.8706, 63.8132, 61.2936, 64.3211], 'loss': 1.4971753244400023}\n",
            "OCS >> Task 3: {'accuracy': 61.04, 'per_class_accuracy': [87.2449, 89.8678, 46.6085, 60.0, 24.9491, 49.8879, 77.2443, 59.7276, 54.6201, 56.0951], 'loss': 1.327889426422119}\n",
            "OCS >> Task 4: {'accuracy': 61.05, 'per_class_accuracy': [87.8571, 91.3656, 51.938, 57.4257, 32.6884, 57.0628, 75.8873, 56.0311, 47.3306, 49.2567], 'loss': 1.2793631582260132}\n",
            "OCS >> Task 5: {'accuracy': 62.04, 'per_class_accuracy': [88.1633, 94.0088, 53.1977, 60.198, 28.9206, 63.2287, 73.4864, 61.6732, 41.0678, 52.5273], 'loss': 1.2552627891540526}\n",
            "OCS >> Task 6: {'accuracy': 61.58, 'per_class_accuracy': [87.551, 96.2996, 49.3217, 59.1089, 33.1976, 56.1659, 74.8434, 64.3969, 37.885, 52.1308], 'loss': 1.3201776220321655}\n",
            "OCS >> Task 7: {'accuracy': 60.03, 'per_class_accuracy': [86.1224, 97.8855, 47.093, 54.5545, 31.6701, 49.7758, 70.5637, 69.6498, 40.4517, 46.5808], 'loss': 1.3834835743904115}\n",
            "OCS >> Task 8: {'accuracy': 58.74, 'per_class_accuracy': [82.6531, 97.533, 46.3178, 44.0594, 43.0754, 41.5919, 68.1628, 72.5681, 42.7105, 42.1209], 'loss': 1.46553938331604}\n",
            "OCS >> Task 9: {'accuracy': 56.14, 'per_class_accuracy': [79.898, 97.9736, 47.4806, 35.6436, 46.4358, 31.3901, 59.2902, 74.0272, 45.8932, 35.3816], 'loss': 1.5801987753868103}\n",
            "OCS >> Task 10: {'accuracy': 52.94, 'per_class_accuracy': [74.3878, 96.652, 44.2829, 28.9109, 44.3992, 25.4484, 53.6534, 78.1128, 46.0986, 28.7413], 'loss': 1.723313278388977}\n",
            "OCS >> Task 11: {'accuracy': 51.92, 'per_class_accuracy': [70.9184, 89.6916, 43.4109, 26.7327, 42.668, 20.6278, 45.929, 77.6265, 51.3347, 41.6254], 'loss': 1.7687276773452758}\n",
            "OCS >> Task 12: {'accuracy': 48.57, 'per_class_accuracy': [63.3673, 69.8678, 39.6318, 28.5149, 41.446, 14.574, 36.952, 72.7626, 53.3881, 58.1764], 'loss': 1.872144316482544}\n",
            "OCS >> Task 13: {'accuracy': 45.41, 'per_class_accuracy': [60.6122, 50.6608, 36.531, 22.0792, 45.6212, 9.9776, 30.4802, 71.5953, 55.3388, 66.2042], 'loss': 2.0992203338623048}\n",
            "OCS >> Task 14: {'accuracy': 41.16, 'per_class_accuracy': [55.9184, 30.837, 38.0814, 20.0, 53.8697, 7.7354, 23.1733, 59.4358, 48.5626, 71.2587], 'loss': 2.34744294090271}\n",
            "OCS >> (average accuracy): 55.191428571428574\n",
            "OCS >> (Forgetting): 0.41689230769230756\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 15 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 15.67\n",
            "Epoch 0.05 >> (class accuracy): [0.4082, 38.1498, 6.5891, 7.1287, 36.8635, 0.0, 0.9395, 34.7276, 26.2834, 0.5946]\n",
            "Epoch 0.1 >> (per-task accuracy): 10.09\n",
            "Epoch 0.1 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 15.02\n",
            "Epoch 0.15 >> (class accuracy): [50.7143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.6036]\n",
            "Epoch 0.2 >> (per-task accuracy): 17.52\n",
            "Epoch 0.2 >> (class accuracy): [78.9796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.9277]\n",
            "Epoch 0.25 >> (per-task accuracy): 18.77\n",
            "Epoch 0.25 >> (class accuracy): [81.1224, 0.0, 10.562, 0.099, 0.0, 0.0, 0.0, 0.0, 1.0267, 95.3419]\n",
            "Epoch 0.3 >> (per-task accuracy): 25.04\n",
            "Epoch 0.3 >> (class accuracy): [73.6735, 0.0, 35.0775, 18.5149, 0.4073, 0.0, 16.0752, 0.0973, 13.8604, 93.0624]\n",
            "Epoch 0.35 >> (per-task accuracy): 29.01\n",
            "Epoch 0.35 >> (class accuracy): [61.9388, 0.0, 41.9574, 35.5446, 3.5642, 0.0, 26.2004, 2.7237, 29.3634, 89.3954]\n",
            "Epoch 0.4 >> (per-task accuracy): 32.22\n",
            "Epoch 0.4 >> (class accuracy): [55.5102, 2.0264, 41.9574, 45.6436, 9.6741, 0.0, 30.4802, 9.4358, 41.8891, 86.1249]\n",
            "Epoch 0.45 >> (per-task accuracy): 35.88\n",
            "Epoch 0.45 >> (class accuracy): [52.6531, 11.3656, 43.9922, 46.6337, 15.8859, 0.2242, 31.0021, 21.4008, 51.54, 83.3499]\n",
            "Epoch 0.5 >> (per-task accuracy): 38.57\n",
            "Epoch 0.5 >> (class accuracy): [50.4082, 20.7048, 45.7364, 46.1386, 23.7271, 3.0269, 27.6618, 30.3502, 54.6201, 81.3677]\n",
            "Epoch 0.55 >> (per-task accuracy): 39.57\n",
            "Epoch 0.55 >> (class accuracy): [49.0816, 27.5771, 45.5426, 42.7723, 30.1426, 7.1749, 23.904, 35.0195, 54.7228, 77.2052]\n",
            "Epoch 0.6 >> (per-task accuracy): 40.95\n",
            "Epoch 0.6 >> (class accuracy): [47.7551, 32.8634, 46.124, 40.5941, 38.1874, 10.7623, 22.2338, 41.9261, 54.7228, 71.3578]\n",
            "Epoch 0.65 >> (per-task accuracy): 41.01\n",
            "Epoch 0.65 >> (class accuracy): [47.9592, 32.5991, 47.8682, 34.8515, 43.6864, 13.3408, 20.4593, 44.5525, 53.9014, 68.1863]\n",
            "Epoch 0.7 >> (per-task accuracy): 40.4\n",
            "Epoch 0.7 >> (class accuracy): [48.5714, 32.9515, 47.3837, 31.2871, 48.0652, 13.565, 19.1023, 43.7743, 52.6694, 64.0238]\n",
            "Epoch 0.75 >> (per-task accuracy): 40.58\n",
            "Epoch 0.75 >> (class accuracy): [51.1224, 31.8943, 48.5465, 30.297, 49.4908, 15.8072, 18.1628, 45.428, 51.3347, 61.447]\n",
            "Epoch 0.8 >> (per-task accuracy): 40.48\n",
            "Epoch 0.8 >> (class accuracy): [50.9184, 30.9251, 48.062, 27.9208, 50.611, 17.0404, 17.7453, 47.8599, 51.232, 60.4559]\n",
            "Epoch 0.85 >> (per-task accuracy): 40.27\n",
            "Epoch 0.85 >> (class accuracy): [51.4286, 29.8678, 46.6085, 26.7327, 51.7312, 17.4888, 16.7015, 48.93, 51.7454, 59.663]\n",
            "Epoch 0.9 >> (per-task accuracy): 40.63\n",
            "Epoch 0.9 >> (class accuracy): [55.3061, 28.9868, 48.1589, 26.8317, 55.0916, 17.6009, 16.9102, 48.6381, 49.1786, 57.9782]\n",
            "Epoch 0.95 >> (per-task accuracy): 40.5\n",
            "Epoch 0.95 >> (class accuracy): [54.5918, 29.0749, 45.8333, 26.6337, 55.3971, 19.0583, 17.8497, 47.5681, 47.8439, 59.7621]\n",
            "Epoch 1.0 >> (per-task accuracy): 40.96\n",
            "Epoch 1.0 >> (class accuracy): [56.4286, 29.2511, 46.9961, 27.2277, 55.1935, 19.5067, 17.8497, 46.6926, 48.152, 60.9514]\n",
            "OCS >> Task 1: {'accuracy': 50.65, 'per_class_accuracy': [76.5306, 64.9339, 24.8062, 40.495, 18.7373, 43.8341, 74.4259, 60.214, 48.5626, 52.8246], 'loss': 1.6364803049087524}\n",
            "OCS >> Task 2: {'accuracy': 56.23, 'per_class_accuracy': [81.5306, 79.0308, 33.624, 53.1683, 19.9593, 47.7578, 74.9478, 61.6732, 48.3573, 59.2666], 'loss': 1.431318238544464}\n",
            "OCS >> Task 3: {'accuracy': 59.36, 'per_class_accuracy': [84.2857, 90.0441, 46.9961, 56.4356, 24.1344, 53.9238, 73.7996, 57.7821, 48.0493, 54.113], 'loss': 1.2906078497886657}\n",
            "OCS >> Task 4: {'accuracy': 60.19, 'per_class_accuracy': [83.9796, 91.3656, 54.9419, 57.2277, 30.4481, 59.0807, 73.0689, 54.1829, 44.5585, 49.2567], 'loss': 1.2466724422454833}\n",
            "OCS >> Task 5: {'accuracy': 61.03, 'per_class_accuracy': [83.2653, 94.185, 54.3605, 62.2772, 26.2729, 61.0987, 71.0856, 61.4786, 39.9384, 51.8335], 'loss': 1.223461431503296}\n",
            "OCS >> Task 6: {'accuracy': 60.59, 'per_class_accuracy': [83.2653, 95.859, 49.4186, 62.5743, 27.3931, 55.2691, 71.0856, 64.8833, 37.577, 53.221], 'loss': 1.254748492527008}\n",
            "OCS >> Task 7: {'accuracy': 59.24, 'per_class_accuracy': [81.8367, 96.2996, 48.5465, 58.1188, 27.9022, 46.9731, 67.7453, 69.9416, 40.3491, 48.2656], 'loss': 1.3027898025512696}\n",
            "OCS >> Task 8: {'accuracy': 58.14, 'per_class_accuracy': [79.6939, 95.4185, 46.3178, 49.4059, 41.5479, 37.4439, 66.0752, 71.8872, 44.1478, 42.5173], 'loss': 1.3829675269126893}\n",
            "OCS >> Task 9: {'accuracy': 56.28, 'per_class_accuracy': [77.3469, 96.2115, 45.8333, 40.495, 45.723, 29.2601, 59.9165, 72.179, 49.692, 38.2557], 'loss': 1.4682396673202516}\n",
            "OCS >> Task 10: {'accuracy': 53.37, 'per_class_accuracy': [73.1633, 97.4449, 42.5388, 31.6832, 45.723, 25.8969, 52.714, 76.1673, 50.0, 29.7324], 'loss': 1.5787396230697632}\n",
            "OCS >> Task 11: {'accuracy': 51.94, 'per_class_accuracy': [69.2857, 94.2731, 40.407, 28.9109, 41.1405, 22.9821, 44.6764, 75.8755, 55.0308, 37.9584], 'loss': 1.6143099439620971}\n",
            "OCS >> Task 12: {'accuracy': 50.42, 'per_class_accuracy': [63.2653, 86.4317, 35.562, 33.4653, 34.4196, 20.4036, 37.1608, 73.8327, 55.7495, 55.3023], 'loss': 1.6452835306167604}\n",
            "OCS >> Task 13: {'accuracy': 46.82, 'per_class_accuracy': [62.6531, 63.1718, 34.593, 28.8119, 35.947, 18.3857, 31.0021, 75.2918, 55.4415, 56.9871], 'loss': 1.750000810432434}\n",
            "OCS >> Task 14: {'accuracy': 44.87, 'per_class_accuracy': [59.0816, 46.4317, 41.4729, 28.4158, 45.0102, 20.0673, 24.739, 67.3152, 50.5133, 61.8434], 'loss': 1.8562465717315675}\n",
            "OCS >> Task 15: {'accuracy': 40.96, 'per_class_accuracy': [56.4286, 29.2511, 46.9961, 27.2277, 55.1935, 19.5067, 17.8497, 46.6926, 48.152, 60.9514], 'loss': 2.006782787322998}\n",
            "OCS >> (average accuracy): 54.006\n",
            "OCS >> (Forgetting): 0.43022142857142853\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 16 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 7.49\n",
            "Epoch 0.05 >> (class accuracy): [2.8571, 3.9648, 2.7132, 1.6832, 2.0367, 0.0, 0.0, 28.5019, 32.6489, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 10.09\n",
            "Epoch 0.1 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 13.5\n",
            "Epoch 0.15 >> (class accuracy): [34.898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9009]\n",
            "Epoch 0.2 >> (per-task accuracy): 17.42\n",
            "Epoch 0.2 >> (class accuracy): [77.8571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 97.0268]\n",
            "Epoch 0.25 >> (per-task accuracy): 17.88\n",
            "Epoch 0.25 >> (class accuracy): [83.6735, 0.0, 0.3876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 95.5401]\n",
            "Epoch 0.3 >> (per-task accuracy): 19.64\n",
            "Epoch 0.3 >> (class accuracy): [82.449, 0.0, 14.1473, 0.0, 0.8147, 0.0, 0.0, 0.0, 5.9548, 93.558]\n",
            "Epoch 0.35 >> (per-task accuracy): 23.64\n",
            "Epoch 0.35 >> (class accuracy): [76.3265, 0.0, 36.4341, 1.0891, 5.1935, 0.0, 5.428, 0.0, 23.2033, 89.1972]\n",
            "Epoch 0.4 >> (per-task accuracy): 28.12\n",
            "Epoch 0.4 >> (class accuracy): [68.8776, 0.0, 45.155, 14.5545, 17.3116, 0.0, 14.9269, 0.1946, 38.0903, 83.0525]\n",
            "Epoch 0.45 >> (per-task accuracy): 31.74\n",
            "Epoch 0.45 >> (class accuracy): [62.6531, 0.0, 48.8372, 28.1188, 30.2444, 0.0, 21.2944, 1.3619, 51.232, 75.1239]\n",
            "Epoch 0.5 >> (per-task accuracy): 33.66\n",
            "Epoch 0.5 >> (class accuracy): [59.0816, 0.0, 46.5116, 36.2376, 40.7332, 0.0, 28.4969, 3.6965, 58.4189, 65.5104]\n",
            "Epoch 0.55 >> (per-task accuracy): 35.28\n",
            "Epoch 0.55 >> (class accuracy): [57.3469, 2.5551, 49.1279, 40.0, 46.945, 0.5605, 31.6284, 6.5175, 62.0123, 58.0773]\n",
            "Epoch 0.6 >> (per-task accuracy): 37.75\n",
            "Epoch 0.6 >> (class accuracy): [54.7959, 9.4273, 52.907, 43.2673, 42.2607, 3.6996, 32.9854, 13.4241, 66.1191, 59.663]\n",
            "Epoch 0.65 >> (per-task accuracy): 38.94\n",
            "Epoch 0.65 >> (class accuracy): [53.7755, 18.9427, 53.2946, 33.8614, 46.945, 7.3991, 35.0731, 19.8444, 66.7351, 53.8157]\n",
            "Epoch 0.7 >> (per-task accuracy): 40.04\n",
            "Epoch 0.7 >> (class accuracy): [54.3878, 28.5463, 54.0698, 25.4455, 47.6578, 12.2197, 35.8038, 22.7626, 66.3244, 52.7255]\n",
            "Epoch 0.75 >> (per-task accuracy): 40.57\n",
            "Epoch 0.75 >> (class accuracy): [54.3878, 31.8943, 53.2946, 21.8812, 48.0652, 18.9462, 33.9248, 25.3891, 66.9405, 50.7433]\n",
            "Epoch 0.8 >> (per-task accuracy): 40.93\n",
            "Epoch 0.8 >> (class accuracy): [56.4286, 36.4758, 51.1628, 20.198, 50.5092, 22.6457, 30.8977, 27.5292, 66.0164, 46.9772]\n",
            "Epoch 0.85 >> (per-task accuracy): 41.52\n",
            "Epoch 0.85 >> (class accuracy): [57.3469, 37.6211, 52.4225, 20.396, 48.9817, 22.9821, 28.0793, 34.0467, 65.0924, 47.2745]\n",
            "Epoch 0.9 >> (per-task accuracy): 41.0\n",
            "Epoch 0.9 >> (class accuracy): [57.1429, 37.533, 54.7481, 18.1188, 51.3238, 20.2915, 26.5136, 34.144, 62.8337, 45.9861]\n",
            "Epoch 0.95 >> (per-task accuracy): 41.51\n",
            "Epoch 0.95 >> (class accuracy): [56.9388, 38.5022, 52.1318, 18.3168, 52.2403, 19.7309, 26.2004, 35.0195, 64.9897, 49.554]\n",
            "Epoch 1.0 >> (per-task accuracy): 41.71\n",
            "Epoch 1.0 >> (class accuracy): [57.1429, 38.7665, 53.4884, 19.505, 53.5642, 21.4126, 24.1127, 33.6576, 63.4497, 50.5451]\n",
            "OCS >> Task 1: {'accuracy': 48.16, 'per_class_accuracy': [74.4898, 75.7709, 22.5775, 34.9505, 22.4033, 49.1031, 70.3549, 49.2218, 42.2998, 38.6521], 'loss': 1.6689533613204957}\n",
            "OCS >> Task 2: {'accuracy': 53.39, 'per_class_accuracy': [79.0816, 80.0, 32.0736, 48.4158, 25.6619, 52.0179, 73.1733, 53.6965, 44.5585, 42.9138], 'loss': 1.4948121618270873}\n",
            "OCS >> Task 3: {'accuracy': 56.97, 'per_class_accuracy': [82.6531, 89.6035, 46.8023, 54.4554, 31.4664, 55.7175, 72.8601, 53.2101, 44.1478, 35.2825], 'loss': 1.366667500782013}\n",
            "OCS >> Task 4: {'accuracy': 57.78, 'per_class_accuracy': [82.551, 90.3084, 53.876, 58.4158, 33.5031, 55.8296, 71.7119, 54.0856, 42.9158, 30.7235], 'loss': 1.315564098262787}\n",
            "OCS >> Task 5: {'accuracy': 59.47, 'per_class_accuracy': [81.3265, 92.6872, 56.686, 64.0594, 29.5316, 57.6233, 69.833, 63.5214, 39.5277, 35.1833], 'loss': 1.276239183998108}\n",
            "OCS >> Task 6: {'accuracy': 58.71, 'per_class_accuracy': [81.0204, 92.1586, 52.4225, 65.0495, 29.8371, 45.0673, 68.1628, 66.4397, 41.3758, 39.5441], 'loss': 1.2994743482589721}\n",
            "OCS >> Task 7: {'accuracy': 57.72, 'per_class_accuracy': [78.7755, 92.4229, 52.6163, 62.6733, 29.2261, 37.6682, 64.9269, 70.428, 45.4825, 35.9762], 'loss': 1.3375081197738647}\n",
            "OCS >> Task 8: {'accuracy': 56.77, 'per_class_accuracy': [77.7551, 89.163, 50.0969, 54.3564, 39.2057, 28.2511, 63.1524, 71.2062, 50.5133, 36.7691], 'loss': 1.4021314663887023}\n",
            "OCS >> Task 9: {'accuracy': 55.3, 'per_class_accuracy': [74.898, 90.2203, 47.6744, 47.4257, 43.7882, 22.1973, 55.428, 73.5409, 51.0267, 38.553], 'loss': 1.454818074131012}\n",
            "OCS >> Task 10: {'accuracy': 52.62, 'per_class_accuracy': [68.6735, 91.1013, 43.314, 40.8911, 43.9919, 19.5067, 48.9562, 74.1245, 52.4641, 34.3905], 'loss': 1.5261091848373414}\n",
            "OCS >> Task 11: {'accuracy': 51.28, 'per_class_accuracy': [65.8163, 81.0573, 41.0853, 38.1188, 40.224, 17.3767, 43.9457, 74.5136, 57.9055, 44.8959], 'loss': 1.54987542552948}\n",
            "OCS >> Task 12: {'accuracy': 48.77, 'per_class_accuracy': [61.1224, 58.6784, 38.7597, 43.4653, 33.5031, 16.3677, 37.6827, 72.0817, 59.5483, 61.0505], 'loss': 1.5828927410125733}\n",
            "OCS >> Task 13: {'accuracy': 45.56, 'per_class_accuracy': [58.1633, 44.6696, 37.8876, 35.1485, 36.3544, 14.3498, 36.5344, 72.5681, 58.9322, 57.2844], 'loss': 1.6218118432998658}\n",
            "OCS >> Task 14: {'accuracy': 43.83, 'per_class_accuracy': [55.6122, 26.696, 46.4147, 34.5545, 42.1589, 17.6009, 33.5073, 63.8132, 57.2895, 59.5639], 'loss': 1.6492852407455445}\n",
            "OCS >> Task 15: {'accuracy': 43.04, 'per_class_accuracy': [55.0, 27.8414, 54.4574, 30.099, 49.7963, 20.1794, 27.3486, 47.8599, 60.5749, 56.4916], 'loss': 1.6860803468704224}\n",
            "OCS >> Task 16: {'accuracy': 41.71, 'per_class_accuracy': [57.1429, 38.7665, 53.4884, 19.505, 53.5642, 21.4126, 24.1127, 33.6576, 63.4497, 50.5451], 'loss': 1.7886457027435303}\n",
            "OCS >> (average accuracy): 51.942499999999995\n",
            "OCS >> (Forgetting): 0.45335333333333316\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 17 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 9.05\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 2.1145, 7.2674, 0.099, 51.5275, 0.0, 0.0, 0.5837, 30.0821, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 10.09\n",
            "Epoch 0.1 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 13.79\n",
            "Epoch 0.15 >> (class accuracy): [37.8571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9009]\n",
            "Epoch 0.2 >> (per-task accuracy): 17.73\n",
            "Epoch 0.2 >> (class accuracy): [81.1224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.9277]\n",
            "Epoch 0.25 >> (per-task accuracy): 18.13\n",
            "Epoch 0.25 >> (class accuracy): [87.7551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 94.45]\n",
            "Epoch 0.3 >> (per-task accuracy): 17.99\n",
            "Epoch 0.3 >> (class accuracy): [87.0408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 93.7562]\n",
            "Epoch 0.35 >> (per-task accuracy): 18.53\n",
            "Epoch 0.35 >> (class accuracy): [86.5306, 0.0, 5.1357, 0.0, 0.0, 0.0, 0.0, 0.0, 1.232, 93.1615]\n",
            "Epoch 0.4 >> (per-task accuracy): 21.9\n",
            "Epoch 0.4 >> (class accuracy): [77.9592, 0.0, 34.593, 0.297, 0.1018, 0.0, 0.0, 0.0, 14.4764, 91.5758]\n",
            "Epoch 0.45 >> (per-task accuracy): 24.77\n",
            "Epoch 0.45 >> (class accuracy): [72.551, 0.0, 46.6085, 6.5347, 0.1018, 0.0, 3.7578, 0.0, 29.7741, 88.4044]\n",
            "Epoch 0.5 >> (per-task accuracy): 27.01\n",
            "Epoch 0.5 >> (class accuracy): [66.6327, 0.0, 55.2326, 13.5644, 0.9165, 0.0, 9.8121, 0.5837, 39.3224, 84.1427]\n",
            "Epoch 0.55 >> (per-task accuracy): 28.6\n",
            "Epoch 0.55 >> (class accuracy): [66.1224, 0.0, 53.7791, 24.3564, 0.2037, 0.0, 8.7683, 1.751, 47.5359, 83.6472]\n",
            "Epoch 0.6 >> (per-task accuracy): 32.32\n",
            "Epoch 0.6 >> (class accuracy): [59.3878, 11.2775, 56.5891, 29.901, 7.2301, 0.5605, 15.8664, 4.4747, 57.0842, 79.8811]\n",
            "Epoch 0.65 >> (per-task accuracy): 36.13\n",
            "Epoch 0.65 >> (class accuracy): [56.9388, 22.467, 56.2016, 30.6931, 17.7189, 1.6816, 23.5908, 12.7432, 61.9097, 75.4212]\n",
            "Epoch 0.7 >> (per-task accuracy): 38.83\n",
            "Epoch 0.7 >> (class accuracy): [56.0204, 30.6608, 58.5271, 37.4257, 18.9409, 3.3632, 23.382, 18.677, 63.8604, 74.331]\n",
            "Epoch 0.75 >> (per-task accuracy): 40.94\n",
            "Epoch 0.75 >> (class accuracy): [54.4898, 38.8546, 58.1395, 36.7327, 25.2546, 7.3991, 28.2881, 21.4008, 65.0924, 70.2676]\n",
            "Epoch 0.8 >> (per-task accuracy): 40.41\n",
            "Epoch 0.8 >> (class accuracy): [51.9388, 40.9692, 64.0504, 23.7624, 36.8635, 7.3991, 24.739, 20.428, 64.9897, 65.2131]\n",
            "Epoch 0.85 >> (per-task accuracy): 40.75\n",
            "Epoch 0.85 >> (class accuracy): [51.8367, 44.8458, 62.5969, 16.9307, 37.6782, 12.2197, 24.4259, 22.3735, 68.4805, 62.5372]\n",
            "Epoch 0.9 >> (per-task accuracy): 41.58\n",
            "Epoch 0.9 >> (class accuracy): [53.3673, 48.1057, 63.8566, 12.7723, 40.4277, 15.583, 28.2881, 26.8482, 64.8871, 58.0773]\n",
            "Epoch 0.95 >> (per-task accuracy): 41.9\n",
            "Epoch 0.95 >> (class accuracy): [53.5714, 51.3656, 62.9845, 11.7822, 45.0102, 20.1794, 28.6013, 31.1284, 59.4456, 51.338]\n",
            "Epoch 1.0 >> (per-task accuracy): 42.96\n",
            "Epoch 1.0 >> (class accuracy): [56.2245, 50.6608, 62.6938, 15.5446, 43.4827, 24.8879, 29.7495, 30.9339, 58.0082, 54.4103]\n",
            "OCS >> Task 1: {'accuracy': 47.2, 'per_class_accuracy': [73.6735, 80.2643, 16.0853, 35.1485, 11.9145, 55.0448, 66.3883, 41.9261, 39.6304, 50.0496], 'loss': 1.6220882120132447}\n",
            "OCS >> Task 2: {'accuracy': 51.7, 'per_class_accuracy': [77.3469, 85.022, 22.7713, 50.0, 13.2383, 51.7937, 68.8935, 46.2062, 47.9466, 50.8424], 'loss': 1.491953932571411}\n",
            "OCS >> Task 3: {'accuracy': 54.5, 'per_class_accuracy': [81.4286, 93.0396, 35.2713, 55.5446, 16.9043, 53.6996, 66.8058, 47.3735, 53.2854, 37.6611], 'loss': 1.3992963577270507}\n",
            "OCS >> Task 4: {'accuracy': 56.49, 'per_class_accuracy': [82.449, 93.6564, 43.4109, 61.4851, 18.1263, 54.148, 64.5094, 51.1673, 55.7495, 35.778], 'loss': 1.3641644282341003}\n",
            "OCS >> Task 5: {'accuracy': 57.87, 'per_class_accuracy': [82.2449, 95.9471, 48.1589, 67.9208, 15.1731, 52.2422, 59.2902, 60.6031, 54.3121, 37.0664], 'loss': 1.3427367072105407}\n",
            "OCS >> Task 6: {'accuracy': 57.15, 'per_class_accuracy': [81.7347, 93.0396, 44.5736, 68.0198, 14.8676, 40.4709, 57.3069, 65.6615, 56.0575, 43.0129], 'loss': 1.357595008659363}\n",
            "OCS >> Task 7: {'accuracy': 55.52, 'per_class_accuracy': [79.898, 90.3084, 42.6357, 65.9406, 17.1079, 32.7354, 54.1754, 67.3152, 60.3696, 37.5619], 'loss': 1.40440771150589}\n",
            "OCS >> Task 8: {'accuracy': 53.55, 'per_class_accuracy': [77.7551, 82.9956, 39.8256, 57.4257, 27.5967, 23.8789, 52.8184, 68.0934, 59.5483, 38.6521], 'loss': 1.4661200699806214}\n",
            "OCS >> Task 9: {'accuracy': 52.48, 'per_class_accuracy': [73.0612, 81.9383, 40.8915, 49.3069, 34.3177, 16.5919, 49.4781, 69.2607, 60.883, 41.4272], 'loss': 1.5068784321784974}\n",
            "OCS >> Task 10: {'accuracy': 50.15, 'per_class_accuracy': [66.5306, 84.141, 36.9186, 42.8713, 36.4562, 15.8072, 45.6159, 70.3307, 58.9322, 35.778], 'loss': 1.560887075805664}\n",
            "OCS >> Task 11: {'accuracy': 48.37, 'per_class_accuracy': [62.8571, 70.7489, 37.8876, 37.8218, 31.7719, 14.9103, 42.0668, 70.6226, 58.8296, 49.3558], 'loss': 1.5750902498245238}\n",
            "OCS >> Task 12: {'accuracy': 45.93, 'per_class_accuracy': [58.3673, 50.2203, 39.2442, 43.0693, 21.6904, 14.7982, 36.6388, 68.7743, 55.5441, 66.1051], 'loss': 1.5888955081939697}\n",
            "OCS >> Task 13: {'accuracy': 44.64, 'per_class_accuracy': [54.5918, 42.9956, 41.2791, 35.3465, 26.4766, 15.6951, 38.1002, 71.0117, 54.9281, 62.2398], 'loss': 1.590759049987793}\n",
            "OCS >> Task 14: {'accuracy': 43.8, 'per_class_accuracy': [53.8776, 26.5198, 48.6434, 35.7426, 30.8554, 18.9462, 39.5616, 68.2879, 49.384, 64.8167], 'loss': 1.5887492042541504}\n",
            "OCS >> Task 15: {'accuracy': 44.01, 'per_class_accuracy': [54.0816, 23.8767, 59.6899, 32.1782, 37.169, 20.5157, 37.3695, 54.9611, 51.848, 67.6908], 'loss': 1.5824555410385133}\n",
            "OCS >> Task 16: {'accuracy': 43.13, 'per_class_accuracy': [55.3061, 33.7445, 61.9186, 21.6832, 40.1222, 23.4305, 34.0292, 39.8833, 57.5975, 62.4381], 'loss': 1.6323451984405517}\n",
            "OCS >> Task 17: {'accuracy': 42.96, 'per_class_accuracy': [56.2245, 50.6608, 62.6938, 15.5446, 43.4827, 24.8879, 29.7495, 30.9339, 58.0082, 54.4103], 'loss': 1.689578973388672}\n",
            "OCS >> (average accuracy): 49.96764705882353\n",
            "OCS >> (Forgetting): 0.47554374999999993\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 18 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 9.58\n",
            "Epoch 0.05 >> (class accuracy): [1.3265, 0.0, 2.0349, 0.099, 12.9328, 0.0, 0.2088, 2.1401, 79.2608, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 17.99\n",
            "Epoch 0.1 >> (class accuracy): [98.2653, 0.0, 11.531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1027, 70.9613]\n",
            "Epoch 0.15 >> (per-task accuracy): 15.76\n",
            "Epoch 0.15 >> (class accuracy): [99.6939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.3657]\n",
            "Epoch 0.2 >> (per-task accuracy): 17.49\n",
            "Epoch 0.2 >> (class accuracy): [97.9592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 78.1962]\n",
            "Epoch 0.25 >> (per-task accuracy): 18.02\n",
            "Epoch 0.25 >> (class accuracy): [96.3265, 0.0, 0.1938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 84.8365]\n",
            "Epoch 0.3 >> (per-task accuracy): 19.83\n",
            "Epoch 0.3 >> (class accuracy): [91.3265, 0.0, 7.655, 0.0, 0.0, 0.0, 0.0, 0.0973, 10.9856, 89.2963]\n",
            "Epoch 0.35 >> (per-task accuracy): 21.26\n",
            "Epoch 0.35 >> (class accuracy): [86.0204, 0.0, 17.4419, 0.0, 0.1018, 0.0, 13.9875, 0.0, 12.423, 83.9445]\n",
            "Epoch 0.4 >> (per-task accuracy): 22.45\n",
            "Epoch 0.4 >> (class accuracy): [67.6531, 0.0, 62.4031, 0.0, 0.0, 0.0, 1.5658, 0.0, 10.883, 80.9713]\n",
            "Epoch 0.45 >> (per-task accuracy): 24.77\n",
            "Epoch 0.45 >> (class accuracy): [63.8776, 0.0, 66.376, 2.0792, 2.9532, 0.0, 0.0, 0.0, 34.3943, 77.4034]\n",
            "Epoch 0.5 >> (per-task accuracy): 24.96\n",
            "Epoch 0.5 >> (class accuracy): [66.4286, 0.0, 25.2907, 0.0, 11.7108, 2.3543, 1.8789, 0.0973, 72.8953, 71.2587]\n",
            "Epoch 0.55 >> (per-task accuracy): 26.39\n",
            "Epoch 0.55 >> (class accuracy): [58.9796, 0.0, 31.0078, 3.2673, 0.4073, 0.0, 14.0919, 26.9455, 63.5524, 66.6997]\n",
            "Epoch 0.6 >> (per-task accuracy): 26.5\n",
            "Epoch 0.6 >> (class accuracy): [60.7143, 0.0, 28.3915, 5.8416, 3.1568, 0.0, 11.7954, 6.0311, 82.2382, 68.9792]\n",
            "Epoch 0.65 >> (per-task accuracy): 28.57\n",
            "Epoch 0.65 >> (class accuracy): [68.5714, 1.7621, 29.2636, 21.1881, 1.6293, 5.3812, 10.6472, 8.1712, 67.6591, 73.3399]\n",
            "Epoch 0.7 >> (per-task accuracy): 32.33\n",
            "Epoch 0.7 >> (class accuracy): [64.3878, 7.6652, 41.2791, 36.3366, 15.4786, 7.3991, 9.0814, 5.1556, 72.7926, 64.9158]\n",
            "Epoch 0.75 >> (per-task accuracy): 34.17\n",
            "Epoch 0.75 >> (class accuracy): [69.1837, 22.5551, 31.8798, 28.6139, 26.3747, 9.417, 10.4384, 6.8093, 79.9795, 56.7889]\n",
            "Epoch 0.8 >> (per-task accuracy): 39.38\n",
            "Epoch 0.8 >> (class accuracy): [57.7551, 53.2159, 44.0891, 35.6436, 36.558, 18.4978, 12.6305, 24.0272, 64.0657, 43.3102]\n",
            "Epoch 0.85 >> (per-task accuracy): 41.51\n",
            "Epoch 0.85 >> (class accuracy): [55.3061, 61.3216, 53.5853, 27.0297, 39.613, 24.1031, 13.7787, 31.1284, 63.039, 41.328]\n",
            "Epoch 0.9 >> (per-task accuracy): 42.31\n",
            "Epoch 0.9 >> (class accuracy): [59.2857, 51.63, 57.0736, 28.4158, 43.1772, 27.2422, 14.6138, 33.5603, 63.7577, 41.1298]\n",
            "Epoch 0.95 >> (per-task accuracy): 41.17\n",
            "Epoch 0.95 >> (class accuracy): [60.6122, 47.5771, 58.7209, 20.6931, 34.2159, 24.1031, 15.2401, 35.7004, 64.0657, 47.5719]\n",
            "Epoch 1.0 >> (per-task accuracy): 42.02\n",
            "Epoch 1.0 >> (class accuracy): [55.4082, 60.0, 57.1705, 19.703, 35.8452, 33.1839, 18.5804, 30.642, 59.6509, 46.2834]\n",
            "OCS >> Task 1: {'accuracy': 44.12, 'per_class_accuracy': [78.5714, 63.7885, 20.5426, 27.6238, 18.3299, 42.8251, 60.9603, 45.6226, 41.4784, 40.4361], 'loss': 1.6867397388458252}\n",
            "OCS >> Task 2: {'accuracy': 50.01, 'per_class_accuracy': [82.551, 75.1542, 27.8101, 38.9109, 19.4501, 44.6188, 66.9102, 55.8366, 47.7413, 38.6521], 'loss': 1.5294198602676392}\n",
            "OCS >> Task 3: {'accuracy': 53.32, 'per_class_accuracy': [85.4082, 83.348, 39.2442, 43.5644, 20.4684, 49.4395, 67.4322, 56.323, 53.1828, 31.6155], 'loss': 1.415644983100891}\n",
            "OCS >> Task 4: {'accuracy': 54.78, 'per_class_accuracy': [86.1224, 85.2863, 49.031, 46.0396, 20.5703, 53.4753, 68.2672, 57.0039, 49.076, 29.5342], 'loss': 1.3721376180648803}\n",
            "OCS >> Task 5: {'accuracy': 56.09, 'per_class_accuracy': [85.9184, 91.4537, 52.8101, 47.0297, 16.0896, 56.278, 63.6743, 64.0078, 44.9692, 33.9941], 'loss': 1.3374198120117187}\n",
            "OCS >> Task 6: {'accuracy': 54.89, 'per_class_accuracy': [85.2041, 89.0749, 50.2907, 45.1485, 16.9043, 48.3184, 61.7954, 67.2179, 39.4251, 40.0396], 'loss': 1.3618119578361512}\n",
            "OCS >> Task 7: {'accuracy': 51.71, 'per_class_accuracy': [82.6531, 76.0352, 51.7442, 45.7426, 21.7923, 39.9103, 57.3069, 67.8988, 40.0411, 29.2369], 'loss': 1.4167212547302246}\n",
            "OCS >> Task 8: {'accuracy': 48.52, 'per_class_accuracy': [78.6735, 59.0308, 50.0969, 40.7921, 39.3075, 28.2511, 54.071, 67.5097, 38.501, 25.4708], 'loss': 1.4907947477340697}\n",
            "OCS >> Task 9: {'accuracy': 46.85, 'per_class_accuracy': [74.0816, 49.0749, 49.1279, 37.3267, 44.8065, 20.6278, 48.4342, 71.0117, 43.6345, 27.2547], 'loss': 1.5325412998199464}\n",
            "OCS >> Task 10: {'accuracy': 45.21, 'per_class_accuracy': [65.2041, 48.2819, 46.2209, 36.9307, 44.1955, 18.6099, 44.3633, 72.5681, 44.6612, 27.552], 'loss': 1.5764735857009888}\n",
            "OCS >> Task 11: {'accuracy': 43.37, 'per_class_accuracy': [59.7959, 34.185, 40.407, 38.8119, 39.9185, 15.6951, 40.501, 73.8327, 49.1786, 39.2468], 'loss': 1.580421015739441}\n",
            "OCS >> Task 12: {'accuracy': 43.12, 'per_class_accuracy': [53.2653, 24.4053, 37.2093, 47.4257, 32.2811, 14.1256, 35.4906, 75.0973, 52.4641, 57.8791], 'loss': 1.5972422401428223}\n",
            "OCS >> Task 13: {'accuracy': 43.08, 'per_class_accuracy': [50.2041, 24.9339, 37.8876, 44.1584, 29.4297, 14.1256, 35.4906, 75.0973, 53.0801, 64.6184], 'loss': 1.5908255475997926}\n",
            "OCS >> Task 14: {'accuracy': 43.16, 'per_class_accuracy': [47.9592, 24.0529, 46.4147, 45.3465, 26.7821, 20.7399, 34.1336, 68.5798, 47.7413, 68.4836], 'loss': 1.605174461364746}\n",
            "OCS >> Task 15: {'accuracy': 44.31, 'per_class_accuracy': [48.1633, 23.1718, 55.9109, 46.0396, 29.2261, 24.4395, 35.1775, 60.0195, 52.3614, 67.889], 'loss': 1.5901025680541991}\n",
            "OCS >> Task 16: {'accuracy': 43.79, 'per_class_accuracy': [49.6939, 31.8062, 60.7558, 38.2178, 33.0957, 26.9058, 30.7933, 47.4708, 56.3655, 61.5461], 'loss': 1.6315049264907837}\n",
            "OCS >> Task 17: {'accuracy': 44.4, 'per_class_accuracy': [52.9592, 48.1938, 63.7597, 29.604, 35.5397, 30.4933, 26.5136, 41.8288, 56.0575, 56.0951], 'loss': 1.6593158966064454}\n",
            "OCS >> Task 18: {'accuracy': 42.02, 'per_class_accuracy': [55.4082, 60.0, 57.1705, 19.703, 35.8452, 33.1839, 18.5804, 30.642, 59.6509, 46.2834], 'loss': 1.7839484678268434}\n",
            "OCS >> (average accuracy): 47.37499999999999\n",
            "OCS >> (Forgetting): 0.5026999999999999\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 19 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 11.71\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 7.4009, 2.907, 20.297, 86.3544, 0.0, 0.0, 0.0973, 0.308, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 15.37\n",
            "Epoch 0.1 >> (class accuracy): [47.6531, 0.0881, 0.0, 0.0, 37.78, 0.0, 0.0, 0.0, 5.4415, 63.9247]\n",
            "Epoch 0.15 >> (per-task accuracy): 17.88\n",
            "Epoch 0.15 >> (class accuracy): [82.7551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8214, 96.0357]\n",
            "Epoch 0.2 >> (per-task accuracy): 17.08\n",
            "Epoch 0.2 >> (class accuracy): [97.7551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 74.331]\n",
            "Epoch 0.25 >> (per-task accuracy): 16.24\n",
            "Epoch 0.25 >> (class accuracy): [98.3673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 65.4113]\n",
            "Epoch 0.3 >> (per-task accuracy): 17.33\n",
            "Epoch 0.3 >> (class accuracy): [96.2245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 78.2953]\n",
            "Epoch 0.35 >> (per-task accuracy): 17.6\n",
            "Epoch 0.35 >> (class accuracy): [96.0204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.1695]\n",
            "Epoch 0.4 >> (per-task accuracy): 18.05\n",
            "Epoch 0.4 >> (class accuracy): [93.2653, 0.0, 2.8101, 0.0, 0.1018, 0.0, 0.0, 0.0, 0.0, 85.332]\n",
            "Epoch 0.45 >> (per-task accuracy): 18.01\n",
            "Epoch 0.45 >> (class accuracy): [87.2449, 0.0, 1.6473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2053, 91.8731]\n",
            "Epoch 0.5 >> (per-task accuracy): 22.57\n",
            "Epoch 0.5 >> (class accuracy): [81.6327, 0.0, 46.4147, 0.0, 10.0815, 0.0, 0.0, 0.0, 3.1828, 84.0436]\n",
            "Epoch 0.55 >> (per-task accuracy): 23.78\n",
            "Epoch 0.55 >> (class accuracy): [76.5306, 0.0, 59.2054, 0.0, 20.5703, 0.0, 0.0, 0.0, 4.3121, 76.6105]\n",
            "Epoch 0.6 >> (per-task accuracy): 25.02\n",
            "Epoch 0.6 >> (class accuracy): [72.7551, 0.0, 57.9457, 9.802, 4.5825, 0.0, 0.6263, 0.0, 22.8953, 81.0704]\n",
            "Epoch 0.65 >> (per-task accuracy): 25.86\n",
            "Epoch 0.65 >> (class accuracy): [69.1837, 0.0, 26.4535, 0.0, 16.8024, 0.0, 2.1921, 0.0973, 82.8542, 63.5282]\n",
            "Epoch 0.7 >> (per-task accuracy): 29.29\n",
            "Epoch 0.7 >> (class accuracy): [67.551, 0.0, 59.3023, 0.0, 34.6232, 0.0, 8.5595, 1.9455, 66.3244, 56.1943]\n",
            "Epoch 0.75 >> (per-task accuracy): 31.28\n",
            "Epoch 0.75 >> (class accuracy): [62.6531, 0.0, 52.0349, 32.7723, 34.3177, 0.0, 18.3716, 39.1051, 36.7556, 36.9673]\n",
            "Epoch 0.8 >> (per-task accuracy): 31.69\n",
            "Epoch 0.8 >> (class accuracy): [52.1429, 11.7181, 70.0581, 28.8119, 30.8554, 0.1121, 37.9958, 6.5175, 17.8645, 59.663]\n",
            "Epoch 0.85 >> (per-task accuracy): 32.76\n",
            "Epoch 0.85 >> (class accuracy): [59.3878, 18.5903, 74.3217, 5.3465, 33.5031, 0.1121, 8.7683, 16.8288, 51.9507, 56.3925]\n",
            "Epoch 0.9 >> (per-task accuracy): 36.79\n",
            "Epoch 0.9 >> (class accuracy): [53.3673, 46.5198, 73.1589, 8.2178, 47.8615, 4.7085, 24.0084, 29.8638, 43.8398, 31.1199]\n",
            "Epoch 0.95 >> (per-task accuracy): 36.4\n",
            "Epoch 0.95 >> (class accuracy): [53.6735, 35.1542, 67.345, 22.3762, 46.2322, 1.2332, 23.382, 34.144, 49.076, 27.3538]\n",
            "Epoch 1.0 >> (per-task accuracy): 36.29\n",
            "Epoch 1.0 >> (class accuracy): [64.2857, 34.2731, 63.2752, 40.198, 38.0855, 2.0179, 17.2234, 22.9572, 28.3368, 47.7701]\n",
            "OCS >> Task 1: {'accuracy': 39.67, 'per_class_accuracy': [82.3469, 47.4009, 28.6822, 50.396, 13.6456, 14.3498, 47.5992, 22.2763, 32.4435, 54.9058], 'loss': 1.7645672428131103}\n",
            "OCS >> Task 2: {'accuracy': 44.28, 'per_class_accuracy': [85.102, 55.7709, 29.3605, 59.2079, 14.5621, 15.9193, 51.6701, 31.0311, 38.6037, 57.9782], 'loss': 1.6841446908950806}\n",
            "OCS >> Task 3: {'accuracy': 48.59, 'per_class_accuracy': [88.7755, 62.2026, 30.7171, 68.4158, 18.0244, 21.861, 56.3674, 27.4319, 48.152, 60.6541], 'loss': 1.5950256555557252}\n",
            "OCS >> Task 4: {'accuracy': 49.55, 'per_class_accuracy': [90.5102, 62.9956, 32.3643, 69.802, 16.0896, 25.5605, 54.9061, 26.6537, 48.2546, 65.2131], 'loss': 1.5740514707565307}\n",
            "OCS >> Task 5: {'accuracy': 50.96, 'per_class_accuracy': [91.0204, 65.9912, 33.624, 76.0396, 10.0815, 25.4484, 52.4008, 33.6576, 44.2505, 72.8444], 'loss': 1.5597665367126465}\n",
            "OCS >> Task 6: {'accuracy': 49.04, 'per_class_accuracy': [90.9184, 62.2026, 29.845, 75.8416, 6.3136, 18.722, 50.0, 35.8949, 38.501, 77.4034], 'loss': 1.5686919553756713}\n",
            "OCS >> Task 7: {'accuracy': 48.03, 'per_class_accuracy': [89.4898, 46.1674, 29.845, 76.7327, 4.7862, 13.2287, 48.4342, 40.856, 47.6386, 79.8811], 'loss': 1.5876886444091798}\n",
            "OCS >> Task 8: {'accuracy': 44.5, 'per_class_accuracy': [87.449, 29.6035, 27.1318, 74.4554, 9.2668, 10.426, 44.0501, 35.214, 45.7906, 80.3766], 'loss': 1.6179514165878295}\n",
            "OCS >> Task 9: {'accuracy': 42.36, 'per_class_accuracy': [85.0, 19.0308, 31.2016, 70.396, 12.4236, 5.7175, 40.0835, 34.144, 44.7639, 80.2775], 'loss': 1.6259553256988526}\n",
            "OCS >> Task 10: {'accuracy': 40.1, 'per_class_accuracy': [78.9796, 12.0705, 29.7481, 66.5347, 18.1263, 5.2691, 32.1503, 41.537, 39.6304, 76.7096], 'loss': 1.65629624004364}\n",
            "OCS >> Task 11: {'accuracy': 38.45, 'per_class_accuracy': [76.5306, 8.1938, 30.1357, 67.2277, 15.0713, 4.5964, 26.3048, 41.7315, 33.7782, 80.5748], 'loss': 1.6780870056152344}\n",
            "OCS >> Task 12: {'accuracy': 36.21, 'per_class_accuracy': [71.0204, 3.7885, 32.7519, 72.2772, 9.2668, 4.148, 18.476, 36.5759, 28.1314, 85.1338], 'loss': 1.7180995615005492}\n",
            "OCS >> Task 13: {'accuracy': 35.84, 'per_class_accuracy': [67.7551, 3.0837, 37.8876, 69.3069, 17.7189, 2.3543, 16.3883, 42.7043, 19.5072, 80.5748], 'loss': 1.7192722976684571}\n",
            "OCS >> Task 14: {'accuracy': 35.87, 'per_class_accuracy': [65.4082, 2.3789, 50.2907, 67.4257, 25.2546, 1.6816, 15.8664, 44.7471, 12.5257, 71.556], 'loss': 1.7292942541122436}\n",
            "OCS >> Task 15: {'accuracy': 35.61, 'per_class_accuracy': [63.5714, 4.0529, 60.7558, 66.2376, 31.2627, 1.4574, 14.9269, 35.6031, 11.191, 65.2131], 'loss': 1.722902297592163}\n",
            "OCS >> Task 16: {'accuracy': 36.22, 'per_class_accuracy': [64.0816, 16.652, 66.5698, 58.4158, 38.5947, 1.4574, 17.8497, 29.0856, 12.423, 54.0139], 'loss': 1.7329175165176391}\n",
            "OCS >> Task 17: {'accuracy': 37.71, 'per_class_accuracy': [63.8776, 27.8414, 72.9651, 53.2673, 42.2607, 1.4574, 18.7891, 30.0584, 14.271, 47.7701], 'loss': 1.7309109956741333}\n",
            "OCS >> Task 18: {'accuracy': 37.63, 'per_class_accuracy': [63.7755, 36.7401, 71.5116, 44.7525, 43.4827, 1.6816, 17.9541, 25.2918, 20.0205, 45.7879], 'loss': 1.7707727920532226}\n",
            "OCS >> Task 19: {'accuracy': 36.29, 'per_class_accuracy': [64.2857, 34.2731, 63.2752, 40.198, 38.0855, 2.0179, 17.2234, 22.9572, 28.3368, 47.7701], 'loss': 1.8047781665802003}\n",
            "OCS >> (average accuracy): 41.416315789473686\n",
            "OCS >> (Forgetting): 0.5625888888888888\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "---- Task 20 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 10.98\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 67.8414, 0.0, 0.396, 26.8839, 0.0, 0.0, 3.5019, 2.4641, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 15.96\n",
            "Epoch 0.1 >> (class accuracy): [48.1633, 18.4141, 0.0, 0.0, 91.6497, 0.0, 0.0, 0.5837, 0.924, 0.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 17.14\n",
            "Epoch 0.15 >> (class accuracy): [77.551, 0.0, 0.0, 0.0, 97.1487, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.2 >> (per-task accuracy): 17.97\n",
            "Epoch 0.2 >> (class accuracy): [92.2449, 0.0, 0.0, 0.0, 90.9369, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.25 >> (per-task accuracy): 16.42\n",
            "Epoch 0.25 >> (class accuracy): [99.0816, 0.0, 0.0, 0.0, 68.3299, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.3 >> (per-task accuracy): 13.57\n",
            "Epoch 0.3 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 38.391, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.35 >> (per-task accuracy): 12.6\n",
            "Epoch 0.35 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 28.5132, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.4 >> (per-task accuracy): 13.24\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 35.0305, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.45 >> (per-task accuracy): 14.66\n",
            "Epoch 0.45 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 49.4908, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.5 >> (per-task accuracy): 15.68\n",
            "Epoch 0.5 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 59.8778, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.55 >> (per-task accuracy): 16.35\n",
            "Epoch 0.55 >> (class accuracy): [99.1837, 0.0, 0.0, 0.0, 67.5153, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 16.96\n",
            "Epoch 0.6 >> (class accuracy): [98.0612, 0.0, 0.0, 0.0, 74.8473, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.65 >> (per-task accuracy): 17.37\n",
            "Epoch 0.65 >> (class accuracy): [97.3469, 0.0, 0.0, 0.0, 79.7352, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.7 >> (per-task accuracy): 17.6\n",
            "Epoch 0.7 >> (class accuracy): [96.5306, 0.0, 0.0, 0.0, 82.8921, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.75 >> (per-task accuracy): 17.79\n",
            "Epoch 0.75 >> (class accuracy): [95.0, 0.0, 0.0, 0.0, 86.3544, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 17.91\n",
            "Epoch 0.8 >> (class accuracy): [94.2857, 0.0, 0.1938, 0.0, 88.0855, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.85 >> (per-task accuracy): 18.02\n",
            "Epoch 0.85 >> (class accuracy): [93.2653, 0.0, 0.7752, 0.0, 89.613, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.9 >> (per-task accuracy): 18.21\n",
            "Epoch 0.9 >> (class accuracy): [91.8367, 0.0, 2.907, 0.0, 90.6314, 0.0, 0.0, 0.0, 0.1027, 0.0]\n",
            "Epoch 0.95 >> (per-task accuracy): 19.03\n",
            "Epoch 0.95 >> (class accuracy): [91.0204, 0.0, 10.6589, 0.0, 90.835, 0.0, 0.2088, 0.0, 0.7187, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 20.16\n",
            "Epoch 1.0 >> (class accuracy): [89.898, 0.0, 19.3798, 0.0, 89.9185, 0.0, 2.6096, 0.0, 2.7721, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 19.54, 'per_class_accuracy': [94.0816, 0.0, 7.1705, 0.099, 83.8086, 0.0, 7.3069, 0.0, 6.5708, 0.0], 'loss': 2.1339938011169433}\n",
            "OCS >> Task 2: {'accuracy': 19.97, 'per_class_accuracy': [94.898, 0.0, 5.1357, 0.0, 85.336, 0.0, 11.0647, 0.0, 7.1869, 0.0], 'loss': 2.125313875579834}\n",
            "OCS >> Task 3: {'accuracy': 20.43, 'per_class_accuracy': [95.9184, 0.0, 3.9729, 0.0, 87.78, 0.0, 13.8831, 0.0, 6.8789, 0.0], 'loss': 2.1137376586914063}\n",
            "OCS >> Task 4: {'accuracy': 20.16, 'per_class_accuracy': [96.5306, 0.0, 3.3915, 0.0, 90.0204, 0.0, 12.1086, 0.0, 3.5934, 0.0], 'loss': 2.107350492858887}\n",
            "OCS >> Task 5: {'accuracy': 19.92, 'per_class_accuracy': [96.6327, 0.0, 2.5194, 0.198, 90.1222, 0.0, 11.1691, 0.0, 2.5667, 0.0], 'loss': 2.10099354057312}\n",
            "OCS >> Task 6: {'accuracy': 19.98, 'per_class_accuracy': [96.7347, 0.0, 2.5194, 0.198, 90.4277, 0.0, 11.8998, 0.0, 2.0534, 0.0], 'loss': 2.092661856842041}\n",
            "OCS >> Task 7: {'accuracy': 19.78, 'per_class_accuracy': [97.551, 0.0, 1.1628, 0.099, 89.4094, 0.0, 10.4384, 0.0, 3.1828, 0.0], 'loss': 2.0939027088165285}\n",
            "OCS >> Task 8: {'accuracy': 19.92, 'per_class_accuracy': [96.3265, 0.0, 3.2946, 0.0, 87.4745, 0.0, 10.2296, 0.0, 5.8522, 0.0], 'loss': 2.09365114402771}\n",
            "OCS >> Task 9: {'accuracy': 20.13, 'per_class_accuracy': [95.5102, 0.0, 6.8798, 0.495, 86.9654, 0.0, 6.9937, 0.0, 8.2136, 0.0], 'loss': 2.095022808456421}\n",
            "OCS >> Task 10: {'accuracy': 21.07, 'per_class_accuracy': [93.8776, 0.0, 13.7597, 0.0, 87.9837, 0.0, 5.428, 0.0, 13.2444, 0.0], 'loss': 2.0919158641815185}\n",
            "OCS >> Task 11: {'accuracy': 21.66, 'per_class_accuracy': [95.2041, 0.0, 18.5078, 0.0, 87.5764, 0.0, 4.1754, 0.0, 14.5791, 0.0], 'loss': 2.092541897201538}\n",
            "OCS >> Task 12: {'accuracy': 21.37, 'per_class_accuracy': [95.5102, 0.0, 20.6395, 0.099, 86.1507, 0.0, 2.8184, 0.0, 11.7043, 0.0], 'loss': 2.1018512825012206}\n",
            "OCS >> Task 13: {'accuracy': 21.02, 'per_class_accuracy': [94.2857, 0.0, 19.186, 0.0, 88.9002, 0.0, 1.5658, 0.0, 9.4456, 0.0], 'loss': 2.10268543510437}\n",
            "OCS >> Task 14: {'accuracy': 20.86, 'per_class_accuracy': [94.3878, 0.0, 18.9922, 0.0, 90.3259, 0.0, 1.1482, 0.0, 6.8789, 0.0], 'loss': 2.103913734817505}\n",
            "OCS >> Task 15: {'accuracy': 20.47, 'per_class_accuracy': [94.0816, 0.0, 18.1202, 0.0, 89.3075, 0.0, 1.9833, 0.0, 4.3121, 0.0], 'loss': 2.1074736179351805}\n",
            "OCS >> Task 16: {'accuracy': 20.27, 'per_class_accuracy': [92.8571, 0.0, 18.4109, 0.0, 91.3442, 0.0, 1.6701, 0.0, 1.4374, 0.0], 'loss': 2.102886535644531}\n",
            "OCS >> Task 17: {'accuracy': 20.62, 'per_class_accuracy': [91.7347, 0.0, 23.5465, 0.0, 90.5295, 0.0, 2.5052, 0.0, 0.7187, 0.0], 'loss': 2.102026138305664}\n",
            "OCS >> Task 18: {'accuracy': 20.43, 'per_class_accuracy': [90.102, 0.0, 21.7054, 0.0, 91.6497, 0.0, 2.6096, 0.0, 1.1294, 0.0], 'loss': 2.102718702697754}\n",
            "OCS >> Task 19: {'accuracy': 20.54, 'per_class_accuracy': [90.5102, 0.0, 22.5775, 0.0, 90.224, 0.0, 3.2359, 0.0, 1.7454, 0.0], 'loss': 2.1061707576751707}\n",
            "OCS >> Task 20: {'accuracy': 20.16, 'per_class_accuracy': [89.898, 0.0, 19.3798, 0.0, 89.9185, 0.0, 2.6096, 0.0, 2.7721, 0.0], 'loss': 2.1165811553955076}\n",
            "OCS >> (average accuracy): 20.415000000000003\n",
            "OCS >> (Forgetting): 0.7753157894736842\n",
            "Maximum per-task accuracies: [97.96]\n",
            "\n",
            "{'num_tasks': 20, 'per_task_rotation': 9, 'memory_size': 200, 'dataset': 'rot-mnist', 'device': 'cuda', 'momentum': 0.75, 'mlp_hiddens': 256, 'dropout': 0.2, 'lr_decay': 0.75, 'n_classes': 10, 'seq_lr': 0.006, 'stream_size': 100, 'ocspick': True, 'batch_size': 5, 'tau': 900.0, 'ref_hyp': 9.0, 'n_substeps': 20}\n"
          ]
        }
      ],
      "source": [
        "# NEW\n",
        "DATASET = 'rot-mnist'\n",
        "HIDDENS = 256\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = {\n",
        "    'num_tasks': 20,\n",
        "    'per_task_rotation': 9,\n",
        "    'memory_size': 200,\n",
        "    'dataset': DATASET,\n",
        "    'device': DEVICE,\n",
        "    'momentum': 0.7,\n",
        "    'mlp_hiddens': HIDDENS,\n",
        "    'dropout': 0.15,\n",
        "    'lr_decay': 0.7 if 'rot-mnist' in DATASET else 0.76,\n",
        "    'n_classes': 10,\n",
        "    'seq_lr': 0.006,\n",
        "    'stream_size': 100,\n",
        "    'ocspick': True,\n",
        "    'batch_size': 5,\n",
        "     'tau': 950.0,\n",
        "    'ref_hyp': 10. if 'rot-mnist' in DATASET else 50\n",
        "}\n",
        "\n",
        "log_dir =  f\"./summery/{config['dataset']}\"\n",
        "summary = SummaryWriter(log_dir)\n",
        "\n",
        "experiment = Experiment(api_key=\"hidden_key\", project_name=\"mnist\", disabled=True)\n",
        "\n",
        "loaders = get_all_loaders(config)\n",
        "\n",
        "\n",
        "def evaluate_model(model, task, loaders, config):\n",
        "    accuracies, losses = [], []\n",
        "    for t in range(1, task + 1):\n",
        "        metrics = eval_single_epoch(model, loaders['sequential'][t]['val'], config)\n",
        "        accuracies.append(metrics['accuracy'])\n",
        "        losses.append(metrics['loss'])\n",
        "        print(f'OCS >> Task {t}: {metrics}')\n",
        "    return accuracies, losses\n",
        "\n",
        "def main():\n",
        "    setup_experiment(experiment, config)\n",
        "\n",
        "    max_accuracies = [0.0] * config['num_tasks']\n",
        "    for task in range(1, config['num_tasks'] + 1):\n",
        "        print(f'---- Task {task} (OCS) ----')\n",
        "        model = train_task_sequentially(task, loaders, config, summary)\n",
        "\n",
        "        accuracies, _ = evaluate_model(model, task, loaders, config)\n",
        "        max_accuracies = [max(acc, max_acc) for acc, max_acc in zip(accuracies, max_accuracies)]\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies)\n",
        "        if task > 1:\n",
        "            forgetting = np.mean(np.array(max_accuracies[:task - 1]) - np.array(accuracies[:task - 1]))/ 100\n",
        "        else:\n",
        "            forgetting = 0.0\n",
        "\n",
        "        print(f\"OCS >> (average accuracy): {avg_accuracy}\")\n",
        "        print(f\"OCS >> (Forgetting): {forgetting}\")\n",
        "        summary.add_scalar('cl_average_accuracy', avg_accuracy, task - 1)\n",
        "        print(f'Maximum per-task accuracies: {max_accuracies}\\n')\n",
        "\n",
        "    print(config)\n",
        "    experiment.end()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogU8kdShsqi6",
        "outputId": "99105d48-991b-4ba3-807c-6d25683ca3c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "loading coreset placeholder noisy-rot-mnist\n",
            "loading noisy-rot-mnist for task 1\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 2\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 3\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 4\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 5\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 6\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 7\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 8\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 9\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 10\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 11\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 12\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 13\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 14\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 15\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 16\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 17\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 18\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 19\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 20\n",
            "Noisy Rotated MNIST\n",
            "---- Task 1 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 69.3\n",
            "Epoch 0.2 >> (class accuracy): [95.9184, 98.9427, 65.0194, 59.2079, 74.8473, 0.4484, 79.1232, 91.0506, 72.6899, 45.2924]\n",
            "Epoch 0.4 >> (per-task accuracy): 85.96\n",
            "Epoch 0.4 >> (class accuracy): [96.2245, 98.0617, 78.876, 87.0297, 95.6212, 71.1883, 90.9186, 88.5214, 80.2875, 70.3667]\n",
            "Epoch 0.6 >> (per-task accuracy): 90.47\n",
            "Epoch 0.6 >> (class accuracy): [98.0612, 98.326, 84.6899, 90.0, 94.6029, 81.5022, 91.6493, 90.0778, 85.0103, 89.0981]\n",
            "Epoch 0.8 >> (per-task accuracy): 91.82\n",
            "Epoch 0.8 >> (class accuracy): [97.8571, 98.1498, 85.562, 91.9802, 93.5845, 86.435, 92.5887, 91.4397, 87.269, 92.1705]\n",
            "Epoch 1.0 >> (per-task accuracy): 92.86\n",
            "Epoch 1.0 >> (class accuracy): [98.5714, 98.0617, 89.1473, 91.9802, 94.0937, 88.9013, 93.3194, 92.4125, 89.117, 92.0714]\n",
            "OCS >> Task 1: {'accuracy': 92.86, 'per_class_accuracy': [98.5714, 98.0617, 89.1473, 91.9802, 94.0937, 88.9013, 93.3194, 92.4125, 89.117, 92.0714], 'loss': 0.287129345202446}\n",
            "OCS >> (average accuracy): 92.86\n",
            "OCS >> (Forgetting): 0.0\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 2 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 72.16\n",
            "Epoch 0.2 >> (class accuracy): [93.7755, 96.8282, 55.6202, 83.9604, 41.2424, 19.5067, 93.3194, 72.0817, 71.2526, 86.0258]\n",
            "Epoch 0.4 >> (per-task accuracy): 82.97\n",
            "Epoch 0.4 >> (class accuracy): [92.6531, 98.0617, 79.3605, 82.7723, 80.3462, 74.6637, 90.2923, 86.1868, 70.0205, 72.6462]\n",
            "Epoch 0.6 >> (per-task accuracy): 86.02\n",
            "Epoch 0.6 >> (class accuracy): [93.2653, 98.4141, 80.7171, 85.0495, 85.2342, 81.9507, 91.858, 86.6732, 72.3819, 82.7552]\n",
            "Epoch 0.8 >> (per-task accuracy): 87.23\n",
            "Epoch 0.8 >> (class accuracy): [94.4898, 98.5022, 83.1395, 86.0396, 86.0489, 84.8655, 92.5887, 89.2996, 71.9713, 83.6472]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_13774/1459498902.py:12: RuntimeWarning: divide by zero encountered in scalar floor_divide\n",
            "  if (num_residuals // num_class) > 0:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1.0 >> (per-task accuracy): 88.0\n",
            "Epoch 1.0 >> (class accuracy): [93.2653, 98.5022, 82.8488, 86.3366, 86.9654, 86.2108, 92.6931, 91.3424, 75.154, 85.1338]\n",
            "OCS >> Task 1: {'accuracy': 86.04, 'per_class_accuracy': [92.551, 96.5639, 80.3295, 86.7327, 83.5031, 85.3139, 87.7871, 92.1206, 70.8419, 82.9534], 'loss': 0.4794124701499939}\n",
            "OCS >> Task 2: {'accuracy': 88.0, 'per_class_accuracy': [93.2653, 98.5022, 82.8488, 86.3366, 86.9654, 86.2108, 92.6931, 91.3424, 75.154, 85.1338], 'loss': 0.40091448981761935}\n",
            "OCS >> (average accuracy): 87.02000000000001\n",
            "OCS >> (Forgetting): 0.06819999999999993\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 3 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 65.52\n",
            "Epoch 0.2 >> (class accuracy): [90.6122, 98.2379, 30.0388, 82.9703, 80.8554, 0.8969, 94.1545, 84.3385, 57.9055, 26.3627]\n",
            "Epoch 0.4 >> (per-task accuracy): 79.78\n",
            "Epoch 0.4 >> (class accuracy): [91.3265, 97.6211, 69.186, 80.6931, 86.3544, 58.4081, 89.7704, 84.0467, 63.655, 72.6462]\n",
            "Epoch 0.6 >> (per-task accuracy): 83.21\n",
            "Epoch 0.6 >> (class accuracy): [91.8367, 98.4141, 76.8411, 82.0792, 87.6782, 67.2646, 91.6493, 85.214, 67.6591, 80.0793]\n",
            "Epoch 0.8 >> (per-task accuracy): 85.17\n",
            "Epoch 0.8 >> (class accuracy): [92.551, 98.5903, 79.845, 82.4752, 88.391, 74.2152, 91.7537, 86.6732, 72.6899, 81.8632]\n",
            "Epoch 1.0 >> (per-task accuracy): 86.51\n",
            "Epoch 1.0 >> (class accuracy): [93.2653, 98.6784, 79.3605, 85.3465, 89.1039, 74.5516, 93.4238, 88.3268, 78.3368, 82.2597]\n",
            "OCS >> Task 1: {'accuracy': 79.91, 'per_class_accuracy': [91.6327, 85.9031, 69.2829, 79.0099, 82.0774, 78.4753, 86.1169, 84.2412, 70.3285, 71.6551], 'loss': 0.6971127596855163}\n",
            "OCS >> Task 2: {'accuracy': 85.67, 'per_class_accuracy': [92.6531, 94.8899, 79.1667, 85.3465, 87.8819, 81.7265, 91.1273, 88.5214, 76.694, 77.4034], 'loss': 0.48386383228302005}\n",
            "OCS >> Task 3: {'accuracy': 86.51, 'per_class_accuracy': [93.2653, 98.6784, 79.3605, 85.3465, 89.1039, 74.5516, 93.4238, 88.3268, 78.3368, 82.2597], 'loss': 0.44448142366409304}\n",
            "OCS >> (average accuracy): 84.02999999999999\n",
            "OCS >> (Forgetting): 0.1007\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 4 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 51.18\n",
            "Epoch 0.2 >> (class accuracy): [56.6327, 81.4978, 77.5194, 0.297, 87.2709, 73.6547, 65.1357, 58.2685, 6.8789, 3.0723]\n",
            "Epoch 0.4 >> (per-task accuracy): 78.19\n",
            "Epoch 0.4 >> (class accuracy): [86.2245, 93.8326, 73.3527, 75.4455, 83.1976, 59.0807, 87.5783, 71.1089, 70.1232, 78.5927]\n",
            "Epoch 0.6 >> (per-task accuracy): 81.26\n",
            "Epoch 0.6 >> (class accuracy): [85.9184, 95.9471, 74.031, 82.7723, 87.9837, 69.7309, 91.858, 73.7354, 67.7618, 80.3766]\n",
            "Epoch 0.8 >> (per-task accuracy): 82.1\n",
            "Epoch 0.8 >> (class accuracy): [87.551, 96.4758, 74.1279, 82.7723, 89.3075, 77.0179, 93.3194, 78.0156, 61.807, 78.6918]\n",
            "Epoch 1.0 >> (per-task accuracy): 83.88\n",
            "Epoch 1.0 >> (class accuracy): [87.449, 98.326, 77.907, 84.8515, 89.8167, 73.2063, 94.3633, 76.4591, 73.4086, 80.6739]\n",
            "OCS >> Task 1: {'accuracy': 73.94, 'per_class_accuracy': [84.5918, 72.511, 57.4612, 76.6337, 82.2811, 78.139, 82.6722, 82.393, 51.1294, 72.6462], 'loss': 0.9067529670715332}\n",
            "OCS >> Task 2: {'accuracy': 80.82, 'per_class_accuracy': [87.0408, 89.3392, 68.7016, 83.1683, 87.2709, 79.8206, 89.666, 83.0739, 62.6283, 76.7096], 'loss': 0.6154497002601623}\n",
            "OCS >> Task 3: {'accuracy': 84.01, 'per_class_accuracy': [88.3673, 95.3304, 75.6783, 86.0396, 89.613, 77.0179, 92.38, 81.5175, 71.6632, 80.773], 'loss': 0.49375218534469606}\n",
            "OCS >> Task 4: {'accuracy': 83.88, 'per_class_accuracy': [87.449, 98.326, 77.907, 84.8515, 89.8167, 73.2063, 94.3633, 76.4591, 73.4086, 80.6739], 'loss': 0.5124987624168396}\n",
            "OCS >> (average accuracy): 80.6625\n",
            "OCS >> (Forgetting): 0.1327\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 5 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 48.44\n",
            "Epoch 0.2 >> (class accuracy): [96.6327, 78.326, 0.7752, 65.2475, 0.9165, 0.8969, 82.3591, 92.607, 0.0, 57.78]\n",
            "Epoch 0.4 >> (per-task accuracy): 71.37\n",
            "Epoch 0.4 >> (class accuracy): [77.2449, 90.3965, 40.2132, 70.495, 79.8371, 60.9865, 85.595, 62.9377, 64.271, 79.8811]\n",
            "Epoch 0.6 >> (per-task accuracy): 74.76\n",
            "Epoch 0.6 >> (class accuracy): [76.3265, 93.6564, 56.686, 72.6733, 85.7434, 63.3408, 86.8476, 56.1284, 74.23, 79.9802]\n",
            "Epoch 0.8 >> (per-task accuracy): 76.42\n",
            "Epoch 0.8 >> (class accuracy): [80.3061, 95.5066, 55.2326, 70.9901, 83.5031, 71.7489, 89.3528, 58.6576, 75.3593, 82.3588]\n",
            "Epoch 1.0 >> (per-task accuracy): 78.12\n",
            "Epoch 1.0 >> (class accuracy): [81.8367, 95.4185, 62.4031, 76.4356, 84.3177, 70.4036, 91.1273, 57.7821, 76.386, 83.6472]\n",
            "OCS >> Task 1: {'accuracy': 67.84, 'per_class_accuracy': [85.102, 76.8282, 53.876, 71.4851, 80.0407, 51.009, 77.3486, 77.6265, 34.7023, 67.5917], 'loss': 1.1059591970443725}\n",
            "OCS >> Task 2: {'accuracy': 75.43, 'per_class_accuracy': [86.1224, 89.9559, 65.1163, 78.1188, 84.1141, 64.1256, 84.9687, 75.6809, 50.5133, 72.8444], 'loss': 0.8036879473686218}\n",
            "OCS >> Task 3: {'accuracy': 80.08, 'per_class_accuracy': [86.2245, 94.0969, 69.9612, 81.0891, 83.7067, 68.4978, 88.5177, 73.4436, 69.6099, 83.2507], 'loss': 0.6449981754302978}\n",
            "OCS >> Task 4: {'accuracy': 80.78, 'per_class_accuracy': [83.6735, 97.0925, 70.2519, 80.0, 84.7251, 73.2063, 91.9624, 65.9533, 74.9487, 84.1427], 'loss': 0.6236363986968995}\n",
            "OCS >> Task 5: {'accuracy': 78.12, 'per_class_accuracy': [81.8367, 95.4185, 62.4031, 76.4356, 84.3177, 70.4036, 91.1273, 57.7821, 76.386, 83.6472], 'loss': 0.710744845867157}\n",
            "OCS >> (average accuracy): 76.45\n",
            "OCS >> (Forgetting): 0.16827499999999998\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 6 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 44.96\n",
            "Epoch 0.2 >> (class accuracy): [98.0612, 87.4009, 10.1744, 88.7129, 12.0163, 0.0, 39.666, 39.0078, 8.1109, 55.8969]\n",
            "Epoch 0.4 >> (per-task accuracy): 54.0\n",
            "Epoch 0.4 >> (class accuracy): [80.5102, 90.7489, 5.3295, 83.5644, 86.3544, 12.8924, 88.5177, 48.4436, 5.7495, 31.4172]\n",
            "Epoch 0.6 >> (per-task accuracy): 62.4\n",
            "Epoch 0.6 >> (class accuracy): [75.4082, 93.0396, 17.5388, 79.802, 72.8106, 36.0987, 85.3862, 51.8482, 36.961, 70.3667]\n",
            "Epoch 0.8 >> (per-task accuracy): 67.69\n",
            "Epoch 0.8 >> (class accuracy): [75.6122, 93.7445, 34.8837, 77.5248, 78.9206, 42.713, 84.4468, 51.4591, 60.883, 72.7453]\n",
            "Epoch 1.0 >> (per-task accuracy): 70.91\n",
            "Epoch 1.0 >> (class accuracy): [76.4286, 95.2423, 46.5116, 74.8515, 80.2444, 45.5157, 84.7599, 56.1284, 68.0698, 77.2052]\n",
            "OCS >> Task 1: {'accuracy': 62.73, 'per_class_accuracy': [86.4286, 66.6079, 46.3178, 61.6832, 71.3849, 50.0, 79.6451, 72.3735, 22.1766, 69.2765], 'loss': 1.1752616173744201}\n",
            "OCS >> Task 2: {'accuracy': 69.85, 'per_class_accuracy': [88.3673, 83.9648, 54.845, 71.9802, 76.1711, 56.9507, 84.7599, 74.6109, 31.2115, 72.7453], 'loss': 0.9068694770812988}\n",
            "OCS >> Task 3: {'accuracy': 74.65, 'per_class_accuracy': [88.2653, 91.7181, 60.8527, 76.5347, 77.2912, 59.3049, 86.1169, 75.7782, 46.5092, 80.5748], 'loss': 0.7605804141998291}\n",
            "OCS >> Task 4: {'accuracy': 76.19, 'per_class_accuracy': [86.3265, 96.5639, 61.1434, 78.2178, 78.5132, 56.6143, 90.3967, 71.2062, 56.8789, 82.0614], 'loss': 0.7331995676040649}\n",
            "OCS >> Task 5: {'accuracy': 75.17, 'per_class_accuracy': [81.8367, 97.2687, 56.8798, 75.7426, 80.3462, 53.139, 88.6221, 66.9261, 63.5524, 83.2507], 'loss': 0.7689743043899536}\n",
            "OCS >> Task 6: {'accuracy': 70.91, 'per_class_accuracy': [76.4286, 95.2423, 46.5116, 74.8515, 80.2444, 45.5157, 84.7599, 56.1284, 68.0698, 77.2052], 'loss': 0.9294092450141906}\n",
            "OCS >> (average accuracy): 71.58333333333333\n",
            "OCS >> (Forgetting): 0.21142\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 7 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 22.82\n",
            "Epoch 0.2 >> (class accuracy): [99.4898, 8.6344, 3.2946, 0.297, 3.8697, 0.0, 44.572, 1.9455, 69.4045, 1.0902]\n",
            "Epoch 0.4 >> (per-task accuracy): 47.53\n",
            "Epoch 0.4 >> (class accuracy): [80.7143, 93.3921, 5.2326, 84.0594, 88.7984, 1.3453, 94.2589, 7.8794, 0.0, 12.9832]\n",
            "Epoch 0.6 >> (per-task accuracy): 58.29\n",
            "Epoch 0.6 >> (class accuracy): [77.9592, 90.5727, 16.9574, 87.4257, 84.7251, 18.6099, 87.4739, 50.4864, 26.5914, 36.1744]\n",
            "Epoch 0.8 >> (per-task accuracy): 63.53\n",
            "Epoch 0.8 >> (class accuracy): [69.7959, 85.022, 29.5543, 85.1485, 82.4847, 30.8296, 82.5678, 51.07, 57.7002, 57.0862]\n",
            "Epoch 1.0 >> (per-task accuracy): 67.2\n",
            "Epoch 1.0 >> (class accuracy): [70.3061, 84.7577, 45.6395, 83.2673, 86.0489, 38.6771, 81.2109, 52.9183, 66.2218, 59.4648]\n",
            "OCS >> Task 1: {'accuracy': 55.79, 'per_class_accuracy': [77.3469, 69.0749, 32.4612, 47.9208, 65.2749, 47.6457, 73.6952, 68.7743, 14.271, 59.4648], 'loss': 1.3208316578865051}\n",
            "OCS >> Task 2: {'accuracy': 63.33, 'per_class_accuracy': [82.1429, 86.6079, 37.5, 59.802, 71.4868, 55.2691, 78.81, 70.3307, 22.9979, 65.114], 'loss': 1.0682167238235474}\n",
            "OCS >> Task 3: {'accuracy': 68.57, 'per_class_accuracy': [84.0816, 94.5374, 40.6977, 65.8416, 73.0143, 55.157, 80.4802, 74.1245, 39.7331, 73.9346], 'loss': 0.9204263220787048}\n",
            "OCS >> Task 4: {'accuracy': 71.31, 'per_class_accuracy': [84.0816, 97.2687, 45.2519, 70.198, 77.0876, 55.0448, 84.3424, 72.7626, 48.46, 74.4301], 'loss': 0.8524748233795166}\n",
            "OCS >> Task 5: {'accuracy': 72.48, 'per_class_accuracy': [78.4694, 97.4449, 50.1938, 75.6436, 80.5499, 49.7758, 86.5344, 70.3307, 58.5216, 72.7453], 'loss': 0.8195426097869873}\n",
            "OCS >> Task 6: {'accuracy': 70.29, 'per_class_accuracy': [74.1837, 94.8018, 45.5426, 80.198, 86.0489, 43.4978, 84.6555, 62.5486, 68.5832, 58.5728], 'loss': 0.9029988922119141}\n",
            "OCS >> Task 7: {'accuracy': 67.2, 'per_class_accuracy': [70.3061, 84.7577, 45.6395, 83.2673, 86.0489, 38.6771, 81.2109, 52.9183, 66.2218, 59.4648], 'loss': 1.008483694934845}\n",
            "OCS >> (average accuracy): 66.99571428571429\n",
            "OCS >> (Forgetting): 0.2589833333333333\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 8 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 15.93\n",
            "Epoch 0.2 >> (class accuracy): [55.7143, 0.0, 0.0, 0.0, 2.9532, 0.0, 4.8017, 0.0, 99.7947, 0.0]\n",
            "Epoch 0.4 >> (per-task accuracy): 37.24\n",
            "Epoch 0.4 >> (class accuracy): [93.1633, 64.4053, 4.7481, 0.396, 95.112, 0.0, 50.5219, 0.0, 47.7413, 14.2716]\n",
            "Epoch 0.6 >> (per-task accuracy): 50.63\n",
            "Epoch 0.6 >> (class accuracy): [80.8163, 92.511, 9.6899, 60.6931, 76.4766, 26.7937, 71.8163, 0.7782, 38.2957, 44.4995]\n",
            "Epoch 0.8 >> (per-task accuracy): 56.75\n",
            "Epoch 0.8 >> (class accuracy): [77.8571, 89.163, 16.1822, 74.4554, 70.6721, 40.2466, 75.8873, 10.9922, 47.2279, 62.2398]\n",
            "Epoch 1.0 >> (per-task accuracy): 61.66\n",
            "Epoch 1.0 >> (class accuracy): [73.0612, 80.5286, 27.8101, 76.4356, 71.9959, 44.7309, 77.0355, 32.8794, 55.1335, 75.1239]\n",
            "OCS >> Task 1: {'accuracy': 53.29, 'per_class_accuracy': [70.102, 78.326, 31.5891, 49.703, 61.609, 35.426, 62.6305, 59.0467, 20.8419, 58.8702], 'loss': 1.4143730577468872}\n",
            "OCS >> Task 2: {'accuracy': 58.97, 'per_class_accuracy': [76.9388, 91.63, 34.8837, 57.4257, 63.9511, 38.3408, 69.833, 59.5331, 28.6448, 62.7354], 'loss': 1.2154743000030517}\n",
            "OCS >> Task 3: {'accuracy': 63.73, 'per_class_accuracy': [80.8163, 97.0925, 33.5271, 62.0792, 63.9511, 35.9865, 76.2004, 59.8249, 46.8172, 74.9257], 'loss': 1.0783010362625123}\n",
            "OCS >> Task 4: {'accuracy': 66.02, 'per_class_accuracy': [82.9592, 98.326, 33.1395, 64.2574, 63.0346, 37.8924, 84.238, 59.8249, 54.2094, 76.8087], 'loss': 1.026442446899414}\n",
            "OCS >> Task 5: {'accuracy': 67.92, 'per_class_accuracy': [83.2653, 98.7665, 34.4961, 69.3069, 67.4134, 39.7982, 85.2818, 56.0311, 62.423, 77.4034], 'loss': 0.9731562789916992}\n",
            "OCS >> Task 6: {'accuracy': 66.94, 'per_class_accuracy': [78.8776, 98.0617, 30.6202, 74.0594, 73.5234, 41.5919, 84.9687, 45.1362, 65.9138, 72.448], 'loss': 1.0036598300933839}\n",
            "OCS >> Task 7: {'accuracy': 65.85, 'per_class_accuracy': [75.102, 94.5374, 31.2984, 76.8317, 74.7454, 41.1435, 84.4468, 38.6187, 61.807, 76.115], 'loss': 1.03589769115448}\n",
            "OCS >> Task 8: {'accuracy': 61.66, 'per_class_accuracy': [73.0612, 80.5286, 27.8101, 76.4356, 71.9959, 44.7309, 77.0355, 32.8794, 55.1335, 75.1239], 'loss': 1.178233961391449}\n",
            "OCS >> (average accuracy): 63.0475\n",
            "OCS >> (Forgetting): 0.29614285714285715\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 9 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 9.67\n",
            "Epoch 0.2 >> (class accuracy): [0.9184, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.4 >> (per-task accuracy): 29.43\n",
            "Epoch 0.4 >> (class accuracy): [86.1224, 0.9692, 44.9612, 0.0, 13.5438, 2.4664, 45.929, 0.0, 5.9548, 96.2339]\n",
            "Epoch 0.6 >> (per-task accuracy): 49.61\n",
            "Epoch 0.6 >> (class accuracy): [79.3878, 84.4934, 46.5116, 29.0099, 41.8534, 25.7848, 78.0793, 0.0, 26.1807, 79.9802]\n",
            "Epoch 0.8 >> (per-task accuracy): 59.27\n",
            "Epoch 0.8 >> (class accuracy): [76.2245, 87.9295, 45.9302, 79.505, 64.7658, 49.7758, 74.6347, 7.6848, 31.7248, 71.556]\n",
            "Epoch 1.0 >> (per-task accuracy): 59.58\n",
            "Epoch 1.0 >> (class accuracy): [70.6122, 68.0176, 45.9302, 81.3861, 49.5927, 55.6054, 69.2067, 25.9728, 50.616, 78.4936]\n",
            "OCS >> Task 1: {'accuracy': 46.58, 'per_class_accuracy': [70.6122, 44.141, 32.0736, 32.9703, 52.8513, 40.4709, 51.8789, 56.7121, 20.4312, 63.6274], 'loss': 1.5905904001235962}\n",
            "OCS >> Task 2: {'accuracy': 51.24, 'per_class_accuracy': [75.5102, 59.2952, 35.6589, 41.5842, 61.0998, 44.2825, 54.9061, 55.2529, 19.3018, 64.0238], 'loss': 1.393372717857361}\n",
            "OCS >> Task 3: {'accuracy': 57.64, 'per_class_accuracy': [79.3878, 83.5242, 32.9457, 50.396, 64.8676, 40.4709, 62.8392, 53.2101, 32.2382, 72.1506], 'loss': 1.2184686946868897}\n",
            "OCS >> Task 4: {'accuracy': 61.83, 'per_class_accuracy': [81.4286, 91.4537, 33.9147, 56.2376, 68.2281, 37.6682, 75.6785, 57.0039, 40.2464, 71.3578], 'loss': 1.131211142539978}\n",
            "OCS >> Task 5: {'accuracy': 64.68, 'per_class_accuracy': [80.0, 98.6784, 38.0814, 67.5248, 67.3116, 35.426, 75.6785, 57.8794, 47.3306, 72.448], 'loss': 1.0554375402450562}\n",
            "OCS >> Task 6: {'accuracy': 65.6, 'per_class_accuracy': [78.4694, 98.8546, 36.0465, 75.6436, 65.1731, 37.5561, 78.9144, 51.5564, 58.2136, 69.8712], 'loss': 1.0365610610961915}\n",
            "OCS >> Task 7: {'accuracy': 66.94, 'per_class_accuracy': [76.5306, 96.5639, 45.8333, 78.9109, 64.9695, 40.1345, 78.4969, 45.3307, 61.191, 76.115], 'loss': 1.0013012902259826}\n",
            "OCS >> Task 8: {'accuracy': 65.11, 'per_class_accuracy': [74.2857, 88.1057, 46.0271, 79.4059, 58.8595, 49.1031, 75.6785, 37.5486, 59.4456, 79.2864], 'loss': 1.044224903869629}\n",
            "OCS >> Task 9: {'accuracy': 59.58, 'per_class_accuracy': [70.6122, 68.0176, 45.9302, 81.3861, 49.5927, 55.6054, 69.2067, 25.9728, 50.616, 78.4936], 'loss': 1.1525699828147888}\n",
            "OCS >> (average accuracy): 59.91111111111112\n",
            "OCS >> (Forgetting): 0.329075\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 10 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 16.64\n",
            "Epoch 0.2 >> (class accuracy): [21.5306, 0.0, 0.0, 0.0, 0.0, 0.0, 48.7474, 0.0, 0.0, 97.7205]\n",
            "Epoch 0.4 >> (per-task accuracy): 36.96\n",
            "Epoch 0.4 >> (class accuracy): [39.7959, 14.6256, 26.6473, 25.6436, 52.0367, 37.4439, 86.0125, 0.0, 3.3881, 89.5937]\n",
            "Epoch 0.6 >> (per-task accuracy): 46.49\n",
            "Epoch 0.6 >> (class accuracy): [63.9796, 30.9251, 4.6512, 63.8614, 34.4196, 41.8161, 90.6054, 0.8755, 45.6879, 93.6571]\n",
            "Epoch 0.8 >> (per-task accuracy): 44.82\n",
            "Epoch 0.8 >> (class accuracy): [68.4694, 14.185, 5.4264, 75.6436, 20.4684, 59.0807, 64.3006, 2.6265, 55.7495, 90.783]\n",
            "Epoch 1.0 >> (per-task accuracy): 48.36\n",
            "Epoch 1.0 >> (class accuracy): [65.102, 16.9163, 13.2752, 86.0396, 46.334, 56.6143, 63.4656, 22.8599, 37.6797, 82.2597]\n",
            "OCS >> Task 1: {'accuracy': 47.73, 'per_class_accuracy': [75.9184, 65.4626, 41.8605, 11.5842, 46.5377, 36.7713, 45.8246, 55.5447, 39.8357, 54.9058], 'loss': 1.578079814338684}\n",
            "OCS >> Task 2: {'accuracy': 52.01, 'per_class_accuracy': [78.1633, 81.5859, 34.6899, 15.5446, 53.5642, 43.722, 56.1587, 53.6965, 44.4559, 55.005], 'loss': 1.4075133600234986}\n",
            "OCS >> Task 3: {'accuracy': 57.49, 'per_class_accuracy': [78.8776, 94.7137, 25.0, 28.0198, 64.7658, 46.7489, 64.7182, 60.8949, 48.6653, 58.1764], 'loss': 1.2736283321380615}\n",
            "OCS >> Task 4: {'accuracy': 59.49, 'per_class_accuracy': [79.3878, 99.0308, 18.5078, 41.3861, 66.3951, 42.1525, 72.6514, 65.5642, 40.6571, 63.8256], 'loss': 1.2413648368835448}\n",
            "OCS >> Task 5: {'accuracy': 60.25, 'per_class_accuracy': [77.9592, 98.326, 16.1822, 54.0594, 66.5988, 38.4529, 74.0084, 64.6887, 38.7064, 67.7899], 'loss': 1.2312345998764038}\n",
            "OCS >> Task 6: {'accuracy': 60.1, 'per_class_accuracy': [74.1837, 95.5066, 12.2093, 69.1089, 63.5438, 35.2018, 75.8873, 58.463, 39.6304, 71.6551], 'loss': 1.2396148210525513}\n",
            "OCS >> Task 7: {'accuracy': 59.72, 'per_class_accuracy': [73.0612, 85.9031, 13.0814, 77.9208, 58.0448, 41.3677, 77.0355, 44.6498, 43.1211, 79.5837], 'loss': 1.21733251953125}\n",
            "OCS >> Task 8: {'accuracy': 57.35, 'per_class_accuracy': [68.8776, 64.4934, 18.314, 82.4752, 51.9348, 51.2332, 75.1566, 34.2412, 43.7372, 83.3499], 'loss': 1.2612742952346803}\n",
            "OCS >> Task 9: {'accuracy': 54.21, 'per_class_accuracy': [67.6531, 41.3216, 19.5736, 85.3465, 51.3238, 59.0807, 74.1127, 25.0973, 40.0411, 82.8543], 'loss': 1.359587250995636}\n",
            "OCS >> Task 10: {'accuracy': 48.36, 'per_class_accuracy': [65.102, 16.9163, 13.2752, 86.0396, 46.334, 56.6143, 63.4656, 22.8599, 37.6797, 82.2597], 'loss': 1.5822564254760743}\n",
            "OCS >> (average accuracy): 55.67099999999999\n",
            "OCS >> (Forgetting): 0.3637666666666666\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 11 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 12.42\n",
            "Epoch 0.2 >> (class accuracy): [98.7755, 0.0, 0.0, 0.099, 0.3055, 0.0, 0.0, 2.5292, 22.2793, 2.6759]\n",
            "Epoch 0.4 >> (per-task accuracy): 13.74\n",
            "Epoch 0.4 >> (class accuracy): [99.898, 0.0, 0.0, 0.0, 0.4073, 0.0, 13.1524, 0.0, 0.0, 26.2636]\n",
            "Epoch 0.6 >> (per-task accuracy): 28.1\n",
            "Epoch 0.6 >> (class accuracy): [96.9388, 0.0, 0.0, 0.0, 53.8697, 0.0, 63.5699, 0.0, 0.0, 71.556]\n",
            "Epoch 0.8 >> (per-task accuracy): 29.61\n",
            "Epoch 0.8 >> (class accuracy): [91.8367, 0.0, 0.1938, 1.2871, 87.3727, 0.1121, 69.6242, 0.0, 0.0, 51.5362]\n",
            "Epoch 1.0 >> (per-task accuracy): 34.17\n",
            "Epoch 1.0 >> (class accuracy): [85.5102, 2.0264, 11.4341, 31.9802, 91.6497, 14.0135, 70.1461, 0.0, 2.1561, 39.3459]\n",
            "OCS >> Task 1: {'accuracy': 18.68, 'per_class_accuracy': [87.449, 0.0, 0.1938, 11.7822, 65.6823, 0.0, 15.762, 0.0, 1.232, 8.1269], 'loss': 2.128213370132446}\n",
            "OCS >> Task 2: {'accuracy': 20.21, 'per_class_accuracy': [88.8776, 0.0, 0.0969, 15.0495, 74.4399, 0.2242, 18.7891, 0.0, 1.3347, 7.0367], 'loss': 2.110330793762207}\n",
            "OCS >> Task 3: {'accuracy': 22.14, 'per_class_accuracy': [91.1224, 0.0, 0.2907, 25.6436, 78.0041, 0.3363, 19.2067, 0.0, 2.8747, 7.7304], 'loss': 2.0799370738983156}\n",
            "OCS >> Task 4: {'accuracy': 23.62, 'per_class_accuracy': [92.9592, 0.0, 0.4845, 28.7129, 77.1894, 0.7848, 28.0793, 0.0, 1.6427, 10.5055], 'loss': 2.0569484867095946}\n",
            "OCS >> Task 5: {'accuracy': 24.78, 'per_class_accuracy': [93.1633, 0.0, 0.8721, 28.4158, 81.4664, 1.7937, 33.1942, 0.0, 1.7454, 11.6947], 'loss': 2.027525287055969}\n",
            "OCS >> Task 6: {'accuracy': 27.62, 'per_class_accuracy': [92.449, 0.2643, 2.4225, 36.1386, 87.6782, 5.4933, 44.572, 0.0, 2.2587, 10.3072], 'loss': 1.9963792472839355}\n",
            "OCS >> Task 7: {'accuracy': 30.71, 'per_class_accuracy': [91.6327, 1.0573, 5.5233, 40.6931, 90.7332, 9.1928, 58.8727, 0.0, 1.4374, 14.0733], 'loss': 1.9690498651504516}\n",
            "OCS >> Task 8: {'accuracy': 32.11, 'per_class_accuracy': [90.3061, 0.0, 8.624, 35.1485, 93.1772, 15.8072, 67.8497, 0.0, 2.4641, 15.0644], 'loss': 1.9404408111572267}\n",
            "OCS >> Task 9: {'accuracy': 35.39, 'per_class_accuracy': [89.1837, 2.3789, 11.2403, 39.901, 94.1955, 20.9641, 75.6785, 0.0, 1.848, 26.1645], 'loss': 1.9187395534515381}\n",
            "OCS >> Task 10: {'accuracy': 34.44, 'per_class_accuracy': [86.6327, 0.7048, 13.3721, 34.1584, 93.4827, 17.3767, 74.739, 0.0, 1.6427, 29.6333], 'loss': 1.923255099105835}\n",
            "OCS >> Task 11: {'accuracy': 34.17, 'per_class_accuracy': [85.5102, 2.0264, 11.4341, 31.9802, 91.6497, 14.0135, 70.1461, 0.0, 2.1561, 39.3459], 'loss': 1.942981619644165}\n",
            "OCS >> (average accuracy): 27.624545454545455\n",
            "OCS >> (Forgetting): 0.6589\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 12 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 11.79\n",
            "Epoch 0.2 >> (class accuracy): [96.6327, 0.0, 0.0969, 0.0, 0.1018, 0.0, 0.0, 0.5837, 16.9405, 5.8474]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 11.86\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.2234, 0.0, 0.0, 4.0634]\n",
            "Epoch 0.8 >> (per-task accuracy): 23.09\n",
            "Epoch 0.8 >> (class accuracy): [98.1633, 0.0, 0.0, 0.0, 2.444, 0.0, 56.4718, 0.0, 0.0, 77.5025]\n",
            "Epoch 1.0 >> (per-task accuracy): 30.46\n",
            "Epoch 1.0 >> (class accuracy): [93.9796, 16.5639, 1.4535, 1.3861, 27.4949, 0.0, 72.547, 0.0, 0.0, 93.4589]\n",
            "OCS >> Task 1: {'accuracy': 18.65, 'per_class_accuracy': [93.5714, 0.0, 0.0, 0.297, 1.7312, 0.0, 27.1399, 0.0, 0.0, 66.2042], 'loss': 2.189268459701538}\n",
            "OCS >> Task 2: {'accuracy': 19.62, 'per_class_accuracy': [94.3878, 0.0, 0.0, 0.396, 2.3422, 0.0, 28.1837, 0.0, 0.0, 73.3399], 'loss': 2.1809487903594973}\n",
            "OCS >> Task 3: {'accuracy': 20.75, 'per_class_accuracy': [96.4286, 0.0, 0.0, 0.7921, 6.9246, 0.0, 26.4092, 0.0, 0.0, 79.3855], 'loss': 2.17063570022583}\n",
            "OCS >> Task 4: {'accuracy': 22.14, 'per_class_accuracy': [97.6531, 0.0, 0.0, 0.8911, 4.3788, 0.0, 38.309, 0.0, 0.0, 83.0525], 'loss': 2.162018501281738}\n",
            "OCS >> Task 5: {'accuracy': 23.22, 'per_class_accuracy': [97.6531, 0.0, 0.0969, 0.297, 3.2587, 0.0, 46.6597, 0.0, 0.0, 87.4133], 'loss': 2.1489697132110597}\n",
            "OCS >> Task 6: {'accuracy': 24.89, 'per_class_accuracy': [97.8571, 0.7048, 0.1938, 1.3861, 2.7495, 0.0, 59.8121, 0.0, 0.0, 89.7919], 'loss': 2.13563656539917}\n",
            "OCS >> Task 7: {'accuracy': 25.71, 'per_class_accuracy': [97.551, 3.7885, 0.6783, 1.6832, 3.7678, 0.0, 63.7787, 0.0, 0.0, 89.1972], 'loss': 2.124775784301758}\n",
            "OCS >> Task 8: {'accuracy': 26.87, 'per_class_accuracy': [97.7551, 6.8722, 0.5814, 0.495, 4.6843, 0.0, 70.7724, 0.0, 0.0, 90.783], 'loss': 2.1073193183898926}\n",
            "OCS >> Task 9: {'accuracy': 28.76, 'per_class_accuracy': [97.551, 15.0661, 1.3566, 1.4851, 7.7393, 0.0, 74.0084, 0.0, 0.0, 92.666], 'loss': 2.0894819313049315}\n",
            "OCS >> Task 10: {'accuracy': 29.03, 'per_class_accuracy': [96.1224, 13.2159, 1.938, 0.7921, 12.7291, 0.0, 75.1566, 0.0, 0.0, 92.9633], 'loss': 2.082692115020752}\n",
            "OCS >> Task 11: {'accuracy': 31.02, 'per_class_accuracy': [95.6122, 19.9119, 2.6163, 1.7822, 23.9308, 0.0, 74.5303, 0.0, 0.0, 93.6571], 'loss': 2.077286766052246}\n",
            "OCS >> Task 12: {'accuracy': 30.46, 'per_class_accuracy': [93.9796, 16.5639, 1.4535, 1.3861, 27.4949, 0.0, 72.547, 0.0, 0.0, 93.4589], 'loss': 2.087648859024048}\n",
            "OCS >> (average accuracy): 25.09333333333333\n",
            "OCS >> (Forgetting): 0.6825454545454547\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 13 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 10.4\n",
            "Epoch 0.2 >> (class accuracy): [99.4898, 0.0, 0.0, 0.0, 0.3055, 0.0, 0.0, 0.0973, 5.1335, 1.0902]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 9.8\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 13.47\n",
            "Epoch 0.8 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 26.6802, 0.0, 0.0, 0.0, 0.0, 10.4063]\n",
            "Epoch 1.0 >> (per-task accuracy): 20.92\n",
            "Epoch 1.0 >> (class accuracy): [98.8776, 0.0, 0.6783, 0.0, 88.7984, 0.0, 6.785, 0.0, 0.0, 17.7403]\n",
            "OCS >> Task 1: {'accuracy': 16.34, 'per_class_accuracy': [98.1633, 0.0, 0.0969, 0.0, 64.664, 0.0, 0.0, 0.0, 0.0, 3.5679], 'loss': 2.242296824645996}\n",
            "OCS >> Task 2: {'accuracy': 16.67, 'per_class_accuracy': [98.4694, 0.0, 0.0969, 0.0, 70.0611, 0.0, 0.0, 0.0, 0.0, 1.2884], 'loss': 2.2387691619873045}\n",
            "OCS >> Task 3: {'accuracy': 17.08, 'per_class_accuracy': [98.9796, 0.0, 0.0, 0.0, 74.4399, 0.0, 0.0, 0.0, 0.0, 0.6938], 'loss': 2.231716012954712}\n",
            "OCS >> Task 4: {'accuracy': 16.9, 'per_class_accuracy': [99.2857, 0.0, 0.0, 0.0, 72.1996, 0.0, 0.0, 0.0, 0.0, 0.7929], 'loss': 2.2278476890563965}\n",
            "OCS >> Task 5: {'accuracy': 16.98, 'per_class_accuracy': [99.4898, 0.0, 0.0, 0.0, 71.5886, 0.0, 0.0, 0.0, 0.0, 1.9822], 'loss': 2.222469446563721}\n",
            "OCS >> Task 6: {'accuracy': 17.14, 'per_class_accuracy': [99.1837, 0.0, 0.0, 0.0, 72.8106, 0.0, 0.0, 0.0, 0.0, 2.6759], 'loss': 2.216515901565552}\n",
            "OCS >> Task 7: {'accuracy': 17.22, 'per_class_accuracy': [99.6939, 0.0, 0.1938, 0.0, 73.4216, 0.0, 0.3132, 0.0, 0.0, 1.8831], 'loss': 2.212533512878418}\n",
            "OCS >> Task 8: {'accuracy': 17.74, 'per_class_accuracy': [99.1837, 0.0, 0.1938, 0.0, 77.6986, 0.0, 1.7745, 0.0, 0.0, 1.9822], 'loss': 2.2032352729797364}\n",
            "OCS >> Task 9: {'accuracy': 18.56, 'per_class_accuracy': [99.2857, 0.0, 0.0969, 0.0, 83.1976, 0.0, 3.8622, 0.0, 0.0, 2.775], 'loss': 2.1925988090515136}\n",
            "OCS >> Task 10: {'accuracy': 19.74, 'per_class_accuracy': [98.9796, 0.0, 0.0969, 0.0, 88.7984, 0.0, 7.0981, 0.0, 0.0, 6.2438], 'loss': 2.1851078620910647}\n",
            "OCS >> Task 11: {'accuracy': 20.46, 'per_class_accuracy': [99.1837, 0.0, 0.3876, 0.0, 90.4277, 0.0, 9.1858, 0.0, 0.0, 9.3162], 'loss': 2.1779890209198}\n",
            "OCS >> Task 12: {'accuracy': 20.68, 'per_class_accuracy': [99.2857, 0.0, 0.5814, 0.0, 90.224, 0.0, 9.9165, 0.0, 0.0, 10.7037], 'loss': 2.180911971282959}\n",
            "OCS >> Task 13: {'accuracy': 20.92, 'per_class_accuracy': [98.8776, 0.0, 0.6783, 0.0, 88.7984, 0.0, 6.785, 0.0, 0.0, 17.7403], 'loss': 2.183188316726685}\n",
            "OCS >> (average accuracy): 18.186923076923076\n",
            "OCS >> (Forgetting): 0.7490083333333333\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 14 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 10.58\n",
            "Epoch 0.2 >> (class accuracy): [99.7959, 0.0, 0.0969, 0.0, 0.5092, 0.0, 0.0, 0.0, 2.9774, 4.4599]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 9.8\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 10.73\n",
            "Epoch 0.8 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.217]\n",
            "Epoch 1.0 >> (per-task accuracy): 16.66\n",
            "Epoch 1.0 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.1018, 0.0, 1.6701, 0.0, 0.0, 66.3033]\n",
            "OCS >> Task 1: {'accuracy': 11.77, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.5243], 'loss': 2.273686629486084}\n",
            "OCS >> Task 2: {'accuracy': 11.31, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 0.2037, 0.0, 0.0, 0.0, 0.0, 14.8662], 'loss': 2.2711376907348635}\n",
            "OCS >> Task 3: {'accuracy': 11.35, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.3617], 'loss': 2.267174659729004}\n",
            "OCS >> Task 4: {'accuracy': 11.61, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.9386], 'loss': 2.2644913639068602}\n",
            "OCS >> Task 5: {'accuracy': 12.17, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4886], 'loss': 2.26180643157959}\n",
            "OCS >> Task 6: {'accuracy': 12.12, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.9931], 'loss': 2.2591875793457032}\n",
            "OCS >> Task 7: {'accuracy': 12.58, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.552], 'loss': 2.2580627212524416}\n",
            "OCS >> Task 8: {'accuracy': 13.26, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.2914], 'loss': 2.254252256011963}\n",
            "OCS >> Task 9: {'accuracy': 14.08, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.4182], 'loss': 2.2492337562561033}\n",
            "OCS >> Task 10: {'accuracy': 15.26, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.113], 'loss': 2.2457359523773195}\n",
            "OCS >> Task 11: {'accuracy': 15.49, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1044, 0.0, 0.0, 56.2934], 'loss': 2.240511310195923}\n",
            "OCS >> Task 12: {'accuracy': 15.61, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4175, 0.0, 0.0, 57.1853], 'loss': 2.238844765853882}\n",
            "OCS >> Task 13: {'accuracy': 16.48, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4175, 0.0, 0.0, 65.8077], 'loss': 2.2377840118408203}\n",
            "OCS >> Task 14: {'accuracy': 16.66, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.1018, 0.0, 1.6701, 0.0, 0.0, 66.3033], 'loss': 2.2359878665924073}\n",
            "OCS >> (average accuracy): 13.553571428571429\n",
            "OCS >> (Forgetting): 0.7954538461538462\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 15 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 10.65\n",
            "Epoch 0.2 >> (class accuracy): [99.5918, 0.0, 0.0, 0.0, 1.5275, 0.0, 0.0, 0.0, 1.7454, 5.6492]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 9.88\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7929]\n",
            "Epoch 0.8 >> (per-task accuracy): 11.28\n",
            "Epoch 0.8 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.5092, 0.0, 0.0, 0.0, 0.0, 14.1724]\n",
            "Epoch 1.0 >> (per-task accuracy): 18.34\n",
            "Epoch 1.0 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 30.8554, 0.0, 0.0, 0.0, 0.0, 54.6085]\n",
            "OCS >> Task 1: {'accuracy': 11.08, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 11.3035, 0.0, 0.0, 0.0, 0.0, 1.6848], 'loss': 2.292097183227539}\n",
            "OCS >> Task 2: {'accuracy': 11.07, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 12.7291, 0.0, 0.0, 0.0, 0.0, 0.1982], 'loss': 2.2900215896606446}\n",
            "OCS >> Task 3: {'accuracy': 11.25, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 14.5621, 0.0, 0.0, 0.0, 0.0, 0.1982], 'loss': 2.287968768310547}\n",
            "OCS >> Task 4: {'accuracy': 11.0, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 11.3035, 0.0, 0.0, 0.0, 0.0, 0.9911], 'loss': 2.2859137828826905}\n",
            "OCS >> Task 5: {'accuracy': 11.13, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 11.0998, 0.0, 0.0, 0.0, 0.0, 2.4777], 'loss': 2.2835010005950926}\n",
            "OCS >> Task 6: {'accuracy': 11.32, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 10.7943, 0.0, 0.0, 0.0, 0.0, 4.559], 'loss': 2.281932301712036}\n",
            "OCS >> Task 7: {'accuracy': 11.29, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 12.5255, 0.0, 0.0, 0.0, 0.0, 2.5768], 'loss': 2.282773260498047}\n",
            "OCS >> Task 8: {'accuracy': 12.25, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 22.0978, 0.0, 0.0, 0.0, 0.0, 2.775], 'loss': 2.281178034591675}\n",
            "OCS >> Task 9: {'accuracy': 11.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 17.6171, 0.0, 0.0, 0.0, 0.0, 2.6759], 'loss': 2.279623736190796}\n",
            "OCS >> Task 10: {'accuracy': 12.54, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 19.5519, 0.0, 0.0, 0.0, 0.0, 8.1269], 'loss': 2.2786056804656982}\n",
            "OCS >> Task 11: {'accuracy': 12.77, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 15.0713, 0.0, 0.0, 0.0, 0.0, 14.7671], 'loss': 2.2765263236999513}\n",
            "OCS >> Task 12: {'accuracy': 13.25, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 9.2668, 0.0, 0.0, 0.0, 0.0, 25.1734], 'loss': 2.2742376247406004}\n",
            "OCS >> Task 13: {'accuracy': 15.16, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 17.9226, 0.0, 0.0, 0.0, 0.0, 35.6789], 'loss': 2.2701097316741943}\n",
            "OCS >> Task 14: {'accuracy': 17.16, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 26.0692, 0.0, 0.0, 0.0, 0.0, 47.5719], 'loss': 2.2663612636566164}\n",
            "OCS >> Task 15: {'accuracy': 18.34, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 30.8554, 0.0, 0.0, 0.0, 0.0, 54.6085], 'loss': 2.264809384918213}\n",
            "OCS >> (average accuracy): 12.760666666666667\n",
            "OCS >> (Forgetting): 0.8049785714285714\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 16 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 10.71\n",
            "Epoch 0.2 >> (class accuracy): [98.3673, 0.0, 0.0, 0.0, 1.222, 0.0, 0.0, 0.0, 5.3388, 4.2616]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 9.8\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 9.8\n",
            "Epoch 0.8 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 9.8\n",
            "Epoch 1.0 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.300709847640991}\n",
            "OCS >> Task 2: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2994200302124024}\n",
            "OCS >> Task 3: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.297780377197266}\n",
            "OCS >> Task 4: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2963339683532715}\n",
            "OCS >> Task 5: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2945241676330568}\n",
            "OCS >> Task 6: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2929044967651366}\n",
            "OCS >> Task 7: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.293585704803467}\n",
            "OCS >> Task 8: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.292512720108032}\n",
            "OCS >> Task 9: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.292641583251953}\n",
            "OCS >> Task 10: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.293125121688843}\n",
            "OCS >> Task 11: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.293274887466431}\n",
            "OCS >> Task 12: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2922776142120362}\n",
            "OCS >> Task 13: {'accuracy': 9.81, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.1018, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2896537940979003}\n",
            "OCS >> Task 14: {'accuracy': 9.81, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.1018, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2852318031311034}\n",
            "OCS >> Task 15: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2832523754119873}\n",
            "OCS >> Task 16: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2790310836791994}\n",
            "OCS >> (average accuracy): 9.80125\n",
            "OCS >> (Forgetting): 0.8305866666666664\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 17 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 10.46\n",
            "Epoch 0.2 >> (class accuracy): [97.6531, 0.0, 0.0, 0.0, 0.5092, 0.0, 0.0, 0.0973, 6.6735, 1.7839]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 9.8\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 9.8\n",
            "Epoch 0.8 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 9.8\n",
            "Epoch 1.0 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.309549301147461}\n",
            "OCS >> Task 2: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.308013391113281}\n",
            "OCS >> Task 3: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3063643680572508}\n",
            "OCS >> Task 4: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.30497917098999}\n",
            "OCS >> Task 5: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3036148330688477}\n",
            "OCS >> Task 6: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.302321931838989}\n",
            "OCS >> Task 7: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3028222076416016}\n",
            "OCS >> Task 8: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.302702276992798}\n",
            "OCS >> Task 9: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.303417806625366}\n",
            "OCS >> Task 10: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.305178651046753}\n",
            "OCS >> Task 11: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.307003931427002}\n",
            "OCS >> Task 12: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.307533320617676}\n",
            "OCS >> Task 13: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3060444961547852}\n",
            "OCS >> Task 14: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3021817264556885}\n",
            "OCS >> Task 15: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3001102478027344}\n",
            "OCS >> Task 16: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.29559623336792}\n",
            "OCS >> Task 17: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.295147177886963}\n",
            "OCS >> (average accuracy): 9.8\n",
            "OCS >> (Forgetting): 0.8306\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 18 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 10.79\n",
            "Epoch 0.2 >> (class accuracy): [94.898, 0.0, 0.0, 0.0, 0.611, 0.0, 0.0, 0.0, 13.5524, 1.0902]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 9.8\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 9.8\n",
            "Epoch 0.8 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 9.8\n",
            "Epoch 1.0 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.307737996292114}\n",
            "OCS >> Task 2: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.307206130218506}\n",
            "OCS >> Task 3: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.306131679916382}\n",
            "OCS >> Task 4: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.304951219177246}\n",
            "OCS >> Task 5: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.303455595779419}\n",
            "OCS >> Task 6: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3023182567596434}\n",
            "OCS >> Task 7: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.302493704223633}\n",
            "OCS >> Task 8: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3016651473999024}\n",
            "OCS >> Task 9: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3024520656585694}\n",
            "OCS >> Task 10: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3038241706848144}\n",
            "OCS >> Task 11: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.305396736526489}\n",
            "OCS >> Task 12: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3060862159729005}\n",
            "OCS >> Task 13: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3053213417053224}\n",
            "OCS >> Task 14: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3030721481323244}\n",
            "OCS >> Task 15: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.300773901748657}\n",
            "OCS >> Task 16: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2966421703338624}\n",
            "OCS >> Task 17: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2960642597198486}\n",
            "OCS >> Task 18: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.292079224395752}\n",
            "OCS >> (average accuracy): 9.800000000000002\n",
            "OCS >> (Forgetting): 0.8306\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 19 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 10.1\n",
            "Epoch 0.2 >> (class accuracy): [91.3265, 0.0, 0.0, 0.0, 0.3055, 0.0, 0.0, 0.0, 11.191, 0.2973]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 9.8\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 9.8\n",
            "Epoch 0.8 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 9.8\n",
            "Epoch 1.0 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3072700355529787}\n",
            "OCS >> Task 2: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3073068355560302}\n",
            "OCS >> Task 3: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3063636104583742}\n",
            "OCS >> Task 4: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3053311180114746}\n",
            "OCS >> Task 5: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3039634796142576}\n",
            "OCS >> Task 6: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.30288031539917}\n",
            "OCS >> Task 7: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3028285209655763}\n",
            "OCS >> Task 8: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3021698482513426}\n",
            "OCS >> Task 9: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3026622455596923}\n",
            "OCS >> Task 10: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.303792993927002}\n",
            "OCS >> Task 11: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3051498107910158}\n",
            "OCS >> Task 12: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.305689952468872}\n",
            "OCS >> Task 13: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3051336055755614}\n",
            "OCS >> Task 14: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3035740074157713}\n",
            "OCS >> Task 15: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3018515647888185}\n",
            "OCS >> Task 16: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.29807784538269}\n",
            "OCS >> Task 17: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2976634620666503}\n",
            "OCS >> Task 18: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2943208866119384}\n",
            "OCS >> Task 19: {'accuracy': 9.8, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2969515827178957}\n",
            "OCS >> (average accuracy): 9.800000000000002\n",
            "OCS >> (Forgetting): 0.8306\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "---- Task 20 (OCS) ----\n",
            "Epoch 0.2 >> (per-task accuracy): 9.41\n",
            "Epoch 0.2 >> (class accuracy): [80.102, 0.0, 0.0969, 0.0, 0.5092, 0.0, 0.0, 0.0973, 15.2977, 0.0]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.7\n",
            "Epoch 0.4 >> (class accuracy): [90.7143, 0.0, 0.0, 0.0, 0.4073, 0.0, 0.0, 0.0, 7.9055, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 10.05\n",
            "Epoch 0.6 >> (class accuracy): [98.8776, 0.0, 0.0, 0.0, 0.611, 0.0, 0.0, 0.0, 3.0801, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 9.92\n",
            "Epoch 0.8 >> (class accuracy): [99.898, 0.0, 0.0, 0.0, 0.7128, 0.0, 0.0, 0.0, 0.616, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 9.99\n",
            "Epoch 1.0 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 1.4257, 0.0, 0.3132, 0.0, 0.2053, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 9.9, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.7128, 0.0, 0.0, 0.0, 0.308, 0.0], 'loss': 2.3045639923095704}\n",
            "OCS >> Task 2: {'accuracy': 9.94, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 0.8147, 0.0, 0.0, 0.0, 0.7187, 0.0], 'loss': 2.3051012794494627}\n",
            "OCS >> Task 3: {'accuracy': 10.03, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.9165, 0.0, 0.0, 0.0, 1.4374, 0.0], 'loss': 2.3042284717559816}\n",
            "OCS >> Task 4: {'accuracy': 9.91, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.0, 0.2037, 0.0, 0.0, 0.0, 1.1294, 0.0], 'loss': 2.303425043487549}\n",
            "OCS >> Task 5: {'accuracy': 9.92, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.4073, 0.0, 0.0, 0.0, 0.8214, 0.0], 'loss': 2.301966077041626}\n",
            "OCS >> Task 6: {'accuracy': 9.89, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 0.611, 0.0, 0.0, 0.0, 0.4107, 0.0], 'loss': 2.300853396987915}\n",
            "OCS >> Task 7: {'accuracy': 9.85, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.3055, 0.0, 0.0, 0.0, 0.2053, 0.0], 'loss': 2.300946032714844}\n",
            "OCS >> Task 8: {'accuracy': 9.94, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.0, 1.3238, 0.0, 0.0, 0.0, 0.308, 0.0], 'loss': 2.300649701309204}\n",
            "OCS >> Task 9: {'accuracy': 9.91, 'per_class_accuracy': [99.7959, 0.0, 0.0, 0.0, 1.1202, 0.0, 0.0, 0.0, 0.2053, 0.0], 'loss': 2.300787260055542}\n",
            "OCS >> Task 10: {'accuracy': 9.84, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 0.3055, 0.0, 0.0, 0.0, 0.2053, 0.0], 'loss': 2.3012604301452635}\n",
            "OCS >> Task 11: {'accuracy': 9.87, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.1018, 0.0, 0.0, 0.0, 0.616, 0.0], 'loss': 2.302347180175781}\n",
            "OCS >> Task 12: {'accuracy': 9.82, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.1018, 0.0, 0.0, 0.0, 0.1027, 0.0], 'loss': 2.3026184177398683}\n",
            "OCS >> Task 13: {'accuracy': 9.82, 'per_class_accuracy': [99.898, 0.0, 0.0, 0.0, 0.2037, 0.0, 0.0, 0.0, 0.1027, 0.0], 'loss': 2.3020056079864504}\n",
            "OCS >> Task 14: {'accuracy': 9.83, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.3055, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.3009226779937744}\n",
            "OCS >> Task 15: {'accuracy': 9.88, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.8147, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.299119786071777}\n",
            "OCS >> Task 16: {'accuracy': 9.94, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 1.4257, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.295804606246948}\n",
            "OCS >> Task 17: {'accuracy': 9.82, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.2037, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': 2.2956949813842775}\n",
            "OCS >> Task 18: {'accuracy': 10.0, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 1.5275, 0.0, 0.1044, 0.0, 0.4107, 0.0], 'loss': 2.292920600128174}\n",
            "OCS >> Task 19: {'accuracy': 9.85, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 0.4073, 0.0, 0.1044, 0.0, 0.0, 0.0], 'loss': 2.295213398361206}\n",
            "OCS >> Task 20: {'accuracy': 9.99, 'per_class_accuracy': [100.0, 0.0, 0.0, 0.0, 1.4257, 0.0, 0.3132, 0.0, 0.2053, 0.0], 'loss': 2.2956337551116945}\n",
            "OCS >> (average accuracy): 9.897499999999999\n",
            "OCS >> (Forgetting): 0.8296736842105265\n",
            "Maximum per-task accuracies: [92.86]\n",
            "\n",
            "{'num_tasks': 20, 'per_task_rotation': 9, 'memory_size': 200, 'dataset': 'noisy-rot-mnist', 'device': 'cuda', 'momentum': 0.8, 'mlp_hiddens': 256, 'dropout': 0.2, 'lr_decay': 0.75, 'n_classes': 10, 'seq_lr': 0.005, 'stream_size': 100, 'ocspick': True, 'batch_size': 20, 'tau': 1000.0, 'ref_hyp': 10.0, 'n_substeps': 5}\n"
          ]
        }
      ],
      "source": [
        "DATASET = 'noisy-rot-mnist'\n",
        "HIDDENS = 256\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = {\n",
        "    'num_tasks': 20,\n",
        "    'per_task_rotation': 9,\n",
        "    'memory_size': 200,\n",
        "    'dataset': DATASET,\n",
        "    'device': DEVICE,\n",
        "    'momentum': 0.8,\n",
        "    'mlp_hiddens': HIDDENS,\n",
        "    'dropout': 0.2,\n",
        "    'lr_decay': 0.75 if 'rot-mnist' in DATASET else 0.8,\n",
        "    'n_classes': 10,\n",
        "    'seq_lr': 0.005,\n",
        "    'stream_size': 100,\n",
        "    'ocspick': True,\n",
        "    'batch_size': 20,\n",
        "     'tau': 1000.0,\n",
        "    'ref_hyp': 10. if 'rot-mnist' in DATASET else 50\n",
        "}\n",
        "\n",
        "log_dir =  f\"./summery/{config['dataset']}\"\n",
        "summary = SummaryWriter(log_dir)\n",
        "\n",
        "experiment = Experiment(api_key=\"hidden_key\", project_name=\"mnist\", disabled=True)\n",
        "\n",
        "loaders = get_all_loaders(config)\n",
        "\n",
        "\n",
        "def evaluate_model(model, task, loaders, config):\n",
        "    accuracies, losses = [], []\n",
        "    for t in range(1, task + 1):\n",
        "        metrics = eval_single_epoch(model, loaders['sequential'][t]['val'], config)\n",
        "        accuracies.append(metrics['accuracy'])\n",
        "        losses.append(metrics['loss'])\n",
        "        print(f'OCS >> Task {t}: {metrics}')\n",
        "    return accuracies, losses\n",
        "\n",
        "def main():\n",
        "    setup_experiment(experiment, config)\n",
        "\n",
        "    max_accuracies = [0.0] * config['num_tasks']\n",
        "    for task in range(1, config['num_tasks'] + 1):\n",
        "        print(f'---- Task {task} (OCS) ----')\n",
        "        model = train_task_sequentially(task, loaders, config, summary)\n",
        "\n",
        "        accuracies, _ = evaluate_model(model, task, loaders, config)\n",
        "        max_accuracies = [max(acc, max_acc) for acc, max_acc in zip(accuracies, max_accuracies)]\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies)\n",
        "        if task > 1:\n",
        "            forgetting = np.mean(np.array(max_accuracies[:task - 1]) - np.array(accuracies[:task - 1]))/ 100\n",
        "        else:\n",
        "            forgetting = 0.0\n",
        "\n",
        "        print(f\"OCS >> (average accuracy): {avg_accuracy}\")\n",
        "        print(f\"OCS >> (Forgetting): {forgetting}\")\n",
        "        summary.add_scalar('cl_average_accuracy', avg_accuracy, task - 1)\n",
        "        print(f'Maximum per-task accuracies: {max_accuracies}\\n')\n",
        "\n",
        "    print(config)\n",
        "    experiment.end()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "-THHjeIU1VHl",
        "outputId": "13e0f12f-1ca6-45f1-b64e-56f17dbb4b0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "loading coreset placeholder noisy-rot-mnist\n",
            "loading noisy-rot-mnist for task 1\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 2\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 3\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 4\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 5\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 6\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 7\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 8\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 9\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 10\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 11\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 12\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 13\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 14\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 15\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 16\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 17\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 18\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 19\n",
            "Noisy Rotated MNIST\n",
            "loading noisy-rot-mnist for task 20\n",
            "Noisy Rotated MNIST\n",
            "---- Task 1 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 49.34\n",
            "Epoch 0.05 >> (class accuracy): [97.551, 82.2907, 77.8101, 90.396, 0.1018, 13.565, 9.499, 94.2607, 2.0534, 12.4876]\n",
            "Epoch 0.1 >> (per-task accuracy): 84.17\n",
            "Epoch 0.1 >> (class accuracy): [93.9796, 98.2379, 70.4457, 86.9307, 95.6212, 56.0538, 89.2484, 89.786, 87.885, 69.6729]\n",
            "Epoch 0.15 >> (per-task accuracy): 89.78\n",
            "Epoch 0.15 >> (class accuracy): [97.3469, 98.6784, 81.9767, 87.6238, 95.0102, 81.5022, 96.4509, 86.8677, 85.4209, 85.6293]\n",
            "Epoch 0.2 >> (per-task accuracy): 91.52\n",
            "Epoch 0.2 >> (class accuracy): [97.6531, 98.5022, 87.1124, 84.0594, 95.8248, 89.7982, 96.3466, 93.677, 85.3183, 86.224]\n",
            "Epoch 0.25 >> (per-task accuracy): 92.13\n",
            "Epoch 0.25 >> (class accuracy): [98.6735, 98.6784, 91.0853, 85.3465, 96.6395, 94.1704, 95.8246, 94.5525, 83.5729, 82.3588]\n",
            "Epoch 0.3 >> (per-task accuracy): 93.78\n",
            "Epoch 0.3 >> (class accuracy): [97.6531, 98.6784, 92.5388, 89.901, 96.0285, 95.6278, 96.0334, 92.8016, 91.0678, 87.3142]\n",
            "Epoch 0.35 >> (per-task accuracy): 94.24\n",
            "Epoch 0.35 >> (class accuracy): [98.1633, 98.9427, 93.6047, 90.297, 96.7413, 97.3094, 96.1378, 95.8171, 89.6304, 85.6293]\n",
            "Epoch 0.4 >> (per-task accuracy): 95.09\n",
            "Epoch 0.4 >> (class accuracy): [98.9796, 99.1189, 93.7016, 92.3762, 97.4542, 94.843, 96.2422, 93.1907, 95.0719, 89.6928]\n",
            "Epoch 0.45 >> (per-task accuracy): 95.34\n",
            "Epoch 0.45 >> (class accuracy): [98.1633, 99.0308, 92.7326, 94.9505, 96.8432, 97.6457, 97.0772, 95.428, 90.3491, 91.0803]\n",
            "Epoch 0.5 >> (per-task accuracy): 94.23\n",
            "Epoch 0.5 >> (class accuracy): [99.2857, 98.4141, 92.345, 83.5644, 95.8248, 97.5336, 95.8246, 96.4981, 90.8624, 92.1705]\n",
            "Epoch 0.55 >> (per-task accuracy): 95.35\n",
            "Epoch 0.55 >> (class accuracy): [98.6735, 99.0308, 92.8295, 89.802, 94.0937, 98.4305, 96.3466, 96.1089, 94.0452, 94.1526]\n",
            "Epoch 0.6 >> (per-task accuracy): 95.91\n",
            "Epoch 0.6 >> (class accuracy): [98.6735, 98.9427, 93.6047, 93.9604, 95.2138, 97.6457, 97.286, 95.9144, 92.2998, 95.441]\n",
            "Epoch 0.65 >> (per-task accuracy): 95.21\n",
            "Epoch 0.65 >> (class accuracy): [97.1429, 99.1189, 92.6357, 86.0396, 95.8248, 97.9821, 98.5386, 96.3035, 93.8398, 94.7473]\n",
            "Epoch 0.7 >> (per-task accuracy): 96.13\n",
            "Epoch 0.7 >> (class accuracy): [98.2653, 98.9427, 95.9302, 94.1584, 91.2424, 96.7489, 98.3299, 96.8872, 94.6612, 95.8375]\n",
            "Epoch 0.75 >> (per-task accuracy): 96.11\n",
            "Epoch 0.75 >> (class accuracy): [98.2653, 99.0308, 95.8333, 96.4356, 94.501, 97.3094, 98.3299, 95.7198, 90.9651, 94.45]\n",
            "Epoch 0.8 >> (per-task accuracy): 96.13\n",
            "Epoch 0.8 >> (class accuracy): [97.9592, 98.7665, 93.0233, 94.5545, 92.8717, 97.3094, 98.3299, 96.8872, 95.9959, 95.5401]\n",
            "Epoch 0.85 >> (per-task accuracy): 96.41\n",
            "Epoch 0.85 >> (class accuracy): [98.5714, 98.8546, 94.5736, 95.0495, 95.8248, 98.7668, 97.3904, 97.3735, 93.4292, 94.2517]\n",
            "Epoch 0.9 >> (per-task accuracy): 96.67\n",
            "Epoch 0.9 >> (class accuracy): [98.7755, 98.8546, 95.9302, 95.7426, 96.5377, 97.3094, 97.9123, 96.3035, 94.7639, 94.45]\n",
            "Epoch 0.95 >> (per-task accuracy): 95.95\n",
            "Epoch 0.95 >> (class accuracy): [98.8776, 98.6784, 94.7674, 91.0891, 94.501, 98.4305, 97.3904, 95.8171, 94.1478, 95.8375]\n",
            "Epoch 1.0 >> (per-task accuracy): 96.91\n",
            "Epoch 1.0 >> (class accuracy): [98.9796, 99.1189, 95.5426, 96.1386, 97.2505, 97.4215, 98.1211, 97.3735, 95.4825, 93.558]\n",
            "OCS >> Task 1: {'accuracy': 96.91, 'per_class_accuracy': [98.9796, 99.1189, 95.5426, 96.1386, 97.2505, 97.4215, 98.1211, 97.3735, 95.4825, 93.558], 'loss': 0.1289217499345541}\n",
            "OCS >> (average accuracy): 96.91\n",
            "OCS >> (Forgetting): 0.0\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 2 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 66.97\n",
            "Epoch 0.05 >> (class accuracy): [73.7755, 92.5991, 84.593, 51.6832, 53.055, 31.8386, 48.3299, 88.8132, 69.3018, 66.6006]\n",
            "Epoch 0.1 >> (per-task accuracy): 84.05\n",
            "Epoch 0.1 >> (class accuracy): [86.5306, 94.0088, 89.3411, 87.8218, 67.4134, 71.6368, 87.4739, 79.9611, 85.6263, 87.8097]\n",
            "Epoch 0.15 >> (per-task accuracy): 86.15\n",
            "Epoch 0.15 >> (class accuracy): [92.2449, 94.7137, 89.438, 92.2772, 69.7556, 73.6547, 90.1879, 83.1712, 84.8049, 88.6026]\n",
            "Epoch 0.2 >> (per-task accuracy): 88.04\n",
            "Epoch 0.2 >> (class accuracy): [90.9184, 95.859, 89.5349, 91.6832, 75.7637, 84.5291, 92.6931, 84.4358, 83.6756, 89.7919]\n",
            "Epoch 0.25 >> (per-task accuracy): 86.58\n",
            "Epoch 0.25 >> (class accuracy): [94.1837, 93.6564, 90.6008, 93.0693, 72.0978, 72.7578, 91.858, 77.2374, 87.3717, 90.6838]\n",
            "Epoch 0.3 >> (per-task accuracy): 88.11\n",
            "Epoch 0.3 >> (class accuracy): [93.6735, 96.2996, 91.1822, 93.7624, 74.9491, 77.5785, 91.023, 82.393, 87.7823, 90.1883]\n",
            "Epoch 0.35 >> (per-task accuracy): 87.48\n",
            "Epoch 0.35 >> (class accuracy): [93.3673, 96.2115, 92.1512, 92.7723, 73.3198, 73.5426, 90.9186, 81.0311, 88.501, 90.2874]\n",
            "Epoch 0.4 >> (per-task accuracy): 88.61\n",
            "Epoch 0.4 >> (class accuracy): [95.4082, 94.978, 92.0543, 93.8614, 73.8289, 80.8296, 90.3967, 84.6304, 86.1396, 92.0714]\n",
            "Epoch 0.45 >> (per-task accuracy): 88.92\n",
            "Epoch 0.45 >> (class accuracy): [93.5714, 95.3304, 92.6357, 92.7723, 73.1161, 82.7354, 92.1712, 82.0039, 89.8357, 93.4589]\n",
            "Epoch 0.5 >> (per-task accuracy): 89.06\n",
            "Epoch 0.5 >> (class accuracy): [93.1633, 96.0352, 93.0233, 93.4653, 76.2729, 82.0628, 92.7975, 79.3774, 90.4517, 92.3687]\n",
            "Epoch 0.55 >> (per-task accuracy): 89.26\n",
            "Epoch 0.55 >> (class accuracy): [92.0408, 95.859, 92.1512, 93.7624, 78.4114, 80.3812, 93.5282, 82.0039, 91.1704, 91.5758]\n",
            "Epoch 0.6 >> (per-task accuracy): 89.97\n",
            "Epoch 0.6 >> (class accuracy): [93.1633, 95.4185, 91.9574, 94.3564, 81.2627, 82.287, 93.8413, 82.5875, 91.2731, 92.1705]\n",
            "Epoch 0.65 >> (per-task accuracy): 90.01\n",
            "Epoch 0.65 >> (class accuracy): [95.5102, 97.0925, 92.7326, 93.9604, 79.7352, 81.7265, 91.6493, 81.6148, 91.4784, 92.8642]\n",
            "Epoch 0.7 >> (per-task accuracy): 89.99\n",
            "Epoch 0.7 >> (class accuracy): [96.2245, 97.8855, 92.5388, 93.0693, 78.0041, 82.3991, 92.2756, 80.2529, 91.7864, 93.7562]\n",
            "Epoch 0.75 >> (per-task accuracy): 90.61\n",
            "Epoch 0.75 >> (class accuracy): [95.7143, 97.3568, 93.2171, 94.8515, 78.5132, 81.7265, 94.0501, 84.144, 91.2731, 93.4589]\n",
            "Epoch 0.8 >> (per-task accuracy): 90.2\n",
            "Epoch 0.8 >> (class accuracy): [95.102, 97.7093, 92.7326, 94.7525, 76.4766, 80.7175, 93.737, 84.0467, 91.2731, 93.4589]\n",
            "Epoch 0.85 >> (per-task accuracy): 90.44\n",
            "Epoch 0.85 >> (class accuracy): [93.8776, 97.7093, 94.5736, 92.0792, 76.6802, 85.5381, 93.5282, 84.2412, 91.4784, 93.1615]\n",
            "Epoch 0.9 >> (per-task accuracy): 90.53\n",
            "Epoch 0.9 >> (class accuracy): [96.0204, 96.8282, 93.7984, 95.3465, 79.0224, 78.2511, 92.38, 87.8405, 90.5544, 92.9633]\n",
            "Epoch 0.95 >> (per-task accuracy): 90.65\n",
            "Epoch 0.95 >> (class accuracy): [95.6122, 97.1806, 94.8643, 95.0495, 77.6986, 80.7175, 93.1106, 87.3541, 90.4517, 92.3687]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_19281/1459498902.py:12: RuntimeWarning: divide by zero encountered in scalar floor_divide\n",
            "  if (num_residuals // num_class) > 0:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1.0 >> (per-task accuracy): 90.35\n",
            "Epoch 1.0 >> (class accuracy): [95.7143, 96.4758, 94.5736, 95.1485, 77.0876, 78.8117, 93.3194, 86.5759, 90.7598, 92.8642]\n",
            "OCS >> Task 1: {'accuracy': 86.83, 'per_class_accuracy': [94.0816, 90.7489, 93.5078, 92.3762, 69.5519, 70.1794, 90.501, 86.8677, 87.6797, 90.1883], 'loss': 0.5348783303260803}\n",
            "OCS >> Task 2: {'accuracy': 90.35, 'per_class_accuracy': [95.7143, 96.4758, 94.5736, 95.1485, 77.0876, 78.8117, 93.3194, 86.5759, 90.7598, 92.8642], 'loss': 0.39027177742123603}\n",
            "OCS >> (average accuracy): 88.59\n",
            "OCS >> (Forgetting): 0.10079999999999999\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 3 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 74.82\n",
            "Epoch 0.05 >> (class accuracy): [96.0204, 92.8634, 76.938, 78.7129, 52.0367, 56.3901, 85.3862, 69.9416, 46.8172, 88.3053]\n",
            "Epoch 0.1 >> (per-task accuracy): 79.72\n",
            "Epoch 0.1 >> (class accuracy): [96.4286, 89.4273, 78.3915, 80.495, 55.499, 77.5785, 82.881, 60.8949, 79.9795, 94.5491]\n",
            "Epoch 0.15 >> (per-task accuracy): 82.81\n",
            "Epoch 0.15 >> (class accuracy): [95.5102, 92.7753, 79.3605, 88.0198, 63.5438, 77.9148, 89.7704, 62.2568, 82.7515, 95.0446]\n",
            "Epoch 0.2 >> (per-task accuracy): 81.99\n",
            "Epoch 0.2 >> (class accuracy): [95.3061, 96.5639, 78.1008, 88.8119, 57.0265, 78.0269, 89.3528, 62.1595, 77.4127, 95.2428]\n",
            "Epoch 0.25 >> (per-task accuracy): 83.53\n",
            "Epoch 0.25 >> (class accuracy): [95.3061, 95.5947, 80.6202, 87.8218, 65.6823, 78.6996, 91.1273, 60.1167, 83.7782, 95.2428]\n",
            "Epoch 0.3 >> (per-task accuracy): 84.35\n",
            "Epoch 0.3 >> (class accuracy): [95.4082, 96.3877, 81.3953, 85.9406, 65.7841, 81.3901, 91.4405, 62.3541, 86.1396, 96.1348]\n",
            "Epoch 0.35 >> (per-task accuracy): 84.36\n",
            "Epoch 0.35 >> (class accuracy): [95.5102, 97.1806, 80.3295, 88.1188, 65.8859, 80.7175, 90.8142, 63.5214, 83.9836, 96.1348]\n",
            "Epoch 0.4 >> (per-task accuracy): 84.98\n",
            "Epoch 0.4 >> (class accuracy): [95.7143, 97.6211, 81.686, 88.1188, 66.5988, 81.278, 90.1879, 65.856, 86.037, 95.2428]\n",
            "Epoch 0.45 >> (per-task accuracy): 85.21\n",
            "Epoch 0.45 >> (class accuracy): [95.3061, 97.533, 83.4302, 89.4059, 67.2098, 81.278, 91.6493, 63.9105, 85.729, 95.2428]\n",
            "Epoch 0.5 >> (per-task accuracy): 84.98\n",
            "Epoch 0.5 >> (class accuracy): [95.7143, 96.9163, 82.655, 88.5149, 68.1263, 82.5112, 90.3967, 63.8132, 85.0103, 94.9455]\n",
            "Epoch 0.55 >> (per-task accuracy): 84.8\n",
            "Epoch 0.55 >> (class accuracy): [95.2041, 97.9736, 83.7209, 86.2376, 63.8493, 82.9596, 92.7975, 62.3541, 85.729, 95.9366]\n",
            "Epoch 0.6 >> (per-task accuracy): 85.24\n",
            "Epoch 0.6 >> (class accuracy): [95.7143, 97.7093, 83.624, 85.5446, 66.9043, 82.9596, 91.6493, 66.2451, 85.5236, 95.2428]\n",
            "Epoch 0.65 >> (per-task accuracy): 84.5\n",
            "Epoch 0.65 >> (class accuracy): [95.6122, 97.4449, 83.2364, 87.0297, 62.9328, 82.1749, 89.5616, 64.2023, 84.9076, 96.4321]\n",
            "Epoch 0.7 >> (per-task accuracy): 84.9\n",
            "Epoch 0.7 >> (class accuracy): [95.6122, 97.7093, 84.4961, 86.5347, 64.1548, 83.5202, 91.7537, 64.6887, 84.0862, 95.1437]\n",
            "Epoch 0.75 >> (per-task accuracy): 84.8\n",
            "Epoch 0.75 >> (class accuracy): [93.9796, 97.7093, 83.1395, 88.9109, 63.442, 82.3991, 91.858, 65.0778, 84.3943, 95.6392]\n",
            "Epoch 0.8 >> (per-task accuracy): 84.79\n",
            "Epoch 0.8 >> (class accuracy): [93.9796, 97.6211, 83.1395, 87.8218, 64.3585, 82.8475, 91.5449, 65.2724, 83.9836, 95.9366]\n",
            "Epoch 0.85 >> (per-task accuracy): 84.67\n",
            "Epoch 0.85 >> (class accuracy): [93.9796, 97.3568, 81.2984, 87.0297, 64.2566, 85.9865, 91.4405, 65.7588, 82.9569, 95.6392]\n",
            "Epoch 0.9 >> (per-task accuracy): 84.6\n",
            "Epoch 0.9 >> (class accuracy): [94.7959, 97.4449, 81.2016, 87.9208, 61.9145, 83.8565, 90.6054, 65.1751, 85.1129, 96.7294]\n",
            "Epoch 0.95 >> (per-task accuracy): 85.91\n",
            "Epoch 0.95 >> (class accuracy): [93.8776, 96.8282, 83.0426, 91.0891, 68.1263, 79.7085, 91.023, 70.3307, 87.6797, 95.7384]\n",
            "Epoch 1.0 >> (per-task accuracy): 85.34\n",
            "Epoch 1.0 >> (class accuracy): [93.7755, 97.3568, 81.8798, 88.7129, 64.3585, 81.8386, 90.8142, 68.0934, 89.3224, 95.8375]\n",
            "OCS >> Task 1: {'accuracy': 79.11, 'per_class_accuracy': [86.6327, 82.7313, 74.4186, 79.2079, 61.4053, 65.6951, 86.4301, 80.7393, 80.3901, 91.6749], 'loss': 0.9192611078262329}\n",
            "OCS >> Task 2: {'accuracy': 85.09, 'per_class_accuracy': [91.4286, 93.8326, 82.655, 88.1188, 67.9226, 75.1121, 89.9791, 80.2529, 85.8316, 93.6571], 'loss': 0.6287704905986786}\n",
            "OCS >> Task 3: {'accuracy': 85.34, 'per_class_accuracy': [93.7755, 97.3568, 81.8798, 88.7129, 64.3585, 81.8386, 90.8142, 68.0934, 89.3224, 95.8375], 'loss': 0.596571250551939}\n",
            "OCS >> (average accuracy): 83.17999999999999\n",
            "OCS >> (Forgetting): 0.14809999999999995\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 4 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 73.66\n",
            "Epoch 0.05 >> (class accuracy): [86.6327, 98.1498, 67.1512, 67.3267, 68.3299, 77.2422, 87.4739, 55.7393, 50.1027, 76.4123]\n",
            "Epoch 0.1 >> (per-task accuracy): 77.96\n",
            "Epoch 0.1 >> (class accuracy): [87.3469, 96.4758, 68.5078, 80.7921, 56.9246, 81.6143, 81.2109, 61.7704, 70.4312, 92.7651]\n",
            "Epoch 0.15 >> (per-task accuracy): 77.91\n",
            "Epoch 0.15 >> (class accuracy): [85.3061, 95.5947, 73.7403, 78.5149, 57.0265, 84.8655, 79.8539, 56.323, 74.1273, 92.4678]\n",
            "Epoch 0.2 >> (per-task accuracy): 80.77\n",
            "Epoch 0.2 >> (class accuracy): [84.1837, 96.3877, 75.7752, 85.0495, 61.5071, 84.3049, 87.4739, 64.2023, 73.614, 93.7562]\n",
            "Epoch 0.25 >> (per-task accuracy): 81.18\n",
            "Epoch 0.25 >> (class accuracy): [88.5714, 97.0044, 76.0659, 87.3267, 62.9328, 84.0807, 85.2818, 60.6031, 75.77, 92.7651]\n",
            "Epoch 0.3 >> (per-task accuracy): 82.73\n",
            "Epoch 0.3 >> (class accuracy): [87.449, 97.7093, 78.6822, 83.2673, 68.2281, 85.7623, 88.5177, 65.5642, 77.9261, 92.9633]\n",
            "Epoch 0.35 >> (per-task accuracy): 81.66\n",
            "Epoch 0.35 >> (class accuracy): [88.2653, 97.6211, 74.1279, 83.1683, 64.1548, 88.3408, 88.7265, 65.6615, 71.0472, 94.45]\n",
            "Epoch 0.4 >> (per-task accuracy): 82.84\n",
            "Epoch 0.4 >> (class accuracy): [91.1224, 97.7974, 77.6163, 84.4554, 66.3951, 87.1076, 91.3361, 63.6187, 74.0246, 93.9544]\n",
            "Epoch 0.45 >> (per-task accuracy): 83.58\n",
            "Epoch 0.45 >> (class accuracy): [91.5306, 97.7093, 79.9419, 84.2574, 66.8024, 87.4439, 88.309, 65.9533, 78.1314, 94.6482]\n",
            "Epoch 0.5 >> (per-task accuracy): 83.35\n",
            "Epoch 0.5 >> (class accuracy): [90.7143, 97.8855, 80.0388, 84.9505, 64.4603, 86.8834, 87.8914, 66.8288, 77.1047, 95.441]\n",
            "Epoch 0.55 >> (per-task accuracy): 84.12\n",
            "Epoch 0.55 >> (class accuracy): [92.551, 97.8855, 81.686, 87.5248, 72.6069, 84.7534, 86.7432, 63.3268, 78.6448, 94.1526]\n",
            "Epoch 0.6 >> (per-task accuracy): 83.95\n",
            "Epoch 0.6 >> (class accuracy): [93.0612, 98.1498, 80.9109, 83.8614, 69.7556, 87.2197, 89.8747, 63.035, 77.9261, 94.7473]\n",
            "Epoch 0.65 >> (per-task accuracy): 82.35\n",
            "Epoch 0.65 >> (class accuracy): [90.6122, 97.0044, 79.7481, 81.4851, 70.3666, 89.7982, 90.7098, 54.9611, 74.3326, 94.1526]\n",
            "Epoch 0.7 >> (per-task accuracy): 84.43\n",
            "Epoch 0.7 >> (class accuracy): [91.9388, 98.1498, 83.2364, 86.3366, 72.7088, 87.1076, 90.3967, 61.1868, 78.4394, 93.8553]\n",
            "Epoch 0.75 >> (per-task accuracy): 83.82\n",
            "Epoch 0.75 >> (class accuracy): [91.8367, 97.7974, 80.814, 86.5347, 70.9776, 87.4439, 89.2484, 60.6031, 78.2341, 93.8553]\n",
            "Epoch 0.8 >> (per-task accuracy): 84.56\n",
            "Epoch 0.8 >> (class accuracy): [93.4694, 98.1498, 81.3953, 87.1287, 70.9776, 87.5561, 89.666, 64.1051, 77.7207, 94.45]\n",
            "Epoch 0.85 >> (per-task accuracy): 84.47\n",
            "Epoch 0.85 >> (class accuracy): [93.2653, 97.9736, 80.5233, 86.5347, 70.5703, 88.2287, 90.2923, 64.3969, 78.5421, 93.558]\n",
            "Epoch 0.9 >> (per-task accuracy): 84.54\n",
            "Epoch 0.9 >> (class accuracy): [92.6531, 97.7974, 82.4612, 88.2178, 70.9776, 88.4529, 88.9353, 64.3969, 77.1047, 93.4589]\n",
            "Epoch 0.95 >> (per-task accuracy): 84.41\n",
            "Epoch 0.95 >> (class accuracy): [93.1633, 98.0617, 80.814, 89.703, 67.8208, 87.5561, 90.1879, 64.2996, 76.7967, 94.6482]\n",
            "Epoch 1.0 >> (per-task accuracy): 84.72\n",
            "Epoch 1.0 >> (class accuracy): [93.1633, 97.9736, 80.1357, 88.4158, 66.8024, 88.6771, 90.2923, 67.1206, 79.1581, 94.5491]\n",
            "OCS >> Task 1: {'accuracy': 73.43, 'per_class_accuracy': [88.1633, 75.5947, 71.124, 78.4158, 47.0468, 55.3812, 84.8643, 77.0428, 63.2444, 90.9812], 'loss': 1.2447869548797608}\n",
            "OCS >> Task 2: {'accuracy': 82.7, 'per_class_accuracy': [91.3265, 88.4581, 82.3643, 87.1287, 61.7108, 74.3274, 89.9791, 79.1829, 78.0287, 92.7651], 'loss': 0.7556775169372558}\n",
            "OCS >> Task 3: {'accuracy': 85.56, 'per_class_accuracy': [92.2449, 95.859, 84.8837, 89.0099, 67.3116, 82.1749, 91.6493, 76.6537, 79.1581, 94.9455], 'loss': 0.5825498484373093}\n",
            "OCS >> Task 4: {'accuracy': 84.72, 'per_class_accuracy': [93.1633, 97.9736, 80.1357, 88.4158, 66.8024, 88.6771, 90.2923, 67.1206, 79.1581, 94.5491], 'loss': 0.6245787121295929}\n",
            "OCS >> (average accuracy): 81.60249999999999\n",
            "OCS >> (Forgetting): 0.1634666666666666\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 5 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 66.94\n",
            "Epoch 0.05 >> (class accuracy): [88.0612, 87.6652, 52.6163, 73.3663, 44.3992, 65.9193, 84.238, 58.6576, 40.8624, 71.3578]\n",
            "Epoch 0.1 >> (per-task accuracy): 69.27\n",
            "Epoch 0.1 >> (class accuracy): [81.2245, 91.0132, 66.0853, 64.4554, 34.4196, 75.6726, 81.7328, 36.7704, 67.6591, 92.3687]\n",
            "Epoch 0.15 >> (per-task accuracy): 72.98\n",
            "Epoch 0.15 >> (class accuracy): [80.7143, 91.9824, 68.0233, 68.7129, 47.556, 78.6996, 83.4029, 44.5525, 73.306, 91.8731]\n",
            "Epoch 0.2 >> (per-task accuracy): 74.65\n",
            "Epoch 0.2 >> (class accuracy): [82.551, 92.2467, 71.124, 77.5248, 43.7882, 80.0448, 85.4906, 44.7471, 74.846, 93.1615]\n",
            "Epoch 0.25 >> (per-task accuracy): 75.64\n",
            "Epoch 0.25 >> (class accuracy): [84.898, 97.0925, 70.8333, 75.0495, 54.7862, 79.148, 85.9081, 39.8833, 75.6674, 91.8731]\n",
            "Epoch 0.3 >> (per-task accuracy): 76.65\n",
            "Epoch 0.3 >> (class accuracy): [88.3673, 96.2115, 71.8023, 79.0099, 55.0916, 79.9327, 86.952, 40.5642, 74.846, 92.666]\n",
            "Epoch 0.35 >> (per-task accuracy): 77.47\n",
            "Epoch 0.35 >> (class accuracy): [87.8571, 95.3304, 78.9729, 81.1881, 56.2118, 80.7175, 84.238, 37.6459, 80.0821, 91.4767]\n",
            "Epoch 0.4 >> (per-task accuracy): 77.21\n",
            "Epoch 0.4 >> (class accuracy): [89.0816, 95.859, 76.8411, 80.8911, 50.3055, 80.9417, 84.6555, 41.1479, 78.0287, 93.1615]\n",
            "Epoch 0.45 >> (per-task accuracy): 77.71\n",
            "Epoch 0.45 >> (class accuracy): [90.9184, 96.9163, 75.7752, 79.802, 54.277, 82.7354, 85.595, 39.786, 78.0287, 92.3687]\n",
            "Epoch 0.5 >> (per-task accuracy): 77.91\n",
            "Epoch 0.5 >> (class accuracy): [88.5714, 96.652, 75.7752, 85.9406, 51.9348, 80.6054, 87.3695, 39.6887, 76.8994, 94.45]\n",
            "Epoch 0.55 >> (per-task accuracy): 78.22\n",
            "Epoch 0.55 >> (class accuracy): [88.4694, 97.0925, 75.1938, 84.9505, 52.0367, 81.7265, 85.595, 43.677, 78.2341, 93.9544]\n",
            "Epoch 0.6 >> (per-task accuracy): 78.74\n",
            "Epoch 0.6 >> (class accuracy): [90.3061, 97.0925, 76.3566, 83.7624, 55.8045, 82.287, 85.3862, 43.4825, 76.386, 95.3419]\n",
            "Epoch 0.65 >> (per-task accuracy): 78.62\n",
            "Epoch 0.65 >> (class accuracy): [91.5306, 96.5639, 75.0, 86.1386, 56.11, 82.8475, 85.0731, 41.537, 76.2834, 94.1526]\n",
            "Epoch 0.7 >> (per-task accuracy): 78.24\n",
            "Epoch 0.7 >> (class accuracy): [90.6122, 97.2687, 75.8721, 81.5842, 53.9715, 83.8565, 85.2818, 40.9533, 77.4127, 94.6482]\n",
            "Epoch 0.75 >> (per-task accuracy): 80.01\n",
            "Epoch 0.75 >> (class accuracy): [90.102, 97.2687, 78.9729, 85.8416, 59.4705, 84.5291, 87.1608, 43.3852, 79.2608, 93.2607]\n",
            "Epoch 0.8 >> (per-task accuracy): 79.43\n",
            "Epoch 0.8 >> (class accuracy): [92.0408, 97.1806, 76.938, 84.6535, 56.4155, 83.5202, 86.3257, 41.6342, 81.0062, 93.7562]\n",
            "Epoch 0.85 >> (per-task accuracy): 79.36\n",
            "Epoch 0.85 >> (class accuracy): [91.9388, 97.2687, 75.7752, 86.2376, 57.6375, 82.9596, 85.8038, 41.0506, 79.5688, 94.45]\n",
            "Epoch 0.9 >> (per-task accuracy): 79.91\n",
            "Epoch 0.9 >> (class accuracy): [90.6122, 97.1806, 78.1008, 86.2376, 54.7862, 84.1928, 84.9687, 46.4008, 80.9035, 94.6482]\n",
            "Epoch 0.95 >> (per-task accuracy): 80.63\n",
            "Epoch 0.95 >> (class accuracy): [90.7143, 97.3568, 78.5853, 88.1188, 56.4155, 82.0628, 85.595, 47.7626, 83.6756, 94.7473]\n",
            "Epoch 1.0 >> (per-task accuracy): 80.31\n",
            "Epoch 1.0 >> (class accuracy): [91.4286, 97.533, 78.7791, 87.8218, 55.7026, 82.8475, 86.4301, 46.1089, 80.6982, 94.5491]\n",
            "OCS >> Task 1: {'accuracy': 68.15, 'per_class_accuracy': [84.6939, 64.4934, 59.2054, 69.0099, 43.3809, 52.8027, 85.1775, 73.0545, 63.347, 85.6293], 'loss': 1.4406980974197388}\n",
            "OCS >> Task 2: {'accuracy': 77.4, 'per_class_accuracy': [89.5918, 78.4141, 74.4186, 81.0891, 54.6843, 67.4888, 87.8914, 72.8599, 76.2834, 90.3865], 'loss': 0.9757675855636597}\n",
            "OCS >> Task 3: {'accuracy': 82.34, 'per_class_accuracy': [91.5306, 89.6916, 83.0426, 86.0396, 60.8961, 75.2242, 90.0835, 69.6498, 81.4168, 94.3508], 'loss': 0.734563928937912}\n",
            "OCS >> Task 4: {'accuracy': 83.31, 'per_class_accuracy': [92.2449, 96.2996, 85.4651, 87.5248, 61.7108, 82.287, 91.1273, 57.9767, 83.9836, 93.2607], 'loss': 0.682512652349472}\n",
            "OCS >> Task 5: {'accuracy': 80.31, 'per_class_accuracy': [91.4286, 97.533, 78.7791, 87.8218, 55.7026, 82.8475, 86.4301, 46.1089, 80.6982, 94.5491], 'loss': 0.8334021837711334}\n",
            "OCS >> (average accuracy): 78.302\n",
            "OCS >> (Forgetting): 0.19109999999999994\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 6 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 54.52\n",
            "Epoch 0.05 >> (class accuracy): [89.2857, 94.185, 36.3372, 86.6337, 21.2831, 17.2646, 78.1837, 0.3891, 50.4107, 64.5193]\n",
            "Epoch 0.1 >> (per-task accuracy): 61.72\n",
            "Epoch 0.1 >> (class accuracy): [74.7959, 82.1145, 52.1318, 69.901, 23.1161, 61.3229, 77.1399, 12.1595, 78.6448, 85.1338]\n",
            "Epoch 0.15 >> (per-task accuracy): 66.41\n",
            "Epoch 0.15 >> (class accuracy): [77.3469, 90.4846, 60.6589, 71.8812, 31.5682, 72.9821, 74.6347, 18.677, 78.2341, 86.6204]\n",
            "Epoch 0.2 >> (per-task accuracy): 68.44\n",
            "Epoch 0.2 >> (class accuracy): [78.0612, 91.1894, 61.7248, 78.0198, 36.7617, 73.6547, 75.0522, 19.8444, 83.0595, 86.1249]\n",
            "Epoch 0.25 >> (per-task accuracy): 69.09\n",
            "Epoch 0.25 >> (class accuracy): [78.2653, 91.5419, 64.0504, 74.4554, 37.3727, 77.6906, 73.6952, 21.9844, 82.7515, 88.4044]\n",
            "Epoch 0.3 >> (per-task accuracy): 69.74\n",
            "Epoch 0.3 >> (class accuracy): [75.7143, 92.2467, 65.5039, 71.9802, 40.3259, 82.8475, 76.2004, 24.7082, 77.2074, 90.2874]\n",
            "Epoch 0.35 >> (per-task accuracy): 71.27\n",
            "Epoch 0.35 >> (class accuracy): [80.5102, 91.63, 66.6667, 75.2475, 49.4908, 79.3722, 74.0084, 24.6109, 81.5195, 89.1972]\n",
            "Epoch 0.4 >> (per-task accuracy): 71.55\n",
            "Epoch 0.4 >> (class accuracy): [80.8163, 93.0396, 66.2791, 79.901, 52.444, 79.8206, 73.904, 24.4163, 74.6407, 89.4945]\n",
            "Epoch 0.45 >> (per-task accuracy): 72.01\n",
            "Epoch 0.45 >> (class accuracy): [78.3673, 94.2731, 67.345, 79.3069, 48.4725, 81.9507, 76.618, 24.2218, 78.8501, 90.0892]\n",
            "Epoch 0.5 >> (per-task accuracy): 72.43\n",
            "Epoch 0.5 >> (class accuracy): [80.0, 94.2731, 69.0891, 80.0, 49.8982, 79.4843, 76.5136, 21.3035, 82.3409, 90.6838]\n",
            "Epoch 0.55 >> (per-task accuracy): 72.8\n",
            "Epoch 0.55 >> (class accuracy): [83.9796, 94.8018, 68.4109, 81.5842, 46.4358, 80.7175, 77.6618, 23.0545, 79.1581, 91.4767]\n",
            "Epoch 0.6 >> (per-task accuracy): 73.25\n",
            "Epoch 0.6 >> (class accuracy): [84.1837, 94.978, 68.6047, 81.1881, 50.3055, 79.9327, 77.0355, 23.93, 80.9035, 90.6838]\n",
            "Epoch 0.65 >> (per-task accuracy): 73.15\n",
            "Epoch 0.65 >> (class accuracy): [80.7143, 96.0352, 69.3798, 82.9703, 47.8615, 80.7175, 77.0355, 24.5136, 79.9795, 91.2785]\n",
            "Epoch 0.7 >> (per-task accuracy): 73.54\n",
            "Epoch 0.7 >> (class accuracy): [82.8571, 96.2115, 68.6047, 83.3663, 52.1385, 79.2601, 77.1399, 21.9844, 82.1355, 90.783]\n",
            "Epoch 0.75 >> (per-task accuracy): 75.41\n",
            "Epoch 0.75 >> (class accuracy): [81.0204, 96.9163, 70.8333, 82.2772, 58.9613, 79.8206, 81.524, 27.7237, 82.6489, 91.4767]\n",
            "Epoch 0.8 >> (per-task accuracy): 74.68\n",
            "Epoch 0.8 >> (class accuracy): [80.7143, 97.0044, 69.9612, 78.7129, 56.8228, 80.157, 81.2109, 27.1401, 82.1355, 92.0714]\n",
            "Epoch 0.85 >> (per-task accuracy): 75.02\n",
            "Epoch 0.85 >> (class accuracy): [81.6327, 96.3877, 70.9302, 80.396, 55.9063, 81.9507, 81.7328, 26.5564, 82.7515, 91.3776]\n",
            "Epoch 0.9 >> (per-task accuracy): 74.74\n",
            "Epoch 0.9 >> (class accuracy): [82.3469, 97.0044, 68.5078, 81.7822, 55.499, 79.5964, 81.4196, 25.7782, 82.4435, 92.1705]\n",
            "Epoch 0.95 >> (per-task accuracy): 74.91\n",
            "Epoch 0.95 >> (class accuracy): [81.8367, 97.4449, 70.9302, 78.9109, 54.9898, 82.5112, 81.1065, 28.6965, 80.1848, 91.6749]\n",
            "Epoch 1.0 >> (per-task accuracy): 75.79\n",
            "Epoch 1.0 >> (class accuracy): [82.3469, 96.9163, 72.8682, 81.6832, 58.2485, 80.9417, 80.167, 29.0856, 82.6489, 92.0714]\n",
            "OCS >> Task 1: {'accuracy': 64.76, 'per_class_accuracy': [81.6327, 63.2599, 53.9729, 66.1386, 51.9348, 53.9238, 76.7223, 72.2763, 47.6386, 79.2864], 'loss': 1.5336147823333741}\n",
            "OCS >> Task 2: {'accuracy': 73.44, 'per_class_accuracy': [86.5306, 78.5022, 66.4729, 79.3069, 59.0631, 65.583, 81.0021, 69.4553, 61.6016, 85.5302], 'loss': 1.09698929271698}\n",
            "OCS >> Task 3: {'accuracy': 78.48, 'per_class_accuracy': [88.8776, 90.0441, 75.7752, 81.7822, 65.5804, 72.6457, 84.8643, 59.9222, 71.6632, 91.9722], 'loss': 0.8502187240600586}\n",
            "OCS >> Task 4: {'accuracy': 80.28, 'per_class_accuracy': [87.449, 96.0352, 81.7829, 80.8911, 66.4969, 80.7175, 86.6388, 49.7082, 79.6715, 92.1705], 'loss': 0.7760840495109558}\n",
            "OCS >> Task 5: {'accuracy': 78.51, 'per_class_accuracy': [86.1224, 98.0617, 79.0698, 82.3762, 61.7108, 80.7175, 84.6555, 36.7704, 81.5195, 92.8642], 'loss': 0.8570723622322083}\n",
            "OCS >> Task 6: {'accuracy': 75.79, 'per_class_accuracy': [82.3469, 96.9163, 72.8682, 81.6832, 58.2485, 80.9417, 80.167, 29.0856, 82.6489, 92.0714], 'loss': 1.0138707246780396}\n",
            "OCS >> (average accuracy): 75.21000000000001\n",
            "OCS >> (Forgetting): 0.21815999999999997\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 7 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 38.69\n",
            "Epoch 0.05 >> (class accuracy): [80.5102, 42.0264, 17.7326, 96.8317, 13.8493, 13.0045, 64.7182, 0.0, 5.5441, 51.1397]\n",
            "Epoch 0.1 >> (per-task accuracy): 56.4\n",
            "Epoch 0.1 >> (class accuracy): [69.2857, 70.3084, 34.7868, 65.7426, 20.8758, 52.8027, 70.8768, 24.8054, 70.2259, 83.8454]\n",
            "Epoch 0.15 >> (per-task accuracy): 61.74\n",
            "Epoch 0.15 >> (class accuracy): [73.3673, 76.652, 39.1473, 66.5347, 33.6049, 65.1345, 71.5031, 29.572, 78.5421, 83.6472]\n",
            "Epoch 0.2 >> (per-task accuracy): 63.32\n",
            "Epoch 0.2 >> (class accuracy): [76.9388, 76.9163, 45.8333, 69.4059, 38.391, 66.0314, 71.5031, 23.93, 79.2608, 85.4311]\n",
            "Epoch 0.25 >> (per-task accuracy): 64.41\n",
            "Epoch 0.25 >> (class accuracy): [77.7551, 78.5903, 47.6744, 70.6931, 37.0672, 69.5067, 71.6075, 28.5019, 75.154, 87.8097]\n",
            "Epoch 0.3 >> (per-task accuracy): 67.59\n",
            "Epoch 0.3 >> (class accuracy): [78.1633, 84.5815, 52.8101, 76.3366, 41.3442, 70.2915, 70.4593, 34.3385, 78.2341, 88.6026]\n",
            "Epoch 0.35 >> (per-task accuracy): 67.42\n",
            "Epoch 0.35 >> (class accuracy): [78.5714, 83.7004, 54.4574, 73.2673, 43.6864, 73.8789, 71.5031, 29.6693, 77.6181, 87.8097]\n",
            "Epoch 0.4 >> (per-task accuracy): 68.7\n",
            "Epoch 0.4 >> (class accuracy): [79.898, 88.7225, 55.814, 73.9604, 43.3809, 72.9821, 72.547, 32.8794, 77.2074, 88.7017]\n",
            "Epoch 0.45 >> (per-task accuracy): 69.84\n",
            "Epoch 0.45 >> (class accuracy): [80.3061, 90.1322, 59.2054, 70.9901, 47.7597, 79.148, 73.904, 33.2685, 75.462, 87.8097]\n",
            "Epoch 0.5 >> (per-task accuracy): 70.77\n",
            "Epoch 0.5 >> (class accuracy): [79.898, 91.1013, 57.7519, 76.0396, 50.0, 76.3453, 74.4259, 36.965, 75.5647, 88.7017]\n",
            "Epoch 0.55 >> (per-task accuracy): 71.22\n",
            "Epoch 0.55 >> (class accuracy): [81.0204, 91.9824, 57.7519, 77.0297, 49.8982, 76.3453, 74.4259, 38.3268, 75.0513, 89.2963]\n",
            "Epoch 0.6 >> (per-task accuracy): 71.44\n",
            "Epoch 0.6 >> (class accuracy): [81.6327, 93.304, 57.1705, 79.505, 51.9348, 75.3363, 72.2338, 37.3541, 75.154, 89.3954]\n",
            "Epoch 0.65 >> (per-task accuracy): 71.69\n",
            "Epoch 0.65 >> (class accuracy): [81.0204, 93.7445, 59.593, 77.0297, 51.1202, 75.3363, 72.0251, 38.8132, 77.1047, 89.5937]\n",
            "Epoch 0.7 >> (per-task accuracy): 72.08\n",
            "Epoch 0.7 >> (class accuracy): [81.7347, 92.8634, 59.3023, 76.5347, 52.7495, 77.13, 73.1733, 37.7432, 79.3634, 89.1972]\n",
            "Epoch 0.75 >> (per-task accuracy): 72.95\n",
            "Epoch 0.75 >> (class accuracy): [83.0612, 92.9515, 61.8217, 80.5941, 55.2953, 75.5605, 72.6514, 38.2296, 78.3368, 89.6928]\n",
            "Epoch 0.8 >> (per-task accuracy): 72.12\n",
            "Epoch 0.8 >> (class accuracy): [82.1429, 92.2467, 59.0116, 71.9802, 58.2485, 77.3543, 75.3653, 37.0623, 77.7207, 89.3954]\n",
            "Epoch 0.85 >> (per-task accuracy): 73.02\n",
            "Epoch 0.85 >> (class accuracy): [81.4286, 94.8018, 57.7519, 76.4356, 56.4155, 78.5874, 73.1733, 41.9261, 77.9261, 90.5847]\n",
            "Epoch 0.9 >> (per-task accuracy): 73.73\n",
            "Epoch 0.9 >> (class accuracy): [82.551, 95.3304, 60.562, 78.1188, 57.7393, 77.8027, 73.7996, 42.1206, 76.2834, 91.5758]\n",
            "Epoch 0.95 >> (per-task accuracy): 74.3\n",
            "Epoch 0.95 >> (class accuracy): [83.2653, 94.8018, 63.1783, 75.9406, 59.5723, 79.5964, 73.5908, 41.7315, 78.9528, 91.2785]\n",
            "Epoch 1.0 >> (per-task accuracy): 74.54\n",
            "Epoch 1.0 >> (class accuracy): [82.6531, 94.978, 62.7907, 78.0198, 62.9328, 78.5874, 74.9478, 40.7588, 78.2341, 90.3865]\n",
            "OCS >> Task 1: {'accuracy': 63.75, 'per_class_accuracy': [77.449, 68.5463, 50.2907, 67.0297, 51.3238, 52.3543, 78.1837, 70.7198, 42.2998, 77.6016], 'loss': 1.647367007637024}\n",
            "OCS >> Task 2: {'accuracy': 70.7, 'per_class_accuracy': [83.5714, 85.022, 58.0426, 78.4158, 52.6477, 59.3049, 81.3152, 65.3696, 56.3655, 84.1427], 'loss': 1.260777832221985}\n",
            "OCS >> Task 3: {'accuracy': 74.22, 'per_class_accuracy': [87.449, 94.3612, 65.407, 79.4059, 58.8595, 65.0224, 85.4906, 53.3074, 60.883, 89.0981], 'loss': 1.0546196210861205}\n",
            "OCS >> Task 4: {'accuracy': 75.88, 'per_class_accuracy': [87.551, 97.8855, 70.155, 79.802, 62.7291, 72.4215, 86.8476, 43.8716, 68.7885, 86.6204], 'loss': 0.9770931739807129}\n",
            "OCS >> Task 5: {'accuracy': 76.78, 'per_class_accuracy': [88.1633, 98.6784, 69.2829, 80.9901, 61.0998, 79.148, 85.4906, 40.3696, 74.538, 88.7017], 'loss': 0.9787028800964356}\n",
            "OCS >> Task 6: {'accuracy': 75.82, 'per_class_accuracy': [85.5102, 98.1498, 65.5039, 78.7129, 62.9328, 80.0448, 80.6889, 40.6615, 76.694, 88.107], 'loss': 1.0209318451881408}\n",
            "OCS >> Task 7: {'accuracy': 74.54, 'per_class_accuracy': [82.6531, 94.978, 62.7907, 78.0198, 62.9328, 78.5874, 74.9478, 40.7588, 78.2341, 90.3865], 'loss': 1.0318402729988099}\n",
            "OCS >> (average accuracy): 73.09857142857142\n",
            "OCS >> (Forgetting): 0.24051666666666666\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 8 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 33.78\n",
            "Epoch 0.05 >> (class accuracy): [92.1429, 72.2467, 0.0, 93.6634, 0.1018, 0.1121, 0.0, 5.1556, 1.54, 63.33]\n",
            "Epoch 0.1 >> (per-task accuracy): 48.3\n",
            "Epoch 0.1 >> (class accuracy): [70.9184, 56.0352, 24.8062, 63.3663, 15.2749, 13.7892, 48.2255, 46.9844, 56.7762, 82.4579]\n",
            "Epoch 0.15 >> (per-task accuracy): 51.72\n",
            "Epoch 0.15 >> (class accuracy): [67.449, 57.4449, 30.4264, 58.4158, 25.6619, 37.6682, 45.5115, 35.7977, 74.23, 83.2507]\n",
            "Epoch 0.2 >> (per-task accuracy): 54.47\n",
            "Epoch 0.2 >> (class accuracy): [72.0408, 60.6167, 36.0465, 65.4455, 24.0326, 33.7444, 51.8789, 33.0739, 78.8501, 87.0168]\n",
            "Epoch 0.25 >> (per-task accuracy): 57.27\n",
            "Epoch 0.25 >> (class accuracy): [78.0612, 61.0573, 42.7326, 68.1188, 25.1527, 35.9865, 49.3737, 40.856, 81.5195, 87.7106]\n",
            "Epoch 0.3 >> (per-task accuracy): 59.33\n",
            "Epoch 0.3 >> (class accuracy): [76.4286, 63.348, 44.8643, 66.4356, 26.7821, 50.4484, 57.5157, 38.9105, 79.7741, 88.2061]\n",
            "Epoch 0.35 >> (per-task accuracy): 60.79\n",
            "Epoch 0.35 >> (class accuracy): [76.8367, 70.3084, 42.9264, 70.5941, 31.0591, 50.3363, 58.977, 37.8405, 79.9795, 87.7106]\n",
            "Epoch 0.4 >> (per-task accuracy): 62.65\n",
            "Epoch 0.4 >> (class accuracy): [77.1429, 72.8634, 46.8992, 74.2574, 33.6049, 50.0, 59.3946, 40.5642, 82.8542, 87.116]\n",
            "Epoch 0.45 >> (per-task accuracy): 63.27\n",
            "Epoch 0.45 >> (class accuracy): [77.3469, 75.859, 44.7674, 70.198, 35.5397, 52.2422, 61.691, 43.0934, 81.4168, 88.7017]\n",
            "Epoch 0.5 >> (per-task accuracy): 63.31\n",
            "Epoch 0.5 >> (class accuracy): [77.551, 74.8899, 46.9961, 68.6139, 37.5764, 51.7937, 60.9603, 43.2879, 80.0821, 89.4945]\n",
            "Epoch 0.55 >> (per-task accuracy): 63.85\n",
            "Epoch 0.55 >> (class accuracy): [75.2041, 75.5947, 48.9341, 68.6139, 44.3992, 54.9327, 60.7516, 39.2996, 79.7741, 89.4945]\n",
            "Epoch 0.6 >> (per-task accuracy): 64.65\n",
            "Epoch 0.6 >> (class accuracy): [76.2245, 77.0925, 49.4186, 67.3267, 43.4827, 55.8296, 64.6138, 41.0506, 80.0821, 89.891]\n",
            "Epoch 0.65 >> (per-task accuracy): 65.26\n",
            "Epoch 0.65 >> (class accuracy): [75.8163, 82.467, 50.6783, 70.0, 44.9084, 54.5964, 64.3006, 40.4669, 77.3101, 89.5937]\n",
            "Epoch 0.7 >> (per-task accuracy): 66.34\n",
            "Epoch 0.7 >> (class accuracy): [76.1224, 82.7313, 49.6124, 74.1584, 48.6762, 54.9327, 63.4656, 42.8988, 78.9528, 89.3954]\n",
            "Epoch 0.75 >> (per-task accuracy): 68.37\n",
            "Epoch 0.75 >> (class accuracy): [76.6327, 85.2863, 52.8101, 76.6337, 50.8147, 57.9596, 67.8497, 44.4553, 80.2875, 88.6026]\n",
            "Epoch 0.8 >> (per-task accuracy): 68.39\n",
            "Epoch 0.8 >> (class accuracy): [77.551, 87.9295, 52.1318, 75.5446, 52.7495, 58.7444, 66.4927, 43.7743, 77.6181, 88.7017]\n",
            "Epoch 0.85 >> (per-task accuracy): 69.49\n",
            "Epoch 0.85 >> (class accuracy): [78.0612, 88.37, 56.1047, 75.6436, 51.222, 61.2108, 65.6576, 47.8599, 78.6448, 89.3954]\n",
            "Epoch 0.9 >> (per-task accuracy): 69.99\n",
            "Epoch 0.9 >> (class accuracy): [78.5714, 89.2511, 54.7481, 75.1485, 55.8045, 59.9776, 68.2672, 44.8444, 83.4702, 87.3142]\n",
            "Epoch 0.95 >> (per-task accuracy): 69.22\n",
            "Epoch 0.95 >> (class accuracy): [77.6531, 89.6916, 51.8411, 76.3366, 52.2403, 63.0045, 67.3278, 44.4553, 78.3368, 88.8999]\n",
            "Epoch 1.0 >> (per-task accuracy): 69.87\n",
            "Epoch 1.0 >> (class accuracy): [78.5714, 89.6035, 51.938, 75.0495, 55.6008, 62.7803, 68.0585, 45.0389, 80.6982, 89.0981]\n",
            "OCS >> Task 1: {'accuracy': 62.4, 'per_class_accuracy': [73.7755, 66.3436, 47.8682, 71.0891, 52.3422, 51.5695, 70.4593, 69.7471, 42.9158, 76.115], 'loss': 1.743821280479431}\n",
            "OCS >> Task 2: {'accuracy': 68.15, 'per_class_accuracy': [79.6939, 82.3789, 53.4884, 78.9109, 49.1853, 58.1839, 74.2171, 66.0506, 54.0041, 82.4579], 'loss': 1.4091845533370972}\n",
            "OCS >> Task 3: {'accuracy': 70.59, 'per_class_accuracy': [83.2653, 92.8634, 61.9186, 79.1089, 52.3422, 60.426, 78.2881, 52.3346, 53.0801, 88.5035], 'loss': 1.2598754188537598}\n",
            "OCS >> Task 4: {'accuracy': 71.29, 'per_class_accuracy': [83.1633, 97.2687, 62.7907, 79.0099, 50.0, 66.0314, 81.9415, 40.7588, 62.3203, 86.5213], 'loss': 1.2347986906051636}\n",
            "OCS >> Task 5: {'accuracy': 71.47, 'per_class_accuracy': [85.3061, 99.1189, 60.562, 80.9901, 46.4358, 69.6188, 78.4969, 38.3268, 67.5565, 85.4311], 'loss': 1.260470209312439}\n",
            "OCS >> Task 6: {'accuracy': 71.83, 'per_class_accuracy': [84.6939, 98.4141, 56.7829, 80.297, 51.6293, 69.843, 75.9916, 38.035, 76.8994, 83.3499], 'loss': 1.2537460258483886}\n",
            "OCS >> Task 7: {'accuracy': 71.37, 'per_class_accuracy': [81.3265, 97.0044, 56.1047, 76.7327, 54.7862, 66.4798, 71.2944, 39.4942, 81.1088, 86.7195], 'loss': 1.2146732276916503}\n",
            "OCS >> Task 8: {'accuracy': 69.87, 'per_class_accuracy': [78.5714, 89.6035, 51.938, 75.0495, 55.6008, 62.7803, 68.0585, 45.0389, 80.6982, 89.0981], 'loss': 1.2825076906204225}\n",
            "OCS >> (average accuracy): 69.62125\n",
            "OCS >> (Forgetting): 0.27324285714285707\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 9 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 28.4\n",
            "Epoch 0.05 >> (class accuracy): [87.2449, 18.8546, 0.0, 91.1881, 0.0, 3.5874, 0.0, 0.0, 0.0, 81.0704]\n",
            "Epoch 0.1 >> (per-task accuracy): 37.03\n",
            "Epoch 0.1 >> (class accuracy): [87.1429, 59.5595, 0.5814, 69.2079, 1.3238, 8.1839, 21.5031, 16.537, 6.4682, 93.4589]\n",
            "Epoch 0.15 >> (per-task accuracy): 45.19\n",
            "Epoch 0.15 >> (class accuracy): [60.6122, 47.8414, 24.6124, 47.9208, 23.6253, 11.9955, 36.952, 46.8872, 62.5257, 85.2329]\n",
            "Epoch 0.2 >> (per-task accuracy): 46.48\n",
            "Epoch 0.2 >> (class accuracy): [59.3878, 46.3436, 32.2674, 43.1683, 27.4949, 14.0135, 39.9791, 43.0934, 70.4312, 85.6293]\n",
            "Epoch 0.25 >> (per-task accuracy): 49.45\n",
            "Epoch 0.25 >> (class accuracy): [56.2245, 51.1894, 36.6279, 48.1188, 30.0407, 15.3587, 45.8246, 46.6926, 75.5647, 85.4311]\n",
            "Epoch 0.3 >> (per-task accuracy): 50.97\n",
            "Epoch 0.3 >> (class accuracy): [60.4082, 50.0441, 38.2752, 46.6337, 33.9104, 17.4888, 45.7203, 46.8872, 81.6222, 85.9267]\n",
            "Epoch 0.35 >> (per-task accuracy): 52.01\n",
            "Epoch 0.35 >> (class accuracy): [56.0204, 54.185, 43.2171, 43.3663, 35.5397, 18.6099, 50.0, 48.6381, 80.8008, 86.4222]\n",
            "Epoch 0.4 >> (per-task accuracy): 53.28\n",
            "Epoch 0.4 >> (class accuracy): [55.9184, 55.5947, 42.6357, 45.0495, 36.0489, 23.4305, 49.3737, 51.6537, 82.8542, 87.2151]\n",
            "Epoch 0.45 >> (per-task accuracy): 54.68\n",
            "Epoch 0.45 >> (class accuracy): [58.1633, 59.4714, 44.186, 44.4554, 40.835, 25.2242, 52.5052, 51.9455, 79.6715, 87.116]\n",
            "Epoch 0.5 >> (per-task accuracy): 56.11\n",
            "Epoch 0.5 >> (class accuracy): [59.1837, 60.8811, 46.3178, 47.4257, 40.1222, 26.9058, 52.714, 52.821, 83.9836, 87.5124]\n",
            "Epoch 0.55 >> (per-task accuracy): 56.43\n",
            "Epoch 0.55 >> (class accuracy): [59.5918, 65.5507, 44.186, 48.4158, 39.613, 28.4753, 54.2797, 50.6809, 80.9035, 88.999]\n",
            "Epoch 0.6 >> (per-task accuracy): 57.02\n",
            "Epoch 0.6 >> (class accuracy): [58.3673, 65.022, 44.5736, 46.6337, 42.057, 30.8296, 55.8455, 53.5992, 81.4168, 88.6026]\n",
            "Epoch 0.65 >> (per-task accuracy): 58.25\n",
            "Epoch 0.65 >> (class accuracy): [59.4898, 66.696, 46.124, 51.4851, 43.5845, 31.7265, 55.7411, 54.6693, 80.3901, 89.0981]\n",
            "Epoch 0.7 >> (per-task accuracy): 58.91\n",
            "Epoch 0.7 >> (class accuracy): [61.5306, 68.1057, 46.2209, 49.505, 47.4542, 32.9596, 56.263, 54.1829, 82.0329, 87.5124]\n",
            "Epoch 0.75 >> (per-task accuracy): 58.7\n",
            "Epoch 0.75 >> (class accuracy): [60.7143, 71.5419, 45.4457, 51.1881, 43.9919, 32.8475, 57.2025, 52.0428, 79.8768, 88.3053]\n",
            "Epoch 0.8 >> (per-task accuracy): 59.29\n",
            "Epoch 0.8 >> (class accuracy): [62.2449, 72.9515, 45.4457, 54.6535, 41.7515, 35.426, 56.8894, 51.07, 79.3634, 89.2963]\n",
            "Epoch 0.85 >> (per-task accuracy): 61.16\n",
            "Epoch 0.85 >> (class accuracy): [63.2653, 77.3568, 45.9302, 58.7129, 46.2322, 35.9865, 57.2025, 53.4047, 80.4928, 88.7017]\n",
            "Epoch 0.9 >> (per-task accuracy): 60.88\n",
            "Epoch 0.9 >> (class accuracy): [63.3673, 78.7665, 47.1899, 55.0495, 46.334, 32.5112, 56.5762, 51.6537, 83.6756, 88.8999]\n",
            "Epoch 0.95 >> (per-task accuracy): 62.15\n",
            "Epoch 0.95 >> (class accuracy): [64.1837, 79.3833, 48.5465, 56.4356, 49.0835, 35.9865, 57.0981, 56.2257, 80.6982, 89.1972]\n",
            "Epoch 1.0 >> (per-task accuracy): 62.71\n",
            "Epoch 1.0 >> (class accuracy): [63.1633, 81.4978, 51.3566, 57.3267, 49.389, 36.5471, 57.5157, 56.0311, 80.2875, 88.999]\n",
            "OCS >> Task 1: {'accuracy': 60.2, 'per_class_accuracy': [71.4286, 66.6079, 51.1628, 67.1287, 48.778, 47.0852, 59.6033, 62.3541, 48.0493, 77.2052], 'loss': 1.7920008123397828}\n",
            "OCS >> Task 2: {'accuracy': 65.72, 'per_class_accuracy': [77.551, 80.6167, 54.7481, 74.7525, 44.2974, 55.7175, 63.7787, 64.1051, 56.4682, 81.7641], 'loss': 1.4793628562927246}\n",
            "OCS >> Task 3: {'accuracy': 66.61, 'per_class_accuracy': [78.5714, 93.0396, 54.4574, 75.1485, 46.7413, 55.6054, 63.9875, 51.1673, 54.5175, 88.107], 'loss': 1.3905843473434447}\n",
            "OCS >> Task 4: {'accuracy': 67.33, 'per_class_accuracy': [76.4286, 97.3568, 56.3953, 71.7822, 46.7413, 57.7354, 69.833, 42.0233, 65.6057, 85.0347], 'loss': 1.368298296737671}\n",
            "OCS >> Task 5: {'accuracy': 67.21, 'per_class_accuracy': [79.3878, 99.0308, 55.1357, 70.6931, 43.7882, 61.2108, 67.6409, 39.9805, 68.6858, 82.4579], 'loss': 1.4239679889678956}\n",
            "OCS >> Task 6: {'accuracy': 67.84, 'per_class_accuracy': [78.8776, 98.6784, 51.1628, 70.5941, 49.2872, 60.7623, 68.3716, 41.9261, 76.4887, 78.5927], 'loss': 1.4286943294525147}\n",
            "OCS >> Task 7: {'accuracy': 67.8, 'per_class_accuracy': [73.3673, 97.4449, 51.6473, 66.9307, 52.8513, 52.2422, 67.8497, 48.249, 80.9035, 81.9623], 'loss': 1.390158243560791}\n",
            "OCS >> Task 8: {'accuracy': 66.19, 'per_class_accuracy': [72.1429, 91.1894, 49.6124, 60.297, 54.6843, 50.1121, 65.5532, 50.5837, 80.0821, 83.6472], 'loss': 1.4671762573242189}\n",
            "OCS >> Task 9: {'accuracy': 62.71, 'per_class_accuracy': [63.1633, 81.4978, 51.3566, 57.3267, 49.389, 36.5471, 57.5157, 56.0311, 80.2875, 88.999], 'loss': 1.6716324697494507}\n",
            "OCS >> (average accuracy): 65.73444444444446\n",
            "OCS >> (Forgetting): 0.307975\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 10 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 24.22\n",
            "Epoch 0.05 >> (class accuracy): [68.3673, 83.1718, 0.0, 0.0, 51.0183, 19.0583, 0.0, 0.0, 13.1417, 0.892]\n",
            "Epoch 0.1 >> (per-task accuracy): 39.87\n",
            "Epoch 0.1 >> (class accuracy): [86.4286, 56.1233, 0.2907, 92.3762, 10.0815, 6.5022, 49.8956, 0.9728, 17.8645, 74.1328]\n",
            "Epoch 0.15 >> (per-task accuracy): 44.36\n",
            "Epoch 0.15 >> (class accuracy): [62.0408, 27.8414, 23.4496, 63.1683, 22.3014, 5.9417, 38.1002, 64.1051, 49.7947, 84.3409]\n",
            "Epoch 0.2 >> (per-task accuracy): 45.91\n",
            "Epoch 0.2 >> (class accuracy): [53.8776, 27.2247, 31.3953, 56.3366, 17.1079, 5.7175, 42.2756, 59.144, 75.9754, 88.107]\n",
            "Epoch 0.25 >> (per-task accuracy): 43.8\n",
            "Epoch 0.25 >> (class accuracy): [49.6939, 27.2247, 34.8837, 47.0297, 18.7373, 5.6054, 34.1336, 54.3774, 73.2033, 90.783]\n",
            "Epoch 0.3 >> (per-task accuracy): 46.95\n",
            "Epoch 0.3 >> (class accuracy): [52.551, 28.4581, 36.2403, 63.7624, 19.5519, 4.9327, 40.7098, 51.8482, 78.0287, 91.1794]\n",
            "Epoch 0.35 >> (per-task accuracy): 46.82\n",
            "Epoch 0.35 >> (class accuracy): [53.6735, 29.6916, 39.2442, 62.3762, 17.9226, 5.4933, 39.0397, 50.6809, 74.846, 92.666]\n",
            "Epoch 0.4 >> (per-task accuracy): 47.91\n",
            "Epoch 0.4 >> (class accuracy): [57.449, 29.7797, 42.0543, 57.6238, 23.0143, 8.1839, 39.4572, 49.8054, 77.1047, 92.5669]\n",
            "Epoch 0.45 >> (per-task accuracy): 49.07\n",
            "Epoch 0.45 >> (class accuracy): [57.6531, 28.37, 44.9612, 52.0792, 27.9022, 12.4439, 41.7537, 53.5992, 78.8501, 91.774]\n",
            "Epoch 0.5 >> (per-task accuracy): 50.61\n",
            "Epoch 0.5 >> (class accuracy): [55.8163, 30.3084, 48.7403, 55.4455, 31.6701, 10.0897, 44.4676, 57.393, 78.7474, 91.4767]\n",
            "Epoch 0.55 >> (per-task accuracy): 51.01\n",
            "Epoch 0.55 >> (class accuracy): [55.7143, 30.4846, 49.031, 53.7624, 33.6049, 11.8834, 45.5115, 57.9767, 78.6448, 91.774]\n",
            "Epoch 0.6 >> (per-task accuracy): 50.93\n",
            "Epoch 0.6 >> (class accuracy): [56.1224, 31.3656, 46.8023, 52.3762, 31.6701, 11.6592, 48.4342, 56.4202, 79.9795, 92.8642]\n",
            "Epoch 0.65 >> (per-task accuracy): 52.38\n",
            "Epoch 0.65 >> (class accuracy): [56.5306, 33.304, 47.4806, 60.099, 31.8737, 14.3498, 48.643, 57.2957, 79.5688, 92.9633]\n",
            "Epoch 0.7 >> (per-task accuracy): 52.52\n",
            "Epoch 0.7 >> (class accuracy): [58.8776, 32.8634, 47.4806, 60.5941, 32.5866, 13.7892, 47.286, 56.5175, 80.1848, 93.3598]\n",
            "Epoch 0.75 >> (per-task accuracy): 52.3\n",
            "Epoch 0.75 >> (class accuracy): [57.0408, 34.0969, 48.062, 58.5149, 33.6049, 12.7803, 47.3904, 56.9066, 79.1581, 93.4589]\n",
            "Epoch 0.8 >> (per-task accuracy): 53.65\n",
            "Epoch 0.8 >> (class accuracy): [57.9592, 35.1542, 48.9341, 59.0099, 38.7984, 13.565, 46.9729, 59.6304, 81.1088, 93.3598]\n",
            "Epoch 0.85 >> (per-task accuracy): 53.7\n",
            "Epoch 0.85 >> (class accuracy): [57.7551, 35.7709, 50.0, 59.604, 41.446, 12.7803, 45.3027, 58.9494, 80.3901, 92.7651]\n",
            "Epoch 0.9 >> (per-task accuracy): 54.46\n",
            "Epoch 0.9 >> (class accuracy): [60.8163, 37.0044, 49.5155, 61.9802, 40.9369, 14.1256, 44.7808, 59.3385, 80.9035, 92.9633]\n",
            "Epoch 0.95 >> (per-task accuracy): 54.71\n",
            "Epoch 0.95 >> (class accuracy): [59.3878, 37.6211, 50.0, 62.6733, 43.4827, 12.7803, 44.3633, 60.0195, 81.3142, 92.9633]\n",
            "Epoch 1.0 >> (per-task accuracy): 55.04\n",
            "Epoch 1.0 >> (class accuracy): [59.898, 39.4714, 48.6434, 62.1782, 42.3625, 13.2287, 46.1378, 62.5486, 80.2875, 92.9633]\n",
            "OCS >> Task 1: {'accuracy': 60.11, 'per_class_accuracy': [73.0612, 63.4361, 54.5543, 66.8317, 42.668, 52.6906, 61.7954, 59.2412, 43.7372, 81.3677], 'loss': 1.80639843044281}\n",
            "OCS >> Task 2: {'accuracy': 65.38, 'per_class_accuracy': [79.1837, 79.1189, 56.5891, 73.5644, 41.0387, 60.6502, 66.3883, 62.2568, 49.384, 82.8543], 'loss': 1.5099923526763916}\n",
            "OCS >> Task 3: {'accuracy': 65.92, 'per_class_accuracy': [79.2857, 91.8943, 54.5543, 71.2871, 46.8432, 63.1166, 65.9708, 48.7354, 46.8172, 86.9177], 'loss': 1.430052205657959}\n",
            "OCS >> Task 4: {'accuracy': 65.54, 'per_class_accuracy': [77.0408, 97.1806, 51.8411, 67.9208, 47.8615, 63.7892, 67.3278, 39.2023, 57.1869, 82.3588], 'loss': 1.4623110939025878}\n",
            "OCS >> Task 5: {'accuracy': 64.32, 'per_class_accuracy': [79.4898, 98.8546, 45.7364, 67.4257, 45.723, 58.7444, 63.6743, 35.7977, 63.2444, 80.3766], 'loss': 1.6065008441925048}\n",
            "OCS >> Task 6: {'accuracy': 63.75, 'per_class_accuracy': [79.6939, 97.9736, 38.8566, 65.1485, 48.4725, 55.7175, 63.8831, 38.1323, 71.0472, 74.7275], 'loss': 1.6935262176513672}\n",
            "OCS >> Task 7: {'accuracy': 62.78, 'per_class_accuracy': [77.2449, 93.9207, 37.0155, 61.8812, 52.3422, 38.7892, 61.1691, 46.2062, 77.9261, 76.115], 'loss': 1.6854148260116577}\n",
            "OCS >> Task 8: {'accuracy': 60.72, 'per_class_accuracy': [74.898, 76.3877, 37.0155, 56.2376, 55.3971, 35.8744, 59.3946, 51.6537, 77.1047, 79.8811], 'loss': 1.7715850290298463}\n",
            "OCS >> Task 9: {'accuracy': 57.69, 'per_class_accuracy': [67.3469, 59.207, 43.0233, 51.2871, 51.4257, 20.6278, 53.2359, 61.0895, 79.1581, 86.9177], 'loss': 1.98193649559021}\n",
            "OCS >> Task 10: {'accuracy': 55.04, 'per_class_accuracy': [59.898, 39.4714, 48.6434, 62.1782, 42.3625, 13.2287, 46.1378, 62.5486, 80.2875, 92.9633], 'loss': 2.1924623252868654}\n",
            "OCS >> (average accuracy): 62.125\n",
            "OCS >> (Forgetting): 0.33997777777777777\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 11 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 25.45\n",
            "Epoch 0.05 >> (class accuracy): [61.0204, 0.0, 3.7791, 47.3267, 0.0, 29.148, 41.023, 0.0, 12.731, 64.7175]\n",
            "Epoch 0.1 >> (per-task accuracy): 19.3\n",
            "Epoch 0.1 >> (class accuracy): [96.8367, 0.0, 0.0, 59.1089, 0.0, 9.5291, 20.5637, 0.0, 2.7721, 7.4331]\n",
            "Epoch 0.15 >> (per-task accuracy): 39.37\n",
            "Epoch 0.15 >> (class accuracy): [83.2653, 21.2335, 0.6783, 86.9307, 7.5356, 3.4753, 66.2839, 14.786, 24.6407, 85.5302]\n",
            "Epoch 0.2 >> (per-task accuracy): 47.62\n",
            "Epoch 0.2 >> (class accuracy): [70.7143, 49.6916, 11.7248, 77.9208, 14.4603, 1.1211, 46.4509, 65.3696, 54.2094, 79.2864]\n",
            "Epoch 0.25 >> (per-task accuracy): 46.7\n",
            "Epoch 0.25 >> (class accuracy): [60.5102, 47.0485, 20.2519, 67.9208, 19.5519, 1.4574, 42.38, 62.2568, 60.7803, 79.782]\n",
            "Epoch 0.3 >> (per-task accuracy): 45.39\n",
            "Epoch 0.3 >> (class accuracy): [56.4286, 41.5859, 22.9651, 61.1881, 21.6904, 1.6816, 42.2756, 56.0311, 64.3737, 81.5659]\n",
            "Epoch 0.35 >> (per-task accuracy): 45.6\n",
            "Epoch 0.35 >> (class accuracy): [54.2857, 36.0352, 24.4186, 63.6634, 25.5601, 1.6816, 41.9624, 53.3074, 70.0205, 81.8632]\n",
            "Epoch 0.4 >> (per-task accuracy): 46.4\n",
            "Epoch 0.4 >> (class accuracy): [55.3061, 37.533, 25.6783, 63.8614, 28.1059, 1.7937, 42.4843, 51.6537, 71.5606, 82.7552]\n",
            "Epoch 0.45 >> (per-task accuracy): 47.1\n",
            "Epoch 0.45 >> (class accuracy): [58.5714, 34.185, 27.3256, 62.3762, 31.2627, 1.7937, 43.4238, 51.751, 74.6407, 83.0525]\n",
            "Epoch 0.5 >> (per-task accuracy): 47.38\n",
            "Epoch 0.5 >> (class accuracy): [58.1633, 34.5374, 28.4884, 63.8614, 32.6884, 1.9058, 44.0501, 51.6537, 71.9713, 83.7463]\n",
            "Epoch 0.55 >> (per-task accuracy): 47.92\n",
            "Epoch 0.55 >> (class accuracy): [57.3469, 35.4185, 30.7171, 63.5644, 34.0122, 2.3543, 44.9896, 51.5564, 72.5873, 83.8454]\n",
            "Epoch 0.6 >> (per-task accuracy): 49.12\n",
            "Epoch 0.6 >> (class accuracy): [59.7959, 38.326, 33.2364, 64.9505, 35.6415, 2.5785, 46.2422, 51.07, 72.1766, 84.0436]\n",
            "Epoch 0.65 >> (per-task accuracy): 49.57\n",
            "Epoch 0.65 >> (class accuracy): [58.5714, 38.1498, 33.8178, 64.7525, 37.3727, 2.5785, 47.5992, 51.3619, 73.922, 84.5391]\n",
            "Epoch 0.7 >> (per-task accuracy): 50.25\n",
            "Epoch 0.7 >> (class accuracy): [60.9184, 39.5595, 35.1744, 64.2574, 39.9185, 2.9148, 47.8079, 51.8482, 72.8953, 84.0436]\n",
            "Epoch 0.75 >> (per-task accuracy): 50.98\n",
            "Epoch 0.75 >> (class accuracy): [61.1224, 41.1454, 35.6589, 63.9604, 39.613, 2.8027, 48.643, 52.821, 76.078, 84.6383]\n",
            "Epoch 0.8 >> (per-task accuracy): 51.2\n",
            "Epoch 0.8 >> (class accuracy): [61.1224, 42.0264, 36.9186, 64.7525, 39.3075, 3.0269, 50.1044, 51.5564, 74.6407, 85.1338]\n",
            "Epoch 0.85 >> (per-task accuracy): 51.61\n",
            "Epoch 0.85 >> (class accuracy): [60.8163, 42.5551, 39.3411, 65.2475, 40.6314, 2.9148, 49.6868, 51.4591, 74.9487, 84.9356]\n",
            "Epoch 0.9 >> (per-task accuracy): 51.79\n",
            "Epoch 0.9 >> (class accuracy): [61.3265, 44.0529, 39.7287, 64.1584, 41.3442, 3.139, 50.0, 51.4591, 73.922, 85.0347]\n",
            "Epoch 0.95 >> (per-task accuracy): 52.31\n",
            "Epoch 0.95 >> (class accuracy): [60.5102, 45.1982, 43.1202, 64.6535, 42.1589, 3.139, 50.2088, 51.6537, 73.8193, 84.6383]\n",
            "Epoch 1.0 >> (per-task accuracy): 52.7\n",
            "Epoch 1.0 >> (class accuracy): [61.6327, 45.1101, 42.1512, 63.0693, 43.0754, 3.0269, 51.2526, 53.3074, 75.462, 85.0347]\n",
            "OCS >> Task 1: {'accuracy': 60.46, 'per_class_accuracy': [84.1837, 62.467, 54.1667, 61.9802, 45.112, 45.9641, 58.7683, 61.284, 56.9815, 71.9524], 'loss': 1.7696060960769653}\n",
            "OCS >> Task 2: {'accuracy': 64.88, 'per_class_accuracy': [85.102, 76.5639, 57.8488, 69.0099, 43.6864, 51.9058, 62.2129, 62.9377, 61.3963, 75.1239], 'loss': 1.495596095275879}\n",
            "OCS >> Task 3: {'accuracy': 65.85, 'per_class_accuracy': [84.5918, 90.4846, 55.2326, 66.6337, 48.3707, 56.3901, 58.6639, 52.7237, 61.191, 80.0793], 'loss': 1.4002735111236573}\n",
            "OCS >> Task 4: {'accuracy': 64.53, 'per_class_accuracy': [83.3673, 95.6828, 52.3256, 64.8515, 48.167, 57.1749, 58.2463, 39.4942, 63.5524, 78.1962], 'loss': 1.44317944355011}\n",
            "OCS >> Task 5: {'accuracy': 63.27, 'per_class_accuracy': [84.0816, 98.4141, 45.3488, 66.0396, 47.0468, 55.3812, 57.3069, 36.0895, 63.039, 75.4212], 'loss': 1.5654565631866455}\n",
            "OCS >> Task 6: {'accuracy': 62.19, 'per_class_accuracy': [81.5306, 98.6784, 37.2093, 67.0297, 48.8798, 49.3274, 59.9165, 35.9922, 68.8912, 69.7721], 'loss': 1.6701652473449706}\n",
            "OCS >> Task 7: {'accuracy': 61.68, 'per_class_accuracy': [80.0, 97.8855, 34.6899, 63.8614, 55.0916, 31.9507, 58.977, 44.7471, 72.6899, 70.4658], 'loss': 1.693090899658203}\n",
            "OCS >> Task 8: {'accuracy': 60.81, 'per_class_accuracy': [78.5714, 92.6872, 31.9767, 59.2079, 57.0265, 25.0, 62.6305, 49.2218, 73.922, 71.556], 'loss': 1.7622192943572998}\n",
            "OCS >> Task 9: {'accuracy': 59.44, 'per_class_accuracy': [73.4694, 84.3172, 35.1744, 57.1287, 53.055, 12.2197, 60.7516, 57.7821, 74.9487, 78.3944], 'loss': 1.8700985355377198}\n",
            "OCS >> Task 10: {'accuracy': 57.2, 'per_class_accuracy': [67.9592, 63.6123, 41.9574, 61.7822, 48.0652, 5.157, 57.3069, 58.1712, 78.4394, 83.8454], 'loss': 1.9978207118988036}\n",
            "OCS >> Task 11: {'accuracy': 52.7, 'per_class_accuracy': [61.6327, 45.1101, 42.1512, 63.0693, 43.0754, 3.0269, 51.2526, 53.3074, 75.462, 85.0347], 'loss': 2.214832674026489}\n",
            "OCS >> (average accuracy): 61.182727272727284\n",
            "OCS >> (Forgetting): 0.34878999999999993\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 12 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 9.39\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 4.2636, 13.0693, 0.0, 83.5202, 0.8351, 0.0, 0.4107, 0.5946]\n",
            "Epoch 0.1 >> (per-task accuracy): 15.84\n",
            "Epoch 0.1 >> (class accuracy): [97.551, 0.0, 0.0969, 54.0594, 0.0, 8.6323, 0.0, 0.0, 0.4107, 0.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 22.65\n",
            "Epoch 0.15 >> (class accuracy): [88.7755, 13.7445, 0.6783, 82.8713, 0.0, 10.3139, 16.3883, 0.0, 3.3881, 11.1992]\n",
            "Epoch 0.2 >> (per-task accuracy): 42.22\n",
            "Epoch 0.2 >> (class accuracy): [82.3469, 60.8811, 7.2674, 87.9208, 1.4257, 3.0269, 43.3194, 49.7082, 6.3655, 72.5471]\n",
            "Epoch 0.25 >> (per-task accuracy): 42.86\n",
            "Epoch 0.25 >> (class accuracy): [73.3673, 47.5771, 8.0426, 85.3465, 10.387, 1.009, 30.2714, 69.6498, 18.6858, 77.6016]\n",
            "Epoch 0.3 >> (per-task accuracy): 43.08\n",
            "Epoch 0.3 >> (class accuracy): [62.449, 35.6828, 14.438, 75.9406, 15.5804, 0.7848, 32.0459, 64.4942, 42.7105, 82.1606]\n",
            "Epoch 0.35 >> (per-task accuracy): 42.38\n",
            "Epoch 0.35 >> (class accuracy): [59.7959, 35.6828, 12.7907, 74.2574, 14.9695, 1.009, 32.3591, 55.1556, 49.384, 84.3409]\n",
            "Epoch 0.4 >> (per-task accuracy): 43.38\n",
            "Epoch 0.4 >> (class accuracy): [59.7959, 40.4405, 12.6938, 72.1782, 18.5336, 0.8969, 33.7161, 53.5992, 53.7988, 83.7463]\n",
            "Epoch 0.45 >> (per-task accuracy): 43.84\n",
            "Epoch 0.45 >> (class accuracy): [57.3469, 39.2952, 14.7287, 70.495, 18.4318, 0.7848, 34.7599, 52.2374, 61.3963, 84.8365]\n",
            "Epoch 0.5 >> (per-task accuracy): 44.12\n",
            "Epoch 0.5 >> (class accuracy): [58.8776, 36.652, 17.345, 67.7228, 20.5703, 0.6726, 34.7599, 52.6265, 63.5524, 84.7374]\n",
            "Epoch 0.55 >> (per-task accuracy): 44.7\n",
            "Epoch 0.55 >> (class accuracy): [58.3673, 38.9427, 17.1512, 69.802, 21.2831, 0.8969, 34.3424, 52.6265, 64.8871, 84.7374]\n",
            "Epoch 0.6 >> (per-task accuracy): 45.19\n",
            "Epoch 0.6 >> (class accuracy): [58.8776, 39.0308, 18.8953, 68.1188, 22.6069, 0.7848, 36.2213, 52.4319, 66.1191, 84.9356]\n",
            "Epoch 0.65 >> (per-task accuracy): 45.91\n",
            "Epoch 0.65 >> (class accuracy): [60.8163, 40.2643, 19.5736, 68.4158, 22.8106, 0.8969, 38.1002, 51.6537, 67.2485, 85.4311]\n",
            "Epoch 0.7 >> (per-task accuracy): 46.4\n",
            "Epoch 0.7 >> (class accuracy): [62.9592, 41.0573, 21.2209, 69.1089, 23.3198, 1.009, 38.309, 49.7082, 67.0431, 86.3231]\n",
            "Epoch 0.75 >> (per-task accuracy): 47.01\n",
            "Epoch 0.75 >> (class accuracy): [64.4898, 41.5859, 22.4806, 68.2178, 25.1527, 1.009, 39.3528, 50.4864, 68.0698, 85.332]\n",
            "Epoch 0.8 >> (per-task accuracy): 47.87\n",
            "Epoch 0.8 >> (class accuracy): [65.8163, 42.2907, 25.1938, 69.0099, 26.8839, 1.009, 42.4843, 49.9027, 67.0431, 85.1338]\n",
            "Epoch 0.85 >> (per-task accuracy): 48.17\n",
            "Epoch 0.85 >> (class accuracy): [66.5306, 43.8767, 26.6473, 68.4158, 26.5784, 1.009, 42.0668, 50.0, 67.1458, 85.2329]\n",
            "Epoch 0.9 >> (per-task accuracy): 48.4\n",
            "Epoch 0.9 >> (class accuracy): [66.5306, 45.6388, 28.5853, 67.5248, 26.4766, 1.009, 42.0668, 48.8327, 66.9405, 85.9267]\n",
            "Epoch 0.95 >> (per-task accuracy): 48.51\n",
            "Epoch 0.95 >> (class accuracy): [66.3265, 47.0485, 28.1008, 67.9208, 27.2912, 1.009, 41.7537, 48.6381, 66.1191, 86.224]\n",
            "Epoch 1.0 >> (per-task accuracy): 48.73\n",
            "Epoch 1.0 >> (class accuracy): [65.6122, 47.6652, 27.1318, 68.5149, 27.5967, 1.009, 42.1712, 49.6109, 67.0431, 86.224]\n",
            "OCS >> Task 1: {'accuracy': 61.11, 'per_class_accuracy': [85.2041, 60.4405, 60.3682, 61.0891, 40.5295, 46.0762, 63.6743, 64.1051, 57.7002, 70.3667], 'loss': 1.6700009679794312}\n",
            "OCS >> Task 2: {'accuracy': 66.18, 'per_class_accuracy': [86.0204, 76.2996, 64.0504, 70.0, 42.8717, 52.4664, 66.4927, 67.607, 59.2402, 73.6373], 'loss': 1.389879838371277}\n",
            "OCS >> Task 3: {'accuracy': 67.16, 'per_class_accuracy': [85.0, 89.6035, 61.2403, 68.0198, 47.556, 58.296, 59.8121, 56.4202, 61.3963, 80.1784], 'loss': 1.2907548025131226}\n",
            "OCS >> Task 4: {'accuracy': 65.86, 'per_class_accuracy': [83.4694, 95.6828, 58.624, 65.3465, 49.2872, 57.6233, 57.5157, 42.7043, 64.5791, 79.2864], 'loss': 1.35522577419281}\n",
            "OCS >> Task 5: {'accuracy': 63.6, 'per_class_accuracy': [85.0, 98.5903, 49.1279, 66.0396, 46.945, 53.3632, 54.071, 38.716, 63.347, 75.7185], 'loss': 1.5183878496170045}\n",
            "OCS >> Task 6: {'accuracy': 61.51, 'per_class_accuracy': [82.9592, 98.8546, 38.0814, 65.0495, 48.6762, 47.9821, 54.9061, 37.1595, 65.8111, 70.4658], 'loss': 1.6818212776184083}\n",
            "OCS >> Task 7: {'accuracy': 60.05, 'per_class_accuracy': [80.6122, 98.6784, 32.2674, 60.396, 54.4807, 31.5022, 53.1315, 45.428, 67.0431, 70.0694], 'loss': 1.7762512851715089}\n",
            "OCS >> Task 8: {'accuracy': 57.7, 'per_class_accuracy': [79.6939, 96.5639, 26.4535, 54.9505, 52.2403, 19.6188, 57.3069, 45.8171, 64.5791, 72.1506], 'loss': 1.9567196323394775}\n",
            "OCS >> Task 9: {'accuracy': 55.56, 'per_class_accuracy': [76.1224, 92.3348, 25.2907, 51.2871, 46.2322, 8.0717, 56.3674, 51.5564, 62.6283, 77.0069], 'loss': 2.139326097488403}\n",
            "OCS >> Task 10: {'accuracy': 54.32, 'per_class_accuracy': [72.1429, 83.2599, 27.8101, 57.2277, 37.4745, 2.9148, 54.4885, 50.2918, 66.8378, 82.3588], 'loss': 2.2651738018035887}\n",
            "OCS >> Task 11: {'accuracy': 51.58, 'per_class_accuracy': [68.9796, 64.6696, 29.1667, 61.2871, 32.9939, 1.6816, 50.8351, 48.1518, 66.7351, 84.9356], 'loss': 2.3945115982055665}\n",
            "OCS >> Task 12: {'accuracy': 48.73, 'per_class_accuracy': [65.6122, 47.6652, 27.1318, 68.5149, 27.5967, 1.009, 42.1712, 49.6109, 67.0431, 86.224], 'loss': 2.5313936656951905}\n",
            "OCS >> (average accuracy): 59.44666666666668\n",
            "OCS >> (Forgetting): 0.364890909090909\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 13 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 9.74\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 21.23\n",
            "Epoch 0.1 >> (class accuracy): [93.3673, 0.0, 0.0, 0.9901, 0.0, 3.2511, 6.6806, 0.0, 82.9569, 29.4351]\n",
            "Epoch 0.15 >> (per-task accuracy): 30.54\n",
            "Epoch 0.15 >> (class accuracy): [87.6531, 9.5154, 31.3953, 3.3663, 19.9593, 1.009, 0.0, 8.2685, 59.5483, 85.1338]\n",
            "Epoch 0.2 >> (per-task accuracy): 31.43\n",
            "Epoch 0.2 >> (class accuracy): [69.4898, 5.815, 13.3721, 56.4356, 3.1568, 4.3722, 16.1795, 29.7665, 29.1581, 86.5213]\n",
            "Epoch 0.25 >> (per-task accuracy): 35.18\n",
            "Epoch 0.25 >> (class accuracy): [55.102, 34.7137, 10.8527, 64.8515, 12.9328, 0.5605, 18.2672, 45.5253, 17.2485, 86.6204]\n",
            "Epoch 0.3 >> (per-task accuracy): 42.35\n",
            "Epoch 0.3 >> (class accuracy): [56.1224, 42.9075, 27.8101, 81.8812, 18.4318, 1.6816, 25.8873, 63.1323, 15.4004, 83.3499]\n",
            "Epoch 0.35 >> (per-task accuracy): 42.21\n",
            "Epoch 0.35 >> (class accuracy): [58.0612, 37.6211, 22.7713, 81.1881, 18.2281, 0.7848, 23.1733, 56.0311, 34.4969, 84.2418]\n",
            "Epoch 0.4 >> (per-task accuracy): 43.96\n",
            "Epoch 0.4 >> (class accuracy): [57.9592, 37.7093, 28.2946, 61.5842, 25.9674, 0.4484, 24.6347, 57.1012, 58.4189, 82.7552]\n",
            "Epoch 0.45 >> (per-task accuracy): 42.31\n",
            "Epoch 0.45 >> (class accuracy): [56.0204, 34.8018, 25.1938, 60.5941, 24.2363, 0.3363, 24.1127, 53.5019, 55.2361, 84.7374]\n",
            "Epoch 0.5 >> (per-task accuracy): 45.2\n",
            "Epoch 0.5 >> (class accuracy): [56.8367, 42.3789, 23.7403, 79.0099, 25.5601, 0.4484, 21.19, 51.8482, 60.883, 84.7374]\n",
            "Epoch 0.55 >> (per-task accuracy): 45.41\n",
            "Epoch 0.55 >> (class accuracy): [52.6531, 44.6696, 28.1977, 80.5941, 31.3646, 0.6726, 22.1294, 51.1673, 51.848, 84.8365]\n",
            "Epoch 0.6 >> (per-task accuracy): 45.93\n",
            "Epoch 0.6 >> (class accuracy): [51.4286, 47.6652, 30.5233, 75.5446, 31.4664, 0.7848, 24.3215, 50.5837, 55.5441, 85.2329]\n",
            "Epoch 0.65 >> (per-task accuracy): 45.97\n",
            "Epoch 0.65 >> (class accuracy): [54.4898, 45.6388, 30.9109, 71.7822, 32.2811, 0.8969, 24.3215, 49.4163, 58.7269, 85.5302]\n",
            "Epoch 0.7 >> (per-task accuracy): 52.53\n",
            "Epoch 0.7 >> (class accuracy): [58.4694, 87.1366, 30.4264, 73.6634, 34.8269, 1.2332, 35.0731, 45.6226, 63.5524, 84.8365]\n",
            "Epoch 0.75 >> (per-task accuracy): 51.37\n",
            "Epoch 0.75 >> (class accuracy): [55.9184, 85.3744, 30.5233, 67.3267, 32.6884, 1.3453, 32.6722, 44.2607, 67.8645, 85.5302]\n",
            "Epoch 0.8 >> (per-task accuracy): 51.5\n",
            "Epoch 0.8 >> (class accuracy): [58.6735, 85.2863, 26.3566, 69.3069, 31.6701, 1.6816, 32.6722, 44.1634, 68.6858, 86.5213]\n",
            "Epoch 0.85 >> (per-task accuracy): 54.21\n",
            "Epoch 0.85 >> (class accuracy): [57.1429, 94.8018, 31.8798, 74.6535, 35.7434, 1.9058, 34.5511, 47.7626, 68.5832, 83.6472]\n",
            "Epoch 0.9 >> (per-task accuracy): 53.71\n",
            "Epoch 0.9 >> (class accuracy): [57.1429, 90.9251, 32.655, 73.5644, 35.947, 1.2332, 31.3152, 47.8599, 70.3285, 85.0347]\n",
            "Epoch 0.95 >> (per-task accuracy): 53.01\n",
            "Epoch 0.95 >> (class accuracy): [58.3673, 84.9339, 32.1705, 69.4059, 35.0305, 1.1211, 33.4029, 49.4163, 70.7392, 85.332]\n",
            "Epoch 1.0 >> (per-task accuracy): 52.6\n",
            "Epoch 1.0 >> (class accuracy): [57.3469, 82.467, 35.3682, 65.7426, 34.5214, 0.6726, 34.4468, 48.93, 70.1232, 86.4222]\n",
            "OCS >> Task 1: {'accuracy': 59.17, 'per_class_accuracy': [83.8776, 64.3172, 56.2016, 59.604, 41.5479, 44.2825, 64.5094, 66.2451, 44.9692, 63.7265], 'loss': 1.6717311248779296}\n",
            "OCS >> Task 2: {'accuracy': 64.16, 'per_class_accuracy': [84.3878, 79.5595, 60.8527, 67.1287, 43.7882, 50.0, 66.9102, 69.5525, 47.4333, 67.9881], 'loss': 1.4144442766189576}\n",
            "OCS >> Task 3: {'accuracy': 65.39, 'per_class_accuracy': [84.1837, 91.3656, 59.7868, 64.3564, 51.1202, 52.13, 61.3779, 59.2412, 48.152, 77.0069], 'loss': 1.3153591455459595}\n",
            "OCS >> Task 4: {'accuracy': 63.78, 'per_class_accuracy': [81.7347, 95.7709, 58.7209, 60.495, 53.8697, 51.6816, 56.5762, 44.1634, 52.8747, 76.5114], 'loss': 1.3752613580703736}\n",
            "OCS >> Task 5: {'accuracy': 61.58, 'per_class_accuracy': [80.0, 98.0617, 49.8062, 60.396, 50.2037, 50.5605, 49.3737, 37.8405, 57.1869, 76.7096], 'loss': 1.5277609363555908}\n",
            "OCS >> Task 6: {'accuracy': 58.68, 'per_class_accuracy': [77.3469, 98.5903, 38.1783, 56.1386, 51.3238, 44.843, 47.5992, 36.0895, 61.0883, 69.7721], 'loss': 1.6867298795700074}\n",
            "OCS >> Task 7: {'accuracy': 57.66, 'per_class_accuracy': [75.6122, 98.7665, 33.9147, 49.703, 56.4155, 28.6996, 44.0501, 46.8872, 64.1684, 70.664], 'loss': 1.7862044095993042}\n",
            "OCS >> Task 8: {'accuracy': 55.13, 'per_class_accuracy': [73.1633, 96.7401, 28.6822, 41.3861, 53.4623, 18.6099, 48.2255, 47.8599, 61.807, 73.0426], 'loss': 1.9567889459609986}\n",
            "OCS >> Task 9: {'accuracy': 52.66, 'per_class_accuracy': [69.4898, 96.7401, 26.5504, 33.6634, 49.389, 6.1659, 47.8079, 54.9611, 55.6468, 76.115], 'loss': 2.1518088447570802}\n",
            "OCS >> Task 10: {'accuracy': 53.19, 'per_class_accuracy': [65.102, 97.8855, 26.5504, 41.5842, 41.0387, 2.13, 49.2693, 53.3074, 63.7577, 80.5748], 'loss': 2.1812497760772707}\n",
            "OCS >> Task 11: {'accuracy': 53.82, 'per_class_accuracy': [63.9796, 95.0661, 29.6512, 49.505, 38.391, 1.4574, 50.8351, 50.9728, 65.5031, 82.3588], 'loss': 2.1634907012939455}\n",
            "OCS >> Task 12: {'accuracy': 53.18, 'per_class_accuracy': [59.898, 88.6344, 32.4612, 58.1188, 35.336, 1.1211, 45.929, 49.8054, 66.5298, 83.8454], 'loss': 2.158856723022461}\n",
            "OCS >> Task 13: {'accuracy': 52.6, 'per_class_accuracy': [57.3469, 82.467, 35.3682, 65.7426, 34.5214, 0.6726, 34.4468, 48.93, 70.1232, 86.4222], 'loss': 2.20946660118103}\n",
            "OCS >> (average accuracy): 57.76923076923076\n",
            "OCS >> (Forgetting): 0.3871\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 14 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 10.99\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 3.9729, 0.198, 0.0, 22.9821, 2.714, 0.0, 3.2854, 78.5927]\n",
            "Epoch 0.1 >> (per-task accuracy): 10.09\n",
            "Epoch 0.1 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 12.12\n",
            "Epoch 0.15 >> (class accuracy): [20.6122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2053, 99.9009]\n",
            "Epoch 0.2 >> (per-task accuracy): 17.02\n",
            "Epoch 0.2 >> (class accuracy): [71.4286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1294, 98.2161]\n",
            "Epoch 0.25 >> (per-task accuracy): 18.34\n",
            "Epoch 0.25 >> (class accuracy): [82.551, 0.0, 0.2907, 0.0, 0.1018, 0.2242, 0.0, 0.0, 5.0308, 96.1348]\n",
            "Epoch 0.3 >> (per-task accuracy): 20.53\n",
            "Epoch 0.3 >> (class accuracy): [81.3265, 4.2291, 3.6822, 0.0, 1.5275, 0.4484, 0.0, 0.0, 19.3018, 95.441]\n",
            "Epoch 0.35 >> (per-task accuracy): 24.64\n",
            "Epoch 0.35 >> (class accuracy): [78.7755, 18.1498, 6.9767, 4.4554, 6.721, 0.5605, 0.0, 0.0, 37.269, 92.666]\n",
            "Epoch 0.4 >> (per-task accuracy): 28.93\n",
            "Epoch 0.4 >> (class accuracy): [74.2857, 28.1938, 9.2054, 20.6931, 12.22, 0.6726, 0.0, 4.6693, 46.8172, 90.2874]\n",
            "Epoch 0.45 >> (per-task accuracy): 32.46\n",
            "Epoch 0.45 >> (class accuracy): [67.8571, 35.6828, 9.0116, 36.2376, 15.6823, 0.6726, 0.0, 15.1751, 52.6694, 88.0079]\n",
            "Epoch 0.5 >> (per-task accuracy): 35.4\n",
            "Epoch 0.5 >> (class accuracy): [61.9388, 41.0573, 9.593, 50.6931, 17.7189, 0.5605, 0.1044, 23.4436, 57.9055, 86.3231]\n",
            "Epoch 0.55 >> (per-task accuracy): 36.93\n",
            "Epoch 0.55 >> (class accuracy): [57.7551, 42.0264, 8.9147, 61.3861, 17.9226, 0.6726, 2.0877, 28.5992, 59.4456, 85.5302]\n",
            "Epoch 0.6 >> (per-task accuracy): 37.85\n",
            "Epoch 0.6 >> (class accuracy): [56.0204, 42.6432, 8.3333, 66.3366, 17.9226, 0.6726, 3.1315, 32.2957, 61.191, 84.8365]\n",
            "Epoch 0.65 >> (per-task accuracy): 38.64\n",
            "Epoch 0.65 >> (class accuracy): [54.0816, 41.7621, 7.8488, 71.4851, 17.5153, 0.6726, 5.0104, 35.7977, 62.6283, 84.5391]\n",
            "Epoch 0.7 >> (per-task accuracy): 38.65\n",
            "Epoch 0.7 >> (class accuracy): [53.3673, 42.2026, 7.9457, 69.802, 17.5153, 0.7848, 6.0543, 35.6031, 63.655, 84.5391]\n",
            "Epoch 0.75 >> (per-task accuracy): 38.74\n",
            "Epoch 0.75 >> (class accuracy): [52.9592, 41.4978, 7.655, 70.198, 16.1914, 0.6726, 7.62, 36.6732, 64.4764, 84.5391]\n",
            "Epoch 0.8 >> (per-task accuracy): 39.08\n",
            "Epoch 0.8 >> (class accuracy): [52.3469, 42.0264, 8.0426, 70.495, 16.4969, 0.6726, 7.5157, 37.4514, 66.1191, 84.6383]\n",
            "Epoch 0.85 >> (per-task accuracy): 39.11\n",
            "Epoch 0.85 >> (class accuracy): [52.2449, 42.2026, 8.3333, 69.901, 16.2933, 0.6726, 7.9332, 37.5486, 66.2218, 84.7374]\n",
            "Epoch 0.9 >> (per-task accuracy): 39.1\n",
            "Epoch 0.9 >> (class accuracy): [51.7347, 41.674, 8.4302, 69.3069, 15.7841, 0.7848, 8.4551, 38.035, 66.4271, 85.4311]\n",
            "Epoch 0.95 >> (per-task accuracy): 39.44\n",
            "Epoch 0.95 >> (class accuracy): [51.8367, 41.7621, 8.4302, 69.604, 15.7841, 0.8969, 8.0376, 40.1751, 68.0698, 84.8365]\n",
            "Epoch 1.0 >> (per-task accuracy): 39.51\n",
            "Epoch 1.0 >> (class accuracy): [51.8367, 41.8502, 9.0116, 69.4059, 15.5804, 0.8969, 8.6639, 39.3969, 68.0698, 85.4311]\n",
            "OCS >> Task 1: {'accuracy': 59.7, 'per_class_accuracy': [85.6122, 53.3921, 59.3023, 66.5347, 36.8635, 50.6726, 66.4927, 63.035, 54.9281, 60.1586], 'loss': 1.425837113571167}\n",
            "OCS >> Task 2: {'accuracy': 64.98, 'per_class_accuracy': [86.8367, 71.63, 60.1744, 71.1881, 42.2607, 60.2018, 69.3111, 67.8016, 57.8029, 61.2488], 'loss': 1.1954330144882201}\n",
            "OCS >> Task 3: {'accuracy': 67.09, 'per_class_accuracy': [85.5102, 87.0485, 58.1395, 70.9901, 45.4175, 61.3229, 65.9708, 58.8521, 63.039, 71.556], 'loss': 1.1037834264755249}\n",
            "OCS >> Task 4: {'accuracy': 65.61, 'per_class_accuracy': [84.6939, 94.6256, 55.1357, 67.4257, 46.5377, 60.6502, 60.4384, 44.6498, 66.3244, 71.8533], 'loss': 1.166287737083435}\n",
            "OCS >> Task 5: {'accuracy': 62.37, 'per_class_accuracy': [84.0816, 98.2379, 43.4109, 62.2772, 50.611, 55.7175, 50.5219, 40.7588, 62.2177, 71.1596], 'loss': 1.2871852851867676}\n",
            "OCS >> Task 6: {'accuracy': 59.81, 'per_class_accuracy': [81.8367, 98.9427, 34.3023, 57.9208, 52.9532, 46.5247, 49.2693, 37.5486, 64.4764, 68.9792], 'loss': 1.4445100675582885}\n",
            "OCS >> Task 7: {'accuracy': 57.64, 'per_class_accuracy': [80.0, 98.5022, 30.814, 51.0891, 56.8228, 27.9148, 44.9896, 46.9844, 63.1417, 68.5828], 'loss': 1.5484697185516358}\n",
            "OCS >> Task 8: {'accuracy': 53.77, 'per_class_accuracy': [78.5714, 96.9163, 25.2907, 42.4752, 50.3055, 15.8072, 43.4238, 44.7471, 59.7536, 71.7542], 'loss': 1.7594547225952148}\n",
            "OCS >> Task 9: {'accuracy': 50.94, 'per_class_accuracy': [75.0, 98.1498, 22.5775, 33.6634, 44.0937, 5.8296, 38.2046, 49.2218, 55.9548, 76.3132], 'loss': 1.9689403804779053}\n",
            "OCS >> Task 10: {'accuracy': 49.51, 'per_class_accuracy': [68.1633, 97.9736, 20.7364, 36.7327, 35.947, 1.9058, 33.7161, 47.6654, 62.423, 78.7909], 'loss': 2.117409679031372}\n",
            "OCS >> Task 11: {'accuracy': 47.98, 'per_class_accuracy': [65.3061, 93.4802, 18.6047, 40.7921, 29.5316, 0.8969, 31.4196, 44.8444, 62.423, 81.7641], 'loss': 2.234255927276611}\n",
            "OCS >> Task 12: {'accuracy': 46.23, 'per_class_accuracy': [61.8367, 81.1454, 15.5039, 53.1683, 25.3564, 0.6726, 23.2777, 45.428, 64.5791, 81.7641], 'loss': 2.303091047668457}\n",
            "OCS >> Task 13: {'accuracy': 43.55, 'per_class_accuracy': [56.9388, 63.1718, 12.6938, 62.1782, 21.7923, 0.5605, 14.405, 43.8716, 68.0698, 84.2418], 'loss': 2.464452921295166}\n",
            "OCS >> Task 14: {'accuracy': 39.51, 'per_class_accuracy': [51.8367, 41.8502, 9.0116, 69.4059, 15.5804, 0.8969, 8.6639, 39.3969, 68.0698, 85.4311], 'loss': 2.696506597900391}\n",
            "OCS >> (average accuracy): 54.90642857142858\n",
            "OCS >> (Forgetting): 0.4081923076923077\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 15 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 11.9\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 3.3915, 0.7921, 0.0, 19.843, 8.7683, 0.0, 18.6858, 69.7721]\n",
            "Epoch 0.1 >> (per-task accuracy): 9.87\n",
            "Epoch 0.1 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 1.2884]\n",
            "Epoch 0.15 >> (per-task accuracy): 11.21\n",
            "Epoch 0.15 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.7947, 14.7671]\n",
            "Epoch 0.2 >> (per-task accuracy): 20.83\n",
            "Epoch 0.2 >> (class accuracy): [49.5918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.8172, 64.8167]\n",
            "Epoch 0.25 >> (per-task accuracy): 24.76\n",
            "Epoch 0.25 >> (class accuracy): [76.9388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.3901, 93.0624]\n",
            "Epoch 0.3 >> (per-task accuracy): 22.56\n",
            "Epoch 0.3 >> (class accuracy): [82.3469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.8214, 94.5491]\n",
            "Epoch 0.35 >> (per-task accuracy): 21.57\n",
            "Epoch 0.35 >> (class accuracy): [79.7959, 0.0, 0.1938, 0.495, 0.1018, 0.0, 0.0, 0.0, 42.4025, 94.5491]\n",
            "Epoch 0.4 >> (per-task accuracy): 22.12\n",
            "Epoch 0.4 >> (class accuracy): [76.7347, 0.0, 1.1628, 2.1782, 0.7128, 0.0, 0.0, 1.8482, 46.4066, 93.9544]\n",
            "Epoch 0.45 >> (per-task accuracy): 24.25\n",
            "Epoch 0.45 >> (class accuracy): [73.1633, 0.5286, 1.6473, 9.703, 1.9348, 0.0, 0.0, 12.8405, 51.9507, 92.1705]\n",
            "Epoch 0.5 >> (per-task accuracy): 27.74\n",
            "Epoch 0.5 >> (class accuracy): [67.7551, 8.0176, 1.8411, 21.2871, 5.499, 0.0, 0.0, 25.4864, 58.7269, 88.8999]\n",
            "Epoch 0.55 >> (per-task accuracy): 31.05\n",
            "Epoch 0.55 >> (class accuracy): [63.2653, 20.0881, 2.0349, 31.8812, 7.4338, 0.0, 0.0, 36.284, 62.115, 85.5302]\n",
            "Epoch 0.6 >> (per-task accuracy): 33.72\n",
            "Epoch 0.6 >> (class accuracy): [60.3061, 28.9868, 1.938, 41.4851, 9.8778, 0.0, 0.0, 43.9689, 63.655, 83.6472]\n",
            "Epoch 0.65 >> (per-task accuracy): 35.91\n",
            "Epoch 0.65 >> (class accuracy): [58.7755, 34.4493, 2.2287, 50.495, 11.4053, 0.1121, 0.0, 49.1245, 64.9897, 83.2507]\n",
            "Epoch 0.7 >> (per-task accuracy): 36.92\n",
            "Epoch 0.7 >> (class accuracy): [56.6327, 34.8018, 2.1318, 58.0198, 13.1365, 0.1121, 0.1044, 50.9728, 66.2218, 82.6561]\n",
            "Epoch 0.75 >> (per-task accuracy): 37.8\n",
            "Epoch 0.75 >> (class accuracy): [55.4082, 35.859, 2.5194, 63.7624, 12.9328, 0.1121, 0.2088, 51.8482, 67.5565, 83.1516]\n",
            "Epoch 0.8 >> (per-task accuracy): 38.15\n",
            "Epoch 0.8 >> (class accuracy): [53.7755, 36.8282, 2.8101, 66.6337, 13.8493, 0.1121, 0.4175, 52.5292, 67.1458, 82.557]\n",
            "Epoch 0.85 >> (per-task accuracy): 37.84\n",
            "Epoch 0.85 >> (class accuracy): [51.8367, 35.0661, 2.7132, 65.7426, 13.8493, 0.2242, 0.6263, 52.0428, 68.9938, 82.7552]\n",
            "Epoch 0.9 >> (per-task accuracy): 37.63\n",
            "Epoch 0.9 >> (class accuracy): [51.0204, 33.0396, 2.6163, 66.4356, 13.442, 0.2242, 0.9395, 50.2918, 70.3285, 83.7463]\n",
            "Epoch 0.95 >> (per-task accuracy): 37.86\n",
            "Epoch 0.95 >> (class accuracy): [51.3265, 33.9207, 2.907, 67.7228, 13.6456, 0.2242, 1.2526, 50.4864, 69.7125, 83.0525]\n",
            "Epoch 1.0 >> (per-task accuracy): 37.97\n",
            "Epoch 1.0 >> (class accuracy): [50.4082, 32.7753, 3.2946, 67.1287, 13.6456, 0.3363, 2.2965, 51.07, 71.4579, 83.1516]\n",
            "OCS >> Task 1: {'accuracy': 56.08, 'per_class_accuracy': [81.6327, 51.1013, 59.0116, 62.8713, 38.1874, 34.6413, 52.9228, 63.035, 58.3162, 57.1853], 'loss': 1.3925374105453492}\n",
            "OCS >> Task 2: {'accuracy': 61.64, 'per_class_accuracy': [83.5714, 70.9251, 58.0426, 68.1188, 42.8717, 46.4126, 56.5762, 68.9689, 60.6776, 57.0862], 'loss': 1.2170747152328492}\n",
            "OCS >> Task 3: {'accuracy': 64.56, 'per_class_accuracy': [83.3673, 86.4317, 56.686, 68.8119, 47.0468, 48.7668, 54.1754, 62.7432, 65.5031, 67.2944], 'loss': 1.1445603887557982}\n",
            "OCS >> Task 4: {'accuracy': 63.63, 'per_class_accuracy': [82.3469, 94.0088, 53.4884, 65.9406, 46.2322, 51.7937, 50.6263, 49.8054, 69.6099, 67.3935], 'loss': 1.1876468559265136}\n",
            "OCS >> Task 5: {'accuracy': 60.51, 'per_class_accuracy': [80.7143, 98.1498, 42.2481, 61.8812, 49.1853, 48.4305, 41.6493, 43.9689, 64.271, 68.6819], 'loss': 1.268938174057007}\n",
            "OCS >> Task 6: {'accuracy': 57.77, 'per_class_accuracy': [79.898, 99.207, 33.2364, 55.4455, 50.611, 42.3767, 39.7704, 37.8405, 65.4004, 67.6908], 'loss': 1.3806131736755372}\n",
            "OCS >> Task 7: {'accuracy': 55.87, 'per_class_accuracy': [77.7551, 99.0308, 30.3295, 48.5149, 54.6843, 27.5785, 34.4468, 44.9416, 63.5524, 69.7721], 'loss': 1.447247689628601}\n",
            "OCS >> Task 8: {'accuracy': 52.53, 'per_class_accuracy': [75.7143, 97.4449, 24.4186, 40.0, 49.1853, 17.4888, 35.6994, 43.5798, 60.2669, 72.6462], 'loss': 1.5946469661712646}\n",
            "OCS >> Task 9: {'accuracy': 49.71, 'per_class_accuracy': [72.7551, 98.1498, 21.3178, 33.5644, 41.0387, 6.7265, 30.3758, 49.2218, 56.7762, 76.5114], 'loss': 1.7284369178771972}\n",
            "OCS >> Task 10: {'accuracy': 47.8, 'per_class_accuracy': [65.2041, 98.9427, 17.8295, 35.1485, 32.6884, 2.2422, 27.0355, 49.3191, 60.6776, 77.4034], 'loss': 1.8339018562316896}\n",
            "OCS >> Task 11: {'accuracy': 46.51, 'per_class_accuracy': [63.5714, 96.9163, 14.7287, 37.3267, 26.6802, 1.009, 24.3215, 47.9572, 60.883, 80.1784], 'loss': 1.9277130252838135}\n",
            "OCS >> Task 12: {'accuracy': 45.41, 'per_class_accuracy': [60.6122, 89.5154, 10.9496, 46.7327, 22.6069, 0.6726, 19.3111, 49.0272, 63.8604, 79.9802], 'loss': 1.9903610385894774}\n",
            "OCS >> Task 13: {'accuracy': 43.69, 'per_class_accuracy': [57.8571, 74.8899, 7.5581, 58.5149, 19.2464, 0.2242, 11.7954, 49.2218, 67.4538, 80.8722], 'loss': 2.071491904449463}\n",
            "OCS >> Task 14: {'accuracy': 40.39, 'per_class_accuracy': [52.9592, 54.2731, 5.0388, 64.2574, 15.1731, 0.3363, 5.8455, 46.2062, 69.1992, 83.8454], 'loss': 2.2112943832397463}\n",
            "OCS >> Task 15: {'accuracy': 37.97, 'per_class_accuracy': [50.4082, 32.7753, 3.2946, 67.1287, 13.6456, 0.3363, 2.2965, 51.07, 71.4579, 83.1516], 'loss': 2.328797821044922}\n",
            "OCS >> (average accuracy): 52.27133333333334\n",
            "OCS >> (Forgetting): 0.43617142857142843\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 16 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 9.33\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 0.5814, 0.198, 0.0, 13.9013, 3.3403, 0.0, 5.5441, 70.8622]\n",
            "Epoch 0.1 >> (per-task accuracy): 9.74\n",
            "Epoch 0.1 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 9.83\n",
            "Epoch 0.15 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.892]\n",
            "Epoch 0.2 >> (per-task accuracy): 14.4\n",
            "Epoch 0.2 >> (class accuracy): [28.8776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.692, 18.4341]\n",
            "Epoch 0.25 >> (per-task accuracy): 23.4\n",
            "Epoch 0.25 >> (class accuracy): [62.6531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 94.2505, 80.0793]\n",
            "Epoch 0.3 >> (per-task accuracy): 24.16\n",
            "Epoch 0.3 >> (class accuracy): [77.1429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.4086, 93.6571]\n",
            "Epoch 0.35 >> (per-task accuracy): 22.77\n",
            "Epoch 0.35 >> (class accuracy): [79.4898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.6468, 94.7473]\n",
            "Epoch 0.4 >> (per-task accuracy): 22.19\n",
            "Epoch 0.4 >> (class accuracy): [77.9592, 0.0, 0.2907, 0.0, 0.0, 0.0, 0.0, 0.0, 50.7187, 94.9455]\n",
            "Epoch 0.45 >> (per-task accuracy): 22.12\n",
            "Epoch 0.45 >> (class accuracy): [75.3061, 0.0, 1.5504, 0.0, 0.0, 0.0, 0.0, 0.0, 52.2587, 94.0535]\n",
            "Epoch 0.5 >> (per-task accuracy): 22.41\n",
            "Epoch 0.5 >> (class accuracy): [72.6531, 0.0, 3.9729, 0.0, 0.1018, 0.0, 0.0, 0.0, 55.6468, 93.6571]\n",
            "Epoch 0.55 >> (per-task accuracy): 23.03\n",
            "Epoch 0.55 >> (class accuracy): [68.1633, 0.0, 6.0078, 0.099, 1.5275, 0.0, 0.0, 2.4319, 61.9097, 92.0714]\n",
            "Epoch 0.6 >> (per-task accuracy): 24.83\n",
            "Epoch 0.6 >> (class accuracy): [65.102, 0.0, 9.3992, 2.3762, 4.4807, 0.0, 0.0, 11.3813, 66.7351, 90.4856]\n",
            "Epoch 0.65 >> (per-task accuracy): 26.06\n",
            "Epoch 0.65 >> (class accuracy): [63.5714, 0.3524, 8.8178, 8.8119, 6.4155, 0.0, 0.0, 19.358, 66.7351, 87.9088]\n",
            "Epoch 0.7 >> (per-task accuracy): 29.15\n",
            "Epoch 0.7 >> (class accuracy): [61.4286, 2.9956, 8.9147, 21.3861, 9.9796, 0.3363, 0.0, 33.2685, 68.8912, 84.9356]\n",
            "Epoch 0.75 >> (per-task accuracy): 31.63\n",
            "Epoch 0.75 >> (class accuracy): [58.2653, 9.7797, 9.0116, 32.6733, 12.22, 0.5605, 0.0, 42.9961, 67.5565, 82.557]\n",
            "Epoch 0.8 >> (per-task accuracy): 33.9\n",
            "Epoch 0.8 >> (class accuracy): [55.4082, 14.8899, 7.4612, 47.0297, 13.8493, 2.13, 0.0, 48.3463, 67.4538, 80.9713]\n",
            "Epoch 0.85 >> (per-task accuracy): 35.41\n",
            "Epoch 0.85 >> (class accuracy): [53.5714, 19.3833, 6.686, 55.0495, 15.3768, 4.3722, 0.1044, 54.2802, 63.1417, 79.9802]\n",
            "Epoch 0.9 >> (per-task accuracy): 36.34\n",
            "Epoch 0.9 >> (class accuracy): [52.551, 21.9383, 6.5891, 59.703, 13.1365, 5.6054, 0.2088, 58.1712, 62.5257, 80.3766]\n",
            "Epoch 0.95 >> (per-task accuracy): 36.7\n",
            "Epoch 0.95 >> (class accuracy): [50.4082, 20.9692, 6.4922, 63.5644, 13.5438, 7.5112, 0.3132, 58.3658, 63.2444, 80.2775]\n",
            "Epoch 1.0 >> (per-task accuracy): 37.06\n",
            "Epoch 1.0 >> (class accuracy): [50.0, 21.674, 6.686, 64.5545, 14.4603, 7.9596, 0.6263, 57.2957, 64.7844, 80.2775]\n",
            "OCS >> Task 1: {'accuracy': 50.35, 'per_class_accuracy': [79.0816, 51.7181, 62.4031, 45.8416, 40.5295, 39.0135, 39.1441, 37.6459, 54.2094, 52.5273], 'loss': 1.4602943376541138}\n",
            "OCS >> Task 2: {'accuracy': 57.5, 'per_class_accuracy': [82.9592, 73.3921, 60.3682, 53.4653, 44.501, 44.2825, 49.3737, 53.7938, 55.9548, 53.3201], 'loss': 1.3535086284637452}\n",
            "OCS >> Task 3: {'accuracy': 59.91, 'per_class_accuracy': [81.4286, 88.37, 58.5271, 50.396, 47.4542, 44.9552, 47.1816, 48.5409, 62.423, 64.5193], 'loss': 1.2991330966949464}\n",
            "OCS >> Task 4: {'accuracy': 58.59, 'per_class_accuracy': [79.5918, 94.185, 53.5853, 47.5248, 45.0102, 42.8251, 44.8852, 41.9261, 63.8604, 66.4024], 'loss': 1.3277324056625366}\n",
            "OCS >> Task 5: {'accuracy': 57.17, 'per_class_accuracy': [79.3878, 98.1498, 46.7054, 41.8812, 45.5193, 38.9013, 35.8038, 42.0233, 65.8111, 70.3667], 'loss': 1.3490080005645753}\n",
            "OCS >> Task 6: {'accuracy': 54.69, 'per_class_accuracy': [80.2041, 98.6784, 37.0155, 39.1089, 45.723, 29.7085, 31.3152, 37.7432, 68.2752, 71.2587], 'loss': 1.4088338523864745}\n",
            "OCS >> Task 7: {'accuracy': 53.24, 'per_class_accuracy': [77.2449, 98.4141, 34.0116, 32.1782, 50.0, 17.2646, 25.9916, 47.9572, 69.3018, 70.5649], 'loss': 1.4346172975540161}\n",
            "OCS >> Task 8: {'accuracy': 50.78, 'per_class_accuracy': [75.7143, 97.0925, 26.2597, 29.2079, 44.8065, 9.8655, 26.618, 46.1089, 69.3018, 72.9435], 'loss': 1.5227675899505615}\n",
            "OCS >> Task 9: {'accuracy': 48.19, 'per_class_accuracy': [72.8571, 98.0617, 21.7054, 22.2772, 38.391, 3.0269, 19.7286, 49.6109, 67.3511, 77.7007], 'loss': 1.603280690765381}\n",
            "OCS >> Task 10: {'accuracy': 46.26, 'per_class_accuracy': [63.8776, 98.4141, 17.8295, 24.5545, 30.7536, 1.3453, 16.2839, 49.6109, 70.4312, 77.7998], 'loss': 1.6787032663345336}\n",
            "OCS >> Task 11: {'accuracy': 45.54, 'per_class_accuracy': [63.3673, 96.2115, 16.4729, 26.3366, 26.8839, 1.009, 15.0313, 49.0272, 69.8152, 79.6829], 'loss': 1.7349490951538087}\n",
            "OCS >> Task 12: {'accuracy': 44.45, 'per_class_accuracy': [59.4898, 90.837, 14.0504, 32.8713, 23.1161, 0.6726, 10.7516, 51.6537, 70.0205, 79.782], 'loss': 1.7718701721191406}\n",
            "OCS >> Task 13: {'accuracy': 43.29, 'per_class_accuracy': [56.1224, 78.8546, 12.3062, 45.8416, 18.3299, 0.8969, 5.8455, 53.2101, 70.8419, 80.5748], 'loss': 1.7928792125701905}\n",
            "OCS >> Task 14: {'accuracy': 40.93, 'per_class_accuracy': [52.7551, 56.3877, 11.3372, 57.8218, 14.5621, 2.6906, 3.4447, 50.6809, 70.3285, 82.1606], 'loss': 1.8546420665740966}\n",
            "OCS >> Task 15: {'accuracy': 39.41, 'per_class_accuracy': [49.6939, 38.4141, 8.4302, 65.0495, 15.0713, 4.8206, 1.4614, 56.5175, 68.2752, 81.5659], 'loss': 1.8775764316558838}\n",
            "OCS >> Task 16: {'accuracy': 37.06, 'per_class_accuracy': [50.0, 21.674, 6.686, 64.5545, 14.4603, 7.9596, 0.6263, 57.2957, 64.7844, 80.2775], 'loss': 1.9441593856811523}\n",
            "OCS >> (average accuracy): 49.21\n",
            "OCS >> (Forgetting): 0.4689\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 17 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 9.32\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 2.6163, 0.0, 0.0, 25.3363, 0.9395, 0.0, 0.1027, 66.3033]\n",
            "Epoch 0.1 >> (per-task accuracy): 9.74\n",
            "Epoch 0.1 >> (class accuracy): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 11.62\n",
            "Epoch 0.15 >> (class accuracy): [19.1837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0]\n",
            "Epoch 0.2 >> (per-task accuracy): 18.39\n",
            "Epoch 0.2 >> (class accuracy): [90.102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.152, 0.0]\n",
            "Epoch 0.25 >> (per-task accuracy): 18.02\n",
            "Epoch 0.25 >> (class accuracy): [96.5306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.885, 0.0]\n",
            "Epoch 0.3 >> (per-task accuracy): 17.79\n",
            "Epoch 0.3 >> (class accuracy): [96.2245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 85.8316, 0.0]\n",
            "Epoch 0.35 >> (per-task accuracy): 18.8\n",
            "Epoch 0.35 >> (class accuracy): [94.3878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.8624, 6.9376]\n",
            "Epoch 0.4 >> (per-task accuracy): 25.03\n",
            "Epoch 0.4 >> (class accuracy): [92.449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.6571, 70.7631]\n",
            "Epoch 0.45 >> (per-task accuracy): 25.21\n",
            "Epoch 0.45 >> (class accuracy): [89.7959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.7741, 85.6293]\n",
            "Epoch 0.5 >> (per-task accuracy): 24.12\n",
            "Epoch 0.5 >> (class accuracy): [87.551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 65.7084, 90.5847]\n",
            "Epoch 0.55 >> (per-task accuracy): 23.41\n",
            "Epoch 0.55 >> (class accuracy): [82.7551, 0.0, 0.1938, 0.0, 0.1018, 0.2242, 0.0, 0.0, 63.2444, 90.0892]\n",
            "Epoch 0.6 >> (per-task accuracy): 23.22\n",
            "Epoch 0.6 >> (class accuracy): [81.7347, 0.0, 0.3876, 1.7822, 0.2037, 0.6726, 0.0, 0.0, 61.0883, 88.8008]\n",
            "Epoch 0.65 >> (per-task accuracy): 23.63\n",
            "Epoch 0.65 >> (class accuracy): [77.2449, 0.0, 0.5814, 7.2277, 0.4073, 1.5695, 0.0, 2.0428, 61.499, 88.107]\n",
            "Epoch 0.7 >> (per-task accuracy): 25.09\n",
            "Epoch 0.7 >> (class accuracy): [75.2041, 0.1762, 0.8721, 15.3465, 3.055, 2.6906, 0.0, 6.9066, 61.7043, 87.2151]\n",
            "Epoch 0.75 >> (per-task accuracy): 26.98\n",
            "Epoch 0.75 >> (class accuracy): [72.6531, 1.4978, 1.2597, 25.3465, 2.8513, 6.3901, 0.0, 13.4241, 62.731, 85.8276]\n",
            "Epoch 0.8 >> (per-task accuracy): 30.22\n",
            "Epoch 0.8 >> (class accuracy): [70.3061, 7.7533, 1.2597, 41.4851, 5.0916, 7.8475, 0.0, 23.249, 63.1417, 83.1516]\n",
            "Epoch 0.85 >> (per-task accuracy): 33.58\n",
            "Epoch 0.85 >> (class accuracy): [69.2857, 20.8811, 1.1628, 46.4356, 7.5356, 12.2197, 0.0, 31.1284, 65.6057, 81.1695]\n",
            "Epoch 0.9 >> (per-task accuracy): 36.15\n",
            "Epoch 0.9 >> (class accuracy): [68.3673, 26.696, 1.0659, 52.6733, 8.8595, 15.3587, 0.0, 40.856, 68.0698, 78.4936]\n",
            "Epoch 0.95 >> (per-task accuracy): 37.36\n",
            "Epoch 0.95 >> (class accuracy): [63.3673, 31.5419, 1.3566, 55.1485, 8.3503, 18.4978, 0.1044, 52.2374, 64.9897, 76.115]\n",
            "Epoch 1.0 >> (per-task accuracy): 37.61\n",
            "Epoch 1.0 >> (class accuracy): [61.7347, 31.2775, 1.1628, 59.1089, 8.554, 18.2735, 0.0, 56.8093, 62.731, 74.331]\n",
            "OCS >> Task 1: {'accuracy': 50.53, 'per_class_accuracy': [82.551, 81.7621, 44.7674, 39.4059, 31.5682, 47.0852, 31.2109, 38.9105, 48.46, 55.005], 'loss': 1.5381230291366577}\n",
            "OCS >> Task 2: {'accuracy': 54.98, 'per_class_accuracy': [83.2653, 91.2775, 48.6434, 46.5347, 32.4847, 52.5785, 37.3695, 49.6109, 46.0986, 56.3925], 'loss': 1.4693411527633666}\n",
            "OCS >> Task 3: {'accuracy': 56.48, 'per_class_accuracy': [83.4694, 96.5639, 49.7093, 47.6238, 35.1324, 49.2152, 37.4739, 44.1634, 50.4107, 64.6184], 'loss': 1.4302117191314698}\n",
            "OCS >> Task 4: {'accuracy': 54.9, 'per_class_accuracy': [81.4286, 98.5022, 47.6744, 45.1485, 32.7902, 47.1973, 35.595, 35.5058, 50.308, 68.0872], 'loss': 1.4536252349853516}\n",
            "OCS >> Task 5: {'accuracy': 54.61, 'per_class_accuracy': [82.449, 99.0308, 41.1822, 43.6634, 36.2525, 41.704, 30.6889, 39.9805, 55.2361, 68.5828], 'loss': 1.4531652936935424}\n",
            "OCS >> Task 6: {'accuracy': 52.57, 'per_class_accuracy': [81.3265, 99.207, 30.0388, 39.802, 35.8452, 32.1749, 27.8706, 38.716, 62.6283, 70.1685], 'loss': 1.4896433954238892}\n",
            "OCS >> Task 7: {'accuracy': 51.56, 'per_class_accuracy': [79.4898, 98.9427, 26.938, 31.0891, 36.6599, 20.5157, 23.1733, 52.3346, 67.8645, 69.1774], 'loss': 1.5099609252929687}\n",
            "OCS >> Task 8: {'accuracy': 48.9, 'per_class_accuracy': [77.7551, 98.4141, 18.314, 25.0495, 35.4379, 10.8744, 22.2338, 52.9183, 69.8152, 68.0872], 'loss': 1.5728100831985474}\n",
            "OCS >> Task 9: {'accuracy': 46.83, 'per_class_accuracy': [74.6939, 98.5903, 16.2791, 16.9307, 29.8371, 3.9238, 16.9102, 58.463, 68.1725, 73.1417], 'loss': 1.6214713788986206}\n",
            "OCS >> Task 10: {'accuracy': 45.17, 'per_class_accuracy': [68.3673, 98.0617, 12.4031, 17.5248, 24.6436, 1.3453, 13.7787, 57.4903, 71.7659, 74.6283], 'loss': 1.6800490783691406}\n",
            "OCS >> Task 11: {'accuracy': 44.04, 'per_class_accuracy': [68.0612, 93.304, 10.8527, 17.9208, 21.9959, 0.4484, 12.1086, 57.8794, 68.3778, 78.0971], 'loss': 1.7208575094223022}\n",
            "OCS >> Task 12: {'accuracy': 42.37, 'per_class_accuracy': [65.5102, 83.7885, 8.3333, 24.0594, 19.7556, 0.4484, 9.8121, 55.8366, 66.8378, 79.0882], 'loss': 1.7581998542785644}\n",
            "OCS >> Task 13: {'accuracy': 40.27, 'per_class_accuracy': [64.0816, 68.1057, 6.1047, 36.6337, 15.9878, 1.009, 3.2359, 53.4047, 65.5031, 80.1784], 'loss': 1.7839458927154541}\n",
            "OCS >> Task 14: {'accuracy': 36.95, 'per_class_accuracy': [60.8163, 41.1454, 5.3295, 47.8218, 12.3218, 2.2422, 1.9833, 48.1518, 63.7577, 81.0704], 'loss': 1.8490746185302733}\n",
            "OCS >> Task 15: {'accuracy': 36.65, 'per_class_accuracy': [60.2041, 25.7269, 3.1008, 59.604, 10.7943, 4.5964, 0.4175, 54.7665, 65.2977, 79.1873], 'loss': 1.8492671634674072}\n",
            "OCS >> Task 16: {'accuracy': 36.46, 'per_class_accuracy': [60.2041, 21.7621, 2.0349, 62.2772, 9.8778, 9.6413, 0.2088, 54.8638, 63.8604, 78.0971], 'loss': 1.882819847869873}\n",
            "OCS >> Task 17: {'accuracy': 37.61, 'per_class_accuracy': [61.7347, 31.2775, 1.1628, 59.1089, 8.554, 18.2735, 0.0, 56.8093, 62.731, 74.331], 'loss': 1.8783608654022217}\n",
            "OCS >> (average accuracy): 46.52235294117647\n",
            "OCS >> (Forgetting): 0.49830624999999995\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 18 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 10.32\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 10.33\n",
            "Epoch 0.1 >> (class accuracy): [0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1027, 0.0]\n",
            "Epoch 0.15 >> (per-task accuracy): 15.76\n",
            "Epoch 0.15 >> (class accuracy): [11.9388, 0.0, 79.3605, 0.0, 0.0, 0.0, 0.0, 0.0, 65.7084, 0.0]\n",
            "Epoch 0.2 >> (per-task accuracy): 16.25\n",
            "Epoch 0.2 >> (class accuracy): [98.5714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 67.6591, 0.0]\n",
            "Epoch 0.25 >> (per-task accuracy): 12.49\n",
            "Epoch 0.25 >> (class accuracy): [99.6939, 0.0, 0.0, 2.1782, 0.0, 0.0, 0.0, 0.0, 25.6674, 0.0]\n",
            "Epoch 0.3 >> (per-task accuracy): 17.69\n",
            "Epoch 0.3 >> (class accuracy): [96.8367, 0.0, 0.0969, 0.0, 0.0, 0.3363, 0.0, 0.0, 83.7782, 0.0]\n",
            "Epoch 0.35 >> (per-task accuracy): 17.81\n",
            "Epoch 0.35 >> (class accuracy): [96.4286, 0.0, 0.0, 0.099, 0.0, 0.0, 0.0, 0.0, 85.729, 0.0]\n",
            "Epoch 0.4 >> (per-task accuracy): 18.05\n",
            "Epoch 0.4 >> (class accuracy): [88.4694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.3039, 0.0]\n",
            "Epoch 0.45 >> (per-task accuracy): 25.41\n",
            "Epoch 0.45 >> (class accuracy): [94.7959, 0.0, 0.0, 30.9901, 0.9165, 0.0, 0.0, 0.0, 51.4374, 78.1962]\n",
            "Epoch 0.5 >> (per-task accuracy): 24.2\n",
            "Epoch 0.5 >> (class accuracy): [88.1633, 0.0, 3.2946, 0.0, 0.0, 0.0, 0.0, 0.0, 93.3265, 60.7532]\n",
            "Epoch 0.55 >> (per-task accuracy): 22.7\n",
            "Epoch 0.55 >> (class accuracy): [89.898, 0.0, 0.4845, 1.0891, 0.0, 0.1121, 0.0, 0.0, 47.6386, 89.9901]\n",
            "Epoch 0.6 >> (per-task accuracy): 25.99\n",
            "Epoch 0.6 >> (class accuracy): [85.4082, 0.0, 0.3876, 0.396, 0.2037, 0.2242, 0.0, 10.4086, 91.0678, 74.9257]\n",
            "Epoch 0.65 >> (per-task accuracy): 24.16\n",
            "Epoch 0.65 >> (class accuracy): [78.1633, 0.0, 0.4845, 17.2277, 0.0, 1.4574, 0.0, 35.5058, 28.3368, 80.9713]\n",
            "Epoch 0.7 >> (per-task accuracy): 26.71\n",
            "Epoch 0.7 >> (class accuracy): [74.898, 2.1145, 1.6473, 4.6535, 28.9206, 1.009, 0.0, 27.1401, 55.9548, 72.5471]\n",
            "Epoch 0.75 >> (per-task accuracy): 27.02\n",
            "Epoch 0.75 >> (class accuracy): [73.5714, 4.0529, 1.3566, 5.1485, 0.1018, 5.7175, 0.2088, 50.5837, 53.7988, 76.4123]\n",
            "Epoch 0.8 >> (per-task accuracy): 34.91\n",
            "Epoch 0.8 >> (class accuracy): [75.4082, 33.6564, 2.5194, 9.3069, 9.4705, 28.6996, 0.0, 41.3424, 76.7967, 72.1506]\n",
            "Epoch 0.85 >> (per-task accuracy): 35.99\n",
            "Epoch 0.85 >> (class accuracy): [71.8367, 31.63, 1.5504, 20.099, 4.7862, 28.5874, 0.6263, 54.572, 77.8234, 68.3845]\n",
            "Epoch 0.9 >> (per-task accuracy): 35.93\n",
            "Epoch 0.9 >> (class accuracy): [72.2449, 31.9824, 2.0349, 32.0792, 4.888, 40.1345, 0.4175, 51.751, 56.4682, 67.889]\n",
            "Epoch 0.95 >> (per-task accuracy): 38.28\n",
            "Epoch 0.95 >> (class accuracy): [73.7755, 43.5242, 3.7791, 32.7723, 4.0733, 31.1659, 4.8017, 59.3385, 63.2444, 64.5193]\n",
            "Epoch 1.0 >> (per-task accuracy): 38.33\n",
            "Epoch 1.0 >> (class accuracy): [73.0612, 51.8943, 1.8411, 29.0099, 4.3788, 32.0628, 8.8727, 55.2529, 57.8029, 66.5015]\n",
            "OCS >> Task 1: {'accuracy': 47.57, 'per_class_accuracy': [81.8367, 70.5727, 31.1047, 64.7525, 40.0204, 39.0135, 29.7495, 32.8794, 25.462, 56.1943], 'loss': 1.5159533323287964}\n",
            "OCS >> Task 2: {'accuracy': 52.94, 'per_class_accuracy': [84.4898, 81.4097, 36.3372, 73.5644, 41.7515, 40.1345, 41.4405, 48.4436, 18.5832, 57.4827], 'loss': 1.4231563276290893}\n",
            "OCS >> Task 3: {'accuracy': 55.27, 'per_class_accuracy': [85.8163, 93.4802, 40.8915, 76.3366, 42.1589, 37.2197, 40.7098, 45.428, 18.9938, 63.8256], 'loss': 1.3809885391235353}\n",
            "OCS >> Task 4: {'accuracy': 55.5, 'per_class_accuracy': [85.5102, 96.4758, 44.4767, 74.4554, 37.8819, 38.2287, 45.0939, 37.0623, 22.2793, 65.7086], 'loss': 1.4007956033706666}\n",
            "OCS >> Task 5: {'accuracy': 56.39, 'per_class_accuracy': [85.9184, 98.7665, 40.6977, 69.802, 35.6415, 37.7803, 41.1273, 41.537, 37.0637, 67.5917], 'loss': 1.4005111940383912}\n",
            "OCS >> Task 6: {'accuracy': 55.46, 'per_class_accuracy': [85.7143, 98.6784, 34.4961, 63.4653, 35.336, 32.0628, 39.8747, 38.5214, 50.1027, 68.3845], 'loss': 1.434161591911316}\n",
            "OCS >> Task 7: {'accuracy': 53.95, 'per_class_accuracy': [82.9592, 98.9427, 30.7171, 51.0891, 35.8452, 19.3946, 31.3152, 48.3463, 63.7577, 67.6908], 'loss': 1.466979789161682}\n",
            "OCS >> Task 8: {'accuracy': 52.23, 'per_class_accuracy': [81.4286, 97.9736, 26.0659, 43.6634, 32.9939, 10.5381, 31.0021, 49.0272, 70.9446, 68.6819], 'loss': 1.5313367645263671}\n",
            "OCS >> Task 9: {'accuracy': 50.09, 'per_class_accuracy': [79.3878, 98.4141, 21.3178, 30.9901, 31.2627, 3.0269, 23.6952, 55.7393, 74.1273, 71.8533], 'loss': 1.5734877391815185}\n",
            "OCS >> Task 10: {'accuracy': 48.08, 'per_class_accuracy': [72.7551, 98.1498, 18.314, 25.5446, 27.4949, 0.8969, 20.9812, 55.3502, 76.4887, 73.439], 'loss': 1.6375497547149658}\n",
            "OCS >> Task 11: {'accuracy': 46.72, 'per_class_accuracy': [70.4082, 94.6256, 13.469, 20.7921, 26.7821, 0.5605, 18.476, 56.2257, 79.8768, 75.1239], 'loss': 1.6715797245025634}\n",
            "OCS >> Task 12: {'accuracy': 44.96, 'per_class_accuracy': [68.4694, 86.1674, 9.2054, 24.4554, 26.3747, 0.7848, 15.6576, 55.642, 77.1047, 75.9167], 'loss': 1.7165202373504638}\n",
            "OCS >> Task 13: {'accuracy': 43.6, 'per_class_accuracy': [68.0612, 75.3304, 7.655, 33.4653, 21.9959, 1.4574, 13.4656, 53.6965, 75.9754, 76.4123], 'loss': 1.7314384197235106}\n",
            "OCS >> Task 14: {'accuracy': 40.85, 'per_class_accuracy': [65.8163, 51.2775, 7.9457, 42.3762, 16.2933, 3.4753, 13.2568, 49.6109, 74.23, 78.9891], 'loss': 1.7763727096557618}\n",
            "OCS >> Task 15: {'accuracy': 39.79, 'per_class_accuracy': [67.1429, 36.8282, 6.4922, 44.3564, 12.7291, 7.6233, 12.7349, 58.5603, 70.9446, 77.3043], 'loss': 1.7671596866607666}\n",
            "OCS >> Task 16: {'accuracy': 39.3, 'per_class_accuracy': [69.5918, 33.2159, 4.4574, 44.9505, 9.165, 12.8924, 12.3173, 59.5331, 66.8378, 77.7998], 'loss': 1.7881725128173829}\n",
            "OCS >> Task 17: {'accuracy': 39.9, 'per_class_accuracy': [72.3469, 38.2379, 2.2287, 41.7822, 7.1283, 23.8789, 12.9436, 63.716, 61.0883, 73.8355], 'loss': 1.7838389293670653}\n",
            "OCS >> Task 18: {'accuracy': 38.33, 'per_class_accuracy': [73.0612, 51.8943, 1.8411, 29.0099, 4.3788, 32.0628, 8.8727, 55.2529, 57.8029, 66.5015], 'loss': 1.8795613822937012}\n",
            "OCS >> (average accuracy): 47.82944444444445\n",
            "OCS >> (Forgetting): 0.4852176470588235\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 19 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 9.09\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 0.0, 31.2871, 0.0, 0.0, 61.8998, 0.0, 0.0, 0.0]\n",
            "Epoch 0.1 >> (per-task accuracy): 8.75\n",
            "Epoch 0.1 >> (class accuracy): [0.6122, 0.0, 0.0, 63.9604, 0.0, 0.0, 22.8601, 0.0, 0.0, 0.3964]\n",
            "Epoch 0.15 >> (per-task accuracy): 17.94\n",
            "Epoch 0.15 >> (class accuracy): [68.7755, 0.0, 0.0, 0.0, 0.0, 0.0, 20.4593, 0.0, 94.5585, 0.2973]\n",
            "Epoch 0.2 >> (per-task accuracy): 12.57\n",
            "Epoch 0.2 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.4394, 0.0]\n",
            "Epoch 0.25 >> (per-task accuracy): 10.29\n",
            "Epoch 0.25 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0308, 0.0]\n",
            "Epoch 0.3 >> (per-task accuracy): 10.49\n",
            "Epoch 0.3 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.1018, 0.0, 0.0, 0.0, 6.9815, 0.0]\n",
            "Epoch 0.35 >> (per-task accuracy): 13.18\n",
            "Epoch 0.35 >> (class accuracy): [99.6939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0103, 0.0]\n",
            "Epoch 0.4 >> (per-task accuracy): 13.95\n",
            "Epoch 0.4 >> (class accuracy): [99.6939, 0.0, 0.0, 0.0, 0.1018, 0.0, 0.0, 0.0, 33.2649, 9.217]\n",
            "Epoch 0.45 >> (per-task accuracy): 21.35\n",
            "Epoch 0.45 >> (class accuracy): [98.0612, 9.4273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 74.846, 33.4985]\n",
            "Epoch 0.5 >> (per-task accuracy): 18.37\n",
            "Epoch 0.5 >> (class accuracy): [90.7143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.9199, 0.3964]\n",
            "Epoch 0.55 >> (per-task accuracy): 24.01\n",
            "Epoch 0.55 >> (class accuracy): [95.7143, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2359, 0.0, 75.3593, 69.1774]\n",
            "Epoch 0.6 >> (per-task accuracy): 23.0\n",
            "Epoch 0.6 >> (class accuracy): [93.0612, 0.0, 0.0, 10.9901, 0.0, 0.0, 0.0, 0.0, 42.0945, 85.9267]\n",
            "Epoch 0.65 >> (per-task accuracy): 24.49\n",
            "Epoch 0.65 >> (class accuracy): [87.9592, 0.0, 0.0, 75.1485, 0.0, 0.0, 0.0, 0.0, 3.7988, 78.3944]\n",
            "Epoch 0.7 >> (per-task accuracy): 23.5\n",
            "Epoch 0.7 >> (class accuracy): [83.1633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 93.8398, 61.5461]\n",
            "Epoch 0.75 >> (per-task accuracy): 26.11\n",
            "Epoch 0.75 >> (class accuracy): [88.2653, 0.0, 0.8721, 3.3663, 0.0, 19.2825, 0.0, 4.6693, 77.8234, 71.8533]\n",
            "Epoch 0.8 >> (per-task accuracy): 29.16\n",
            "Epoch 0.8 >> (class accuracy): [86.1224, 0.5286, 0.3876, 19.1089, 0.0, 1.009, 0.0, 33.2685, 88.6037, 64.9158]\n",
            "Epoch 0.85 >> (per-task accuracy): 28.79\n",
            "Epoch 0.85 >> (class accuracy): [83.0612, 0.0881, 1.0659, 12.8713, 0.2037, 4.148, 0.0, 32.4903, 78.0287, 78.2953]\n",
            "Epoch 0.9 >> (per-task accuracy): 30.79\n",
            "Epoch 0.9 >> (class accuracy): [85.6122, 5.6388, 0.6783, 16.1386, 0.2037, 9.5291, 1.0438, 35.5058, 78.7474, 77.0069]\n",
            "Epoch 0.95 >> (per-task accuracy): 35.81\n",
            "Epoch 0.95 >> (class accuracy): [81.8367, 30.1322, 0.2907, 24.9505, 4.9898, 16.3677, 0.1044, 51.9455, 76.1807, 70.3667]\n",
            "Epoch 1.0 >> (per-task accuracy): 37.55\n",
            "Epoch 1.0 >> (class accuracy): [76.2245, 50.9251, 1.0659, 19.604, 0.611, 13.7892, 0.0, 61.4786, 85.8316, 61.8434]\n",
            "OCS >> Task 1: {'accuracy': 43.9, 'per_class_accuracy': [87.6531, 57.2687, 40.8915, 39.901, 5.0916, 25.7848, 7.5157, 21.0117, 80.8008, 69.4747], 'loss': 1.771305912399292}\n",
            "OCS >> Task 2: {'accuracy': 47.28, 'per_class_accuracy': [88.6735, 65.6388, 43.7984, 43.2673, 6.8228, 21.3004, 12.7349, 35.4086, 79.0554, 70.5649], 'loss': 1.7343352735519408}\n",
            "OCS >> Task 3: {'accuracy': 46.2, 'per_class_accuracy': [88.0612, 59.8238, 48.1589, 42.6733, 7.8411, 15.583, 13.6743, 30.8366, 75.154, 74.7275], 'loss': 1.719961631011963}\n",
            "OCS >> Task 4: {'accuracy': 43.98, 'per_class_accuracy': [86.5306, 55.2423, 47.2868, 40.9901, 5.499, 12.5561, 11.4823, 24.7082, 73.7166, 76.6105], 'loss': 1.7473261482238769}\n",
            "OCS >> Task 5: {'accuracy': 42.25, 'per_class_accuracy': [85.7143, 51.5419, 45.155, 40.099, 6.11, 8.8565, 11.3779, 22.7626, 71.1499, 74.7275], 'loss': 1.7529340372085571}\n",
            "OCS >> Task 6: {'accuracy': 40.42, 'per_class_accuracy': [83.4694, 55.0661, 36.0465, 36.4356, 4.9898, 2.8027, 9.8121, 20.2335, 74.538, 75.0248], 'loss': 1.7816634180068969}\n",
            "OCS >> Task 7: {'accuracy': 39.33, 'per_class_accuracy': [78.6735, 57.6211, 31.686, 24.4554, 4.0733, 2.0179, 10.9603, 26.9455, 78.3368, 72.448], 'loss': 1.7943743495941162}\n",
            "OCS >> Task 8: {'accuracy': 36.4, 'per_class_accuracy': [77.6531, 46.7841, 25.8721, 20.495, 3.1568, 1.2332, 11.2735, 22.0817, 81.2115, 69.9703], 'loss': 1.820781887626648}\n",
            "OCS >> Task 9: {'accuracy': 38.75, 'per_class_accuracy': [73.7755, 71.5419, 25.1938, 10.495, 5.1935, 0.3363, 10.1253, 28.9883, 82.0329, 71.9524], 'loss': 1.8256272560119629}\n",
            "OCS >> Task 10: {'accuracy': 39.26, 'per_class_accuracy': [69.5918, 82.3789, 22.2868, 9.0099, 6.0081, 0.1121, 7.2025, 28.5019, 84.2916, 73.8355], 'loss': 1.8394173351287841}\n",
            "OCS >> Task 11: {'accuracy': 38.72, 'per_class_accuracy': [70.8163, 77.0925, 21.3178, 7.4257, 5.499, 0.1121, 4.8017, 29.8638, 85.8316, 75.7185], 'loss': 1.8352605619430542}\n",
            "OCS >> Task 12: {'accuracy': 36.61, 'per_class_accuracy': [72.0408, 57.3568, 20.6395, 7.2277, 4.5825, 0.0, 2.2965, 31.323, 87.885, 76.6105], 'loss': 1.8379537464141846}\n",
            "OCS >> Task 13: {'accuracy': 36.07, 'per_class_accuracy': [71.2245, 47.9295, 18.7984, 13.3663, 4.277, 0.2242, 0.6263, 34.5331, 87.269, 77.4034], 'loss': 1.836294217300415}\n",
            "OCS >> Task 14: {'accuracy': 33.3, 'per_class_accuracy': [68.1633, 26.8722, 16.8605, 17.6238, 2.9532, 0.4484, 0.1044, 33.463, 86.5503, 77.7007], 'loss': 1.857458642578125}\n",
            "OCS >> Task 15: {'accuracy': 33.54, 'per_class_accuracy': [68.8776, 13.7445, 12.3062, 22.5743, 3.8697, 0.8969, 0.1044, 50.0, 86.4476, 75.8176], 'loss': 1.8439512187957763}\n",
            "OCS >> Task 16: {'accuracy': 33.16, 'per_class_accuracy': [70.6122, 6.7841, 6.7829, 24.2574, 3.7678, 2.13, 0.1044, 56.6148, 84.8049, 76.0159], 'loss': 1.8495684532165528}\n",
            "OCS >> Task 17: {'accuracy': 34.1, 'per_class_accuracy': [73.3673, 12.4229, 3.3915, 23.2673, 2.3422, 5.3812, 0.1044, 63.8132, 84.3943, 72.3489], 'loss': 1.8307293418884278}\n",
            "OCS >> Task 18: {'accuracy': 35.41, 'per_class_accuracy': [72.2449, 31.5419, 1.6473, 22.3762, 1.222, 7.9596, 0.0, 59.3385, 87.885, 67.6908], 'loss': 1.8635627113342286}\n",
            "OCS >> Task 19: {'accuracy': 37.55, 'per_class_accuracy': [76.2245, 50.9251, 1.0659, 19.604, 0.611, 13.7892, 0.0, 61.4786, 85.8316, 61.8434], 'loss': 1.8581702739715575}\n",
            "OCS >> (average accuracy): 38.74894736842106\n",
            "OCS >> (Forgetting): 0.5809444444444444\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "---- Task 20 (OCS) ----\n",
            "Epoch 0.05 >> (per-task accuracy): 12.43\n",
            "Epoch 0.05 >> (class accuracy): [0.0, 0.0, 3.4884, 0.099, 0.0, 36.9955, 51.7745, 0.0, 0.2053, 37.4628]\n",
            "Epoch 0.1 >> (per-task accuracy): 12.47\n",
            "Epoch 0.1 >> (class accuracy): [29.7959, 0.0, 3.5853, 1.0891, 0.0, 24.5516, 47.286, 0.0, 2.6694, 20.7136]\n",
            "Epoch 0.15 >> (per-task accuracy): 10.1\n",
            "Epoch 0.15 >> (class accuracy): [99.898, 0.0, 0.0, 1.2871, 0.0, 1.9058, 0.1044, 0.0, 0.0, 0.0]\n",
            "Epoch 0.2 >> (per-task accuracy): 9.8\n",
            "Epoch 0.2 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.25 >> (per-task accuracy): 9.8\n",
            "Epoch 0.25 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.3 >> (per-task accuracy): 9.8\n",
            "Epoch 0.3 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.35 >> (per-task accuracy): 9.8\n",
            "Epoch 0.35 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.4 >> (per-task accuracy): 9.8\n",
            "Epoch 0.4 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.45 >> (per-task accuracy): 9.8\n",
            "Epoch 0.45 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.5 >> (per-task accuracy): 9.8\n",
            "Epoch 0.5 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.55 >> (per-task accuracy): 9.8\n",
            "Epoch 0.55 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.6 >> (per-task accuracy): 9.8\n",
            "Epoch 0.6 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.65 >> (per-task accuracy): 9.81\n",
            "Epoch 0.65 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.1121, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.7 >> (per-task accuracy): 9.82\n",
            "Epoch 0.7 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.2242, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.75 >> (per-task accuracy): 9.87\n",
            "Epoch 0.75 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 0.7848, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.8 >> (per-task accuracy): 10.08\n",
            "Epoch 0.8 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 3.139, 0.0, 0.0, 0.0, 0.0]\n",
            "Epoch 0.85 >> (per-task accuracy): 10.48\n",
            "Epoch 0.85 >> (class accuracy): [100.0, 0.0, 0.0, 0.0, 0.0, 7.0628, 0.0, 0.0, 0.5133, 0.0]\n",
            "Epoch 0.9 >> (per-task accuracy): 11.39\n",
            "Epoch 0.9 >> (class accuracy): [99.898, 0.0, 0.0, 0.099, 0.3055, 14.6861, 0.0, 0.0, 2.5667, 0.0]\n",
            "Epoch 0.95 >> (per-task accuracy): 12.74\n",
            "Epoch 0.95 >> (class accuracy): [99.7959, 0.9692, 0.0, 0.7921, 0.5092, 21.7489, 0.0, 0.0, 8.0082, 0.0]\n",
            "Epoch 1.0 >> (per-task accuracy): 14.76\n",
            "Epoch 1.0 >> (class accuracy): [99.5918, 8.8987, 0.0, 1.4851, 0.9165, 24.2152, 0.0, 0.0, 16.3244, 0.0]\n",
            "OCS >> Task 1: {'accuracy': 14.36, 'per_class_accuracy': [99.7959, 3.2599, 0.0, 13.6634, 0.3055, 25.4484, 0.0, 0.0, 5.4415, 0.0], 'loss': 2.201104181289673}\n",
            "OCS >> Task 2: {'accuracy': 14.69, 'per_class_accuracy': [99.6939, 2.0264, 0.0, 17.4257, 0.3055, 30.0448, 0.0, 0.0, 2.2587, 0.0], 'loss': 2.1973229255676268}\n",
            "OCS >> Task 3: {'accuracy': 14.87, 'per_class_accuracy': [99.7959, 1.2335, 0.0, 20.495, 0.611, 30.3812, 0.0, 0.0, 1.1294, 0.0], 'loss': 2.1937530181884766}\n",
            "OCS >> Task 4: {'accuracy': 14.11, 'per_class_accuracy': [99.3878, 0.2643, 0.0, 14.9505, 0.9165, 29.7085, 0.0, 0.0, 0.924, 0.0], 'loss': 2.1952900455474853}\n",
            "OCS >> Task 5: {'accuracy': 14.42, 'per_class_accuracy': [99.6939, 0.0, 0.0, 15.4455, 1.5275, 28.4753, 0.0, 0.0, 4.1068, 0.0], 'loss': 2.1930601306915283}\n",
            "OCS >> Task 6: {'accuracy': 14.64, 'per_class_accuracy': [99.7959, 0.2643, 0.0, 14.4554, 6.0081, 25.8969, 0.0, 0.0, 4.8255, 0.0], 'loss': 2.192326971054077}\n",
            "OCS >> Task 7: {'accuracy': 15.06, 'per_class_accuracy': [99.7959, 0.0, 0.0, 12.4752, 6.11, 22.0852, 0.0, 0.0, 14.7844, 0.0991], 'loss': 2.195039962005615}\n",
            "OCS >> Task 8: {'accuracy': 14.89, 'per_class_accuracy': [99.6939, 0.0, 0.0, 9.802, 11.0998, 17.8251, 0.0, 0.0, 14.7844, 0.0991], 'loss': 2.197288081359863}\n",
            "OCS >> Task 9: {'accuracy': 15.76, 'per_class_accuracy': [99.6939, 0.0, 0.0, 10.198, 11.8126, 14.9103, 0.0, 0.0, 25.2567, 0.0991], 'loss': 2.1976852313995363}\n",
            "OCS >> Task 10: {'accuracy': 16.1, 'per_class_accuracy': [99.1837, 0.0, 0.0, 9.802, 15.1731, 19.9552, 0.0, 0.0, 20.7392, 0.9911], 'loss': 2.1971054096221923}\n",
            "OCS >> Task 11: {'accuracy': 14.63, 'per_class_accuracy': [99.5918, 0.0, 0.0, 8.0198, 8.6558, 14.2377, 0.0, 0.0, 18.2752, 1.5857], 'loss': 2.1961508388519286}\n",
            "OCS >> Task 12: {'accuracy': 13.41, 'per_class_accuracy': [99.6939, 0.0, 0.0, 6.0396, 4.0733, 11.6592, 0.0, 0.0, 15.9138, 0.3964], 'loss': 2.1972727210998535}\n",
            "OCS >> Task 13: {'accuracy': 12.67, 'per_class_accuracy': [99.5918, 0.0, 0.0, 4.2574, 1.9348, 12.6682, 0.0, 0.0, 11.0883, 0.7929], 'loss': 2.1979642482757566}\n",
            "OCS >> Task 14: {'accuracy': 12.43, 'per_class_accuracy': [99.6939, 0.0, 0.0, 2.6733, 0.9165, 12.7803, 0.0, 0.0, 11.7043, 0.1982], 'loss': 2.1993637321472166}\n",
            "OCS >> Task 15: {'accuracy': 12.0, 'per_class_accuracy': [99.898, 0.0, 0.0, 1.8812, 1.0183, 10.8744, 0.0, 0.0, 9.5483, 0.1982], 'loss': 2.196813611602783}\n",
            "OCS >> Task 16: {'accuracy': 12.34, 'per_class_accuracy': [99.7959, 0.0881, 0.0, 1.3861, 0.8147, 13.6771, 0.0, 0.0, 11.191, 0.1982], 'loss': 2.1936149047851563}\n",
            "OCS >> Task 17: {'accuracy': 12.54, 'per_class_accuracy': [99.5918, 0.0, 0.0, 1.5842, 2.3422, 13.3408, 0.0, 0.0, 11.9097, 0.3964], 'loss': 2.1903474239349365}\n",
            "OCS >> Task 18: {'accuracy': 13.41, 'per_class_accuracy': [99.6939, 1.7621, 0.0, 2.0792, 1.6293, 15.8072, 0.0, 0.0, 16.8378, 0.1982], 'loss': 2.189331704711914}\n",
            "OCS >> Task 19: {'accuracy': 15.27, 'per_class_accuracy': [99.7959, 10.0441, 0.0, 3.1683, 0.8147, 21.3004, 0.0, 0.0, 21.0472, 0.0], 'loss': 2.1868865787506104}\n",
            "OCS >> Task 20: {'accuracy': 14.76, 'per_class_accuracy': [99.5918, 8.8987, 0.0, 1.4851, 0.9165, 24.2152, 0.0, 0.0, 16.3244, 0.0], 'loss': 2.1855023971557617}\n",
            "OCS >> (average accuracy): 14.117999999999999\n",
            "OCS >> (Forgetting): 0.828257894736842\n",
            "Maximum per-task accuracies: [96.91]\n",
            "\n",
            "{'num_tasks': 20, 'per_task_rotation': 9, 'memory_size': 200, 'dataset': 'noisy-rot-mnist', 'device': 'cuda', 'momentum': 0.75, 'mlp_hiddens': 256, 'dropout': 0.2, 'lr_decay': 0.75, 'n_classes': 10, 'seq_lr': 0.005, 'stream_size': 100, 'ocspick': True, 'batch_size': 5, 'tau': 950.0, 'ref_hyp': 10.0, 'n_substeps': 20}\n"
          ]
        }
      ],
      "source": [
        "# NEW\n",
        "DATASET = 'noisy-rot-mnist'\n",
        "HIDDENS = 256\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = {\n",
        "    'num_tasks': 20,\n",
        "    'per_task_rotation': 9,\n",
        "    'memory_size': 200,\n",
        "    'dataset': DATASET,\n",
        "    'device': DEVICE,\n",
        "    'momentum': 0.7,\n",
        "    'mlp_hiddens': HIDDENS,\n",
        "    'dropout': 0.15,\n",
        "    'lr_decay': 0.7 if 'rot-mnist' in DATASET else 0.76,\n",
        "    'n_classes': 10,\n",
        "    'seq_lr': 0.006,\n",
        "    'stream_size': 100,\n",
        "    'ocspick': True,\n",
        "    'batch_size': 5,\n",
        "     'tau': 950.0,\n",
        "    'ref_hyp': 10. if 'rot-mnist' in DATASET else 50\n",
        "}\n",
        "\n",
        "log_dir =  f\"./summery/{config['dataset']}\"\n",
        "summary = SummaryWriter(log_dir)\n",
        "\n",
        "experiment = Experiment(api_key=\"hidden_key\", project_name=\"mnist\", disabled=True)\n",
        "\n",
        "loaders = get_all_loaders(config)\n",
        "\n",
        "\n",
        "def evaluate_model(model, task, loaders, config):\n",
        "    accuracies, losses = [], []\n",
        "    for t in range(1, task + 1):\n",
        "        metrics = eval_single_epoch(model, loaders['sequential'][t]['val'], config)\n",
        "        accuracies.append(metrics['accuracy'])\n",
        "        losses.append(metrics['loss'])\n",
        "        print(f'OCS >> Task {t}: {metrics}')\n",
        "    return accuracies, losses\n",
        "\n",
        "def main():\n",
        "    setup_experiment(experiment, config)\n",
        "\n",
        "    max_accuracies = [0.0] * config['num_tasks']\n",
        "    for task in range(1, config['num_tasks'] + 1):\n",
        "        print(f'---- Task {task} (OCS) ----')\n",
        "        model = train_task_sequentially(task, loaders, config, summary)\n",
        "\n",
        "        accuracies, _ = evaluate_model(model, task, loaders, config)\n",
        "        max_accuracies = [max(acc, max_acc) for acc, max_acc in zip(accuracies, max_accuracies)]\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies)\n",
        "        if task > 1:\n",
        "            forgetting = np.mean(np.array(max_accuracies[:task - 1]) - np.array(accuracies[:task - 1]))/ 100\n",
        "        else:\n",
        "            forgetting = 0.0\n",
        "\n",
        "        print(f\"OCS >> (average accuracy): {avg_accuracy}\")\n",
        "        print(f\"OCS >> (Forgetting): {forgetting}\")\n",
        "        summary.add_scalar('cl_average_accuracy', avg_accuracy, task - 1)\n",
        "        print(f'Maximum per-task accuracies: {max_accuracies}\\n')\n",
        "\n",
        "    print(config)\n",
        "    experiment.end()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}